{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72f4fd25",
   "metadata": {},
   "source": [
    "# Panic Project (DHLAB) - Data Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5634a08",
   "metadata": {},
   "source": [
    "author:  `@cyshin971`  \n",
    "\n",
    "date:    `2025-07-xx`  \n",
    "\n",
    "Instructions:\n",
    "- Run `data_processing.ipynb`\n",
    "- Output can be found in `./output/{scraped_data_filname}/imputed`\n",
    "\n",
    "version: `3.0`\n",
    " \n",
    "> version `2.0`: imputation separated from `data_analysis.ipynb` (version `1.3`)  \n",
    "> version `3.0`: Release Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76af6c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '3-0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42654e1",
   "metadata": {},
   "source": [
    "# üìö | Import Libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2014ac0",
   "metadata": {},
   "source": [
    "Required Packages:\n",
    "- `python` (`3.10`)\n",
    "- `pandas`  \n",
    "- `numpy`\n",
    "- `json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9df09cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from library.pandas_utils import create_empty_df, read_csv\n",
    "from library.text_utils import save_as_csv\n",
    "from library.json_utils import save_dict_to_file, load_dict_from_file\n",
    "from library.path_utils import get_file_path\n",
    "\n",
    "print(f\"Numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9a73f4",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è | Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "939f1990",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_scraped_data_filename = None # Keep as None if you don't want to manually specify a file\n",
    "\n",
    "use_growing_avg = True # Default: True\n",
    "# True: will use a growing average for the patient, i.e. the average of all previous entries\n",
    "# False: will use a fixed average for the patient, i.e. the average of all entries for that patient\n",
    "\n",
    "null_default_zero = True # Default: True\n",
    "# True: will replace null values with no existing entries for that patient with 0\n",
    "# False: will replace null values with no existing entries for that patient with the patient average or global average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa403ca",
   "metadata": {},
   "source": [
    "# üìÅ | Path Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd8780ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - (json_utils.py) load_dict_from_file: Dictionary loaded successfully from C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\_output\\panic_features_dict.json\n",
      "DEBUG - (json_utils.py) save_dict_to_file: Dictionary saved successfully to C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\_output\\panic_features_dict.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded features dict with 15 keys:\n",
      "  scraped_data_filename: final_result_20250626_360_no_ffill.csv\n",
      "  preproc_version: 3-0\n",
      "  demography: ['gender', 'age', 'marriage', 'job', 'smkHx', 'drinkHx', 'suicideHx', 'suicide_need']\n",
      "  dailylog: ['severity', 'exercise', 'alcohol', 'coffee', 'menstruation', 'smoking', 'positive_feeling', 'negative_feeling', 'positive_E', 'negative_E', 'anxiety', 'annoying']\n",
      "  mood: ['positive_feeling', 'negative_feeling', 'positive_E', 'negative_E', 'anxiety', 'annoying']\n",
      "  dailylog_life: ['exercise', 'alcohol', 'coffee', 'menstruation', 'smoking']\n",
      "  lifelog: ['HR_var', 'HR_max', 'HR_mean', 'HR_hvar_mean', 'HR_acrophase', 'HR_amplitude', 'HR_mesor', 'HR_acrophase_difference', 'HR_acrophase_difference_2d', 'HR_amplitude_difference', 'HR_amplitude_difference_2d', 'HR_mesor_difference', 'HR_mesor_difference_2d', 'bandpower(0.001-0.0005Hz)', 'bandpower(0.0005-0.0001Hz)', 'bandpower(0.0001-0.00005Hz)', 'bandpower(0.00005-0.00001Hz)', 'steps', 'SLT1', 'SLT2', 'SLT3', 'SLT4', 'SLT5', 'SLT6', 'total_sleep', 'steps_maximum', 'steps_mean', 'step_hvar_mean', 'step_delta', 'step_max_delta', 'step_mean_delta', 'step_hvar_mean_delta', 'step_delta2', 'step_max_delta2', 'step_mean_delta2', 'step_hvar_mean_delta2', 'steps_variance']\n",
      "  lifelog_HR: ['HR_var', 'HR_max', 'HR_mean', 'HR_hvar_mean', 'HR_acrophase', 'HR_amplitude', 'HR_mesor', 'HR_acrophase_difference', 'HR_acrophase_difference_2d', 'HR_amplitude_difference', 'HR_amplitude_difference_2d', 'HR_mesor_difference', 'HR_mesor_difference_2d', 'bandpower(0.001-0.0005Hz)', 'bandpower(0.0005-0.0001Hz)', 'bandpower(0.0001-0.00005Hz)', 'bandpower(0.00005-0.00001Hz)']\n",
      "  lifelog_steps: ['steps', 'steps_maximum', 'steps_mean', 'step_hvar_mean', 'step_delta', 'step_max_delta', 'step_mean_delta', 'step_hvar_mean_delta', 'step_delta2', 'step_max_delta2', 'step_mean_delta2', 'step_hvar_mean_delta2', 'steps_variance']\n",
      "  lifelog_sleep: ['SLT1', 'SLT2', 'SLT3', 'SLT4', 'SLT5', 'SLT6', 'total_sleep']\n",
      "  questionnaire: ['PHQ_9', 'STAI_X2', 'CSM', 'CTQ_1', 'CTQ_2', 'CTQ_3', 'CTQ_4', 'CTQ_5', 'KRQ', 'MDQ', 'ACQ', 'APPQ_1', 'APPQ_2', 'APPQ_3', 'BSQ', 'GAD_7', 'BRIAN']\n",
      "  excluded: ['SPAQ_1', 'SPAQ_2', 'BFNE', 'CES_D', 'KOSSSF', 'SADS', 'STAI_X1', 'medication_in_month', 'Unnamed: 0']\n",
      "  id: ['entry_id', 'ID', 'date', 'dataset']\n",
      "  label: ['panic', 'severity', 'panic_label']\n",
      "  metadata: ['dailylog_data', 'lifelog_data', 'questionnaire_data', 'dtype_n', 'ref_event_id', 'n_prior_data']\n"
     ]
    }
   ],
   "source": [
    "TMP_PATH = \"./_tmp\"\n",
    "OUT_PATH = \"./_output\"\n",
    "\n",
    "try:\n",
    "\tfeatures_dict = load_dict_from_file(OUT_PATH, 'panic_features_dict')\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"File not found: {get_file_path(OUT_PATH, 'panic_features_dict')}. Please run data_preprocessing.ipynb first.\")\n",
    "print(f\"Loaded features dict with {len(features_dict)} keys:\")\n",
    "scraped_data_filename = None\n",
    "for k, v in features_dict.items():\n",
    "    if k == 'scraped_data_filename':\n",
    "        print(f\"  {k}: {v}.csv\")\n",
    "        scraped_data_filename = v\n",
    "    elif k == 'preproc_version':\n",
    "        preproc_version = v\n",
    "        print(f\"  {k}: {v}\")\n",
    "    else:\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "if scraped_data_filename is None:\n",
    "\traise ValueError(\"scraped_data_filename not found in features_dict. Please ensure that data_preprocessing.ipynb has been run successfully before running this notebook.\")\n",
    "if manual_scraped_data_filename is not None:\n",
    "    logging.warning(f\"Using manually specified scraped_data_filename: {manual_scraped_data_filename}. If this is not intended, please set it to None.\")\n",
    "    scraped_data_filename = manual_scraped_data_filename\n",
    "\n",
    "features_dict['imputation_version'] = version\n",
    "features_dict['use_growing_avg'] = use_growing_avg\n",
    "features_dict['null_default_zero'] = null_default_zero\n",
    "save_dict_to_file(features_dict, OUT_PATH, 'panic_features_dict')\n",
    "\n",
    "PREPROC_PATH = f\"{OUT_PATH}/{scraped_data_filename}/preprocessed\"\n",
    "OUTPUT_PATH = f\"{OUT_PATH}/{scraped_data_filename}/imputed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6024277b",
   "metadata": {},
   "source": [
    "# ‚öíÔ∏è | Preprocessed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5b1f06",
   "metadata": {},
   "source": [
    "## Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d5a6ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>PHQ_9</th>\n",
       "      <th>STAI_X2</th>\n",
       "      <th>CSM</th>\n",
       "      <th>CTQ_1</th>\n",
       "      <th>CTQ_2</th>\n",
       "      <th>CTQ_3</th>\n",
       "      <th>...</th>\n",
       "      <th>SLT1</th>\n",
       "      <th>SLT2</th>\n",
       "      <th>SLT3</th>\n",
       "      <th>SLT4</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>panic</th>\n",
       "      <th>severity</th>\n",
       "      <th>panic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006_2024-11-04</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10006_2024-11-05</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>15.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                entry_id dataset          ID        date  PHQ_9  STAI_X2  \\\n",
       "0  PXPN_10006_2024-11-04    PXPN  PXPN_10006  2024-11-04    0.0     32.0   \n",
       "1  PXPN_10006_2024-11-05    PXPN  PXPN_10006  2024-11-05    NaN      NaN   \n",
       "\n",
       "    CSM  CTQ_1  CTQ_2  CTQ_3  ...  SLT1  SLT2  SLT3  SLT4  SLT5  SLT6  \\\n",
       "0  31.0   11.0   13.0   17.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1   NaN    NaN    NaN    NaN  ...   0.0  4.47  3.62  4.67  0.65  1.85   \n",
       "\n",
       "   total_sleep  panic  severity  panic_label  \n",
       "0          NaN    0.0       NaN            0  \n",
       "1        15.26    0.0       NaN            0  \n",
       "\n",
       "[2 rows x 72 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "      <th>dtype_n</th>\n",
       "      <th>panic</th>\n",
       "      <th>n_prior_data</th>\n",
       "      <th>dbp</th>\n",
       "      <th>valid_entry_3</th>\n",
       "      <th>valid_entry_2</th>\n",
       "      <th>valid_entry_1</th>\n",
       "      <th>ref_event_id</th>\n",
       "      <th>panic_label</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SYM2-1-96_2021-08-04</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SYM2-1-96_2021-08-03</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               entry_id         ID        date dataset  dailylog_data  \\\n",
       "0  SYM2-1-96_2021-08-04  SYM2-1-96  2021-08-04    SYM2              0   \n",
       "1  SYM2-1-96_2021-08-03  SYM2-1-96  2021-08-03    SYM2              0   \n",
       "\n",
       "   lifelog_data  questionnaire_data  dtype_n  panic  n_prior_data  dbp  \\\n",
       "0             1                   0        1    0.0             2  NaN   \n",
       "1             1                   0        1    0.0             1  NaN   \n",
       "\n",
       "   valid_entry_3  valid_entry_2  valid_entry_1 ref_event_id  panic_label  \\\n",
       "0              0              1              1          NaN            0   \n",
       "1              0              0              1          NaN            0   \n",
       "\n",
       "   severity  \n",
       "0       NaN  \n",
       "1       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>marriage</th>\n",
       "      <th>job</th>\n",
       "      <th>smkHx</th>\n",
       "      <th>drinkHx</th>\n",
       "      <th>suicideHx</th>\n",
       "      <th>suicide_need</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10007</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  gender   age  marriage  job  smkHx  drinkHx  suicideHx  \\\n",
       "0  PXPN_10006       0  32.0       0.0  1.0    1.0      1.0        0.0   \n",
       "1  PXPN_10007       1  38.0       1.0  1.0    0.0      0.0        0.0   \n",
       "\n",
       "   suicide_need  \n",
       "0           0.0  \n",
       "1           0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pre_data = read_csv(get_file_path(PREPROC_PATH, f'panic_pre_data_{preproc_version}({scraped_data_filename}).csv'))\n",
    "display(pre_data.head(2))\n",
    "metadata = read_csv(get_file_path(PREPROC_PATH, f'panic_metadata_{preproc_version}({scraped_data_filename}).csv'))\n",
    "display(metadata.head(2))\n",
    "demography_data = read_csv(get_file_path(PREPROC_PATH, f'panic_demography_data_{preproc_version}({scraped_data_filename}).csv'))\n",
    "display(demography_data.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdce151",
   "metadata": {},
   "source": [
    "# Data Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d9355d",
   "metadata": {},
   "source": [
    "## Questionnaire\n",
    "\n",
    "- The null values were forward filled from the first value in the scraped data\n",
    "- the entries with null values prior to the first value was backward filled\n",
    "- Subsequent entries were forward filled\n",
    "- other null values were set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5360f347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset</th>\n",
       "      <th>PHQ_9</th>\n",
       "      <th>STAI_X2</th>\n",
       "      <th>CSM</th>\n",
       "      <th>CTQ_1</th>\n",
       "      <th>CTQ_2</th>\n",
       "      <th>CTQ_3</th>\n",
       "      <th>...</th>\n",
       "      <th>CTQ_5</th>\n",
       "      <th>KRQ</th>\n",
       "      <th>MDQ</th>\n",
       "      <th>ACQ</th>\n",
       "      <th>APPQ_1</th>\n",
       "      <th>APPQ_2</th>\n",
       "      <th>APPQ_3</th>\n",
       "      <th>BSQ</th>\n",
       "      <th>GAD_7</th>\n",
       "      <th>BRIAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7790</th>\n",
       "      <td>SYM1-1-380_2021-07-24</td>\n",
       "      <td>SYM1-1-380</td>\n",
       "      <td>2021-07-24</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7791</th>\n",
       "      <td>SYM1-1-380_2021-07-25</td>\n",
       "      <td>SYM1-1-380</td>\n",
       "      <td>2021-07-25</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   entry_id          ID        date dataset  PHQ_9  STAI_X2  \\\n",
       "7790  SYM1-1-380_2021-07-24  SYM1-1-380  2021-07-24    SYM1    7.0      0.0   \n",
       "7791  SYM1-1-380_2021-07-25  SYM1-1-380  2021-07-25    SYM1    7.0      0.0   \n",
       "\n",
       "       CSM  CTQ_1  CTQ_2  CTQ_3  ...  CTQ_5  KRQ  MDQ   ACQ  APPQ_1  APPQ_2  \\\n",
       "7790  24.0    0.0    0.0    0.0  ...    0.0  0.0  0.0  18.0    20.0    14.0   \n",
       "7791  24.0    0.0    0.0    0.0  ...    0.0  0.0  0.0  18.0    20.0    14.0   \n",
       "\n",
       "      APPQ_3   BSQ  GAD_7  BRIAN  \n",
       "7790    14.0  41.0    1.0   34.0  \n",
       "7791    14.0  41.0    1.0   34.0  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pre_data_filled_questionnaire = create_empty_df()\n",
    "pre_data_filled_questionnaire = pre_data.copy()\n",
    "\n",
    "pre_data_filled_questionnaire.sort_values(by=['ID', 'date'], inplace=True)\n",
    "\n",
    "for qcol in features_dict['questionnaire']:\n",
    "    pre_data_filled_questionnaire[qcol] = (\n",
    "        pre_data_filled_questionnaire.groupby('ID')[qcol]\n",
    "            .apply(lambda s: s.ffill().bfill())\n",
    "            .fillna(0)\n",
    "            .values\n",
    "    )\n",
    "\n",
    "pre_data_filled_questionnaire.sort_values(by=['ID', 'date'], inplace=True)\n",
    "disp_df = pre_data_filled_questionnaire[pre_data_filled_questionnaire['ID'] == 'SYM1-1-380'].copy()\n",
    "display(disp_df[features_dict['id']+features_dict['questionnaire']].head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304d45e2",
   "metadata": {},
   "source": [
    "## Growing Average Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a53ac46",
   "metadata": {},
   "source": [
    "- Initial fill: All NaNs get 0.\n",
    "- By ID: For each ID, process their entries in chronological order (date).\n",
    "- Running average: Each time a valid value is encountered, add it to the running sum/count.\n",
    "- For every NaN (now 0, but you detect it with the original mask), fill with running average so far.\n",
    "- No values for that ID: Remain at 0 (since running_count stays at 0).\n",
    "- After each value: The average is updated so the imputation logic matches your requirements.\n",
    "- No backward fill: Only forward imputation based on past data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d3281c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (4216903050.py) <module>: Using growing average imputation.\n"
     ]
    }
   ],
   "source": [
    "from utils.imputation_utils import growing_average_impute\n",
    "\n",
    "pre_data_filled_avg = create_empty_df()\n",
    "pre_data_filled_avg = pre_data_filled_questionnaire.copy()\n",
    "\n",
    "avg_features = features_dict['lifelog'] + features_dict['mood']\n",
    "\n",
    "if use_growing_avg:\n",
    "\tlogging.info(\"Using growing average imputation.\")\n",
    "\tpre_data_filled_avg = growing_average_impute(\n",
    "\t\tpre_data_filled_avg, 'ID', avg_features, default_fill_zero=null_default_zero\n",
    "\t)\n",
    "else: \n",
    "\tlogging.info(\"Using fixed average imputation.\")\n",
    "\tfor col in avg_features:\n",
    "\t\tpre_data_filled_avg[col] = pre_data_filled_avg.groupby('ID')[col].transform(\n",
    "\t\t\tlambda x: x.fillna(x.mean())\n",
    "\t\t)\n",
    "\t\tif null_default_zero:\n",
    "\t\t\tpre_data_filled_avg[col].fillna(0, inplace=True)\n",
    "\t\telse:\n",
    "\t\t\tpre_data_filled_avg[col].fillna(pre_data_filled_avg[col].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27d404d",
   "metadata": {},
   "source": [
    "## Null Value 0\n",
    "\n",
    "- Null values set to `0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d609e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_null_features = features_dict['dailylog_life']\n",
    "\n",
    "pre_data_filled_zero_null = create_empty_df()\n",
    "pre_data_filled_zero_null = pre_data_filled_avg.copy()\n",
    "\n",
    "# Fill Null Values\n",
    "pre_data_filled_zero_null.loc[:, zero_null_features] = pre_data_filled_zero_null.loc[:, zero_null_features].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0c8ada",
   "metadata": {},
   "source": [
    "## üíæ | Save Filled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2c34026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - (path_utils.py) make_dir: Created directory: C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\_output\\final_result_20250626_360_no_ffill\\imputed\n",
      "DEBUG - (text_utils.py) save_as_csv: Saved panic_pre_data_filled_3-0(final_result_20250626_360_no_ffill)_grw_zero.csv to C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\_output\\final_result_20250626_360_no_ffill\\imputed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/cyshi/OneDrive/Documents/GitHub/Panic-Project-CYS/_output/final_result_20250626_360_no_ffill/imputed/panic_pre_data_filled_3-0(final_result_20250626_360_no_ffill)_grw_zero.csv')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_data_filled = create_empty_df()\n",
    "pre_data_filled = pre_data_filled_zero_null.copy()\n",
    "\n",
    "save_as_csv(pre_data_filled, OUTPUT_PATH, f\"panic_pre_data_filled_{version}({scraped_data_filename})_{('grw' if use_growing_avg else 'avg')}_{('zero' if null_default_zero else 'global')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeb7bee",
   "metadata": {},
   "source": [
    "## Filled Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4df884ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - (text_utils.py) save_as_csv: Saved panic_metadata_filled_3-0(final_result_20250626_360_no_ffill)_grw_zero.csv to C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\_output\\final_result_20250626_360_no_ffill\\imputed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "      <th>dtype_n</th>\n",
       "      <th>panic</th>\n",
       "      <th>n_prior_data</th>\n",
       "      <th>dbp</th>\n",
       "      <th>valid_entry_3</th>\n",
       "      <th>valid_entry_2</th>\n",
       "      <th>valid_entry_1</th>\n",
       "      <th>ref_event_id</th>\n",
       "      <th>panic_label</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SYM2-1-96_2021-08-04</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SYM2-1-96_2021-08-03</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               entry_id         ID        date dataset  dailylog_data  \\\n",
       "0  SYM2-1-96_2021-08-04  SYM2-1-96  2021-08-04    SYM2              1   \n",
       "1  SYM2-1-96_2021-08-03  SYM2-1-96  2021-08-03    SYM2              1   \n",
       "\n",
       "   lifelog_data  questionnaire_data  dtype_n  panic  n_prior_data  dbp  \\\n",
       "0             1                   1        3    0.0             2  NaN   \n",
       "1             1                   1        3    0.0             1  NaN   \n",
       "\n",
       "   valid_entry_3  valid_entry_2  valid_entry_1 ref_event_id  panic_label  \\\n",
       "0              0              1              1          NaN            0   \n",
       "1              0              0              1          NaN            0   \n",
       "\n",
       "   severity  \n",
       "0       NaN  \n",
       "1       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata_filled = create_empty_df()\n",
    "metadata_filled = metadata.copy()\n",
    "if len(pre_data_filled) != len(metadata):\n",
    "    raise ValueError(f\"Length of pre_data_filled ({len(pre_data_filled)}) does not match length of metadata ({len(metadata)}). Please check the data consistency.\")\n",
    "none_columns = ['dailylog_data', 'lifelog_data', 'questionnaire_data', 'dtype_n']\n",
    "for col in none_columns:\n",
    "    metadata_filled[col] = None\n",
    "\n",
    "metadata_filled['dailylog_data'] = pre_data_filled[features_dict['dailylog']].notnull().any(axis=1).astype(int)\n",
    "metadata_filled['lifelog_data'] = pre_data_filled[features_dict['lifelog']].notnull().any(axis=1).astype(int)\n",
    "metadata_filled['questionnaire_data'] = pre_data_filled[features_dict['questionnaire']].notnull().any(axis=1).astype(int)\n",
    "\n",
    "# TODO: Diary data is not used in the current analysis, but can be useful for future reference\n",
    "metadata_filled['dtype_n'] = metadata_filled['dailylog_data'] + metadata_filled['lifelog_data'] + metadata_filled['questionnaire_data']\n",
    "\n",
    "save_as_csv(metadata_filled, OUTPUT_PATH, f\"panic_metadata_filled_{version}({scraped_data_filename})_{('grw' if use_growing_avg else 'avg')}_{('zero' if null_default_zero else 'global')}\")\n",
    "display(metadata_filled.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bdba2a",
   "metadata": {},
   "source": [
    "# üìí | Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77f58181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique IDs in pre_data_filled: 273\n",
      "Total number of entries in pre_data_filled: 19379\n",
      "Total number of panic entries in pre_data_filled: 811\n"
     ]
    }
   ],
   "source": [
    "unique_filled_ids =  pre_data_filled['ID'].unique()\n",
    "print(f\"Total number of unique IDs in pre_data_filled: {len(unique_filled_ids)}\")\n",
    "print(f\"Total number of entries in pre_data_filled: {len(pre_data_filled)}\")\n",
    "panic_entries = pre_data_filled[pre_data_filled['panic_label'] == 1]\n",
    "print(f\"Total number of panic entries in pre_data_filled: {len(panic_entries)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9142c25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of daily log entries: 19379 / 19379 (100.00%)\n",
      "Total number of life log entries: 19379 / 19379 (100.00%)\n",
      "Total number of questionnaire entries: 19379 / 19379 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "filled_entry_ids = pre_data_filled['entry_id'].unique()\n",
    "print(f\"Total number of daily log entries: {metadata_filled[metadata_filled['dailylog_data'] == 1].shape[0]} / {len(filled_entry_ids)} ({metadata_filled[metadata_filled['dailylog_data'] == 1].shape[0] / len(filled_entry_ids) * 100:.2f}%)\")\n",
    "print(f\"Total number of life log entries: {metadata_filled[metadata_filled['lifelog_data'] == 1].shape[0]} / {len(filled_entry_ids)} ({metadata_filled[metadata_filled['lifelog_data'] == 1].shape[0] / len(filled_entry_ids) * 100:.2f}%)\")\n",
    "print(f\"Total number of questionnaire entries: {metadata_filled[metadata_filled['questionnaire_data'] == 1].shape[0]} / {len(filled_entry_ids)} ({metadata_filled[metadata_filled['questionnaire_data'] == 1].shape[0] / len(filled_entry_ids) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "befcc5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of patients with panic events: 105\n"
     ]
    }
   ],
   "source": [
    "panic_patients = metadata_filled[metadata_filled['panic_label'] == 1]['ID'].unique()\n",
    "print(f\"Total number of patients with panic events: {len(panic_patients)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dhlab-panic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
