{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72f4fd25",
   "metadata": {},
   "source": [
    "# Panic Project (DHLAB) - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5634a08",
   "metadata": {},
   "source": [
    "author:  `@cyshin971`  \n",
    "\n",
    "date:    `2025-07-14`  \n",
    "\n",
    "Instructions:\n",
    "- Scrape data (see `README` - `Instructions` - `Data Scraping`)  \n",
    "- Run the notebook (`Run All`) (may take 1 ~ 2 minutes)\n",
    "- preprocesssed data can be found in `./data/`\n",
    "\n",
    "version: `3.1`\n",
    "\n",
    "> version `1.0`: Derived from `data_analysis.ipynb` version `1.0`  \n",
    "> version `2.0`: Updated to consensus on progress meeting `20250619`  \n",
    "> version `3.0`: Release Version  \n",
    "> -  version `3.1`: Directory organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "534a5112",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"3-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42654e1",
   "metadata": {},
   "source": [
    "# üìö | Import Libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7205a14",
   "metadata": {},
   "source": [
    "Required Packages:\n",
    "- `python` (`3.10`)\n",
    "- `pandas`  \n",
    "- `numpy`\n",
    "- `json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9df09cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.3.1\n",
      "Numpy version: 2.2.6\n"
     ]
    }
   ],
   "source": [
    "import config as cfg\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "\n",
    "from library.pandas_utils import move_column, remove_columns, aggregate_by_column, create_empty_df, read_csv\n",
    "from library.text_utils import save_as_csv\n",
    "from library.json_utils import save_dict_to_file\n",
    "from library.path_utils import get_file_path\n",
    "\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfc0e3f",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è | Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e80a7b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_data_filename = \"merged_df\" # (Default: \"scraped_data\") Name of the scraped data file without extension (.csv)\n",
    "\n",
    "save_removed_data = False  # Set to True (Default: False) if you want to save the removed data to TMP_PATH\n",
    "\n",
    "is_dev = False  # Set to True (Default: False) if you want to run the notebook in development mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd7b00ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (2846733894.py) <module>: Notebook running with:\n",
      "preproc version: 3-1\n",
      "scraped_data_filename = 'merged_df.csv'\n",
      "mode = production\n",
      "save_removed_data = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not is_dev and scraped_data_filename != \"merged_df\":\n",
    "    raise ValueError(\"scraped_data_filename must be 'merged_df.csv' in production mode\")\n",
    "\n",
    "logging.info(f\"Notebook running with:\\n\" +\n",
    "             f\"preproc version: {version}\\n\" +\n",
    "             f\"scraped_data_filename = '{scraped_data_filename}.csv'\\n\" +\n",
    "             f\"mode = {('development' if is_dev else 'production')}\\n\" +\n",
    "             f\"save_removed_data = {save_removed_data}\\n\")\n",
    "\n",
    "current_config = {\n",
    "\t\"scraped_data_filename\": scraped_data_filename,\n",
    "    \"preproc_version\": version,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa403ca",
   "metadata": {},
   "source": [
    "# üìÅ | Path Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd8780ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data\"\n",
    "TMP_PATH = \"./_tmp\"\n",
    "file_desc = \"\"\n",
    "if is_dev:\n",
    "\tOUT_PATH = f\"./_output\"\n",
    "\tOUT_FILE_PATH = f\"./_output/{scraped_data_filename}\"\n",
    "\tOUTPUT_PATH = f\"{OUT_FILE_PATH}/preprocessed\"\n",
    "\tfile_desc = f\"_{version}({scraped_data_filename})\"\n",
    "else:\n",
    "\tOUT_PATH = TMP_PATH\n",
    "\tOUT_FILE_PATH = DATA_PATH\n",
    "\tOUTPUT_PATH = DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bbe0e9",
   "metadata": {},
   "source": [
    "# ‚õèÔ∏è | Scraped Data\n",
    "\n",
    "load preprocessed data (by `junyeol_lee`)\n",
    "- Each entry are the datapoints for a patient (`ID`) on a specific date (`date`)\n",
    "- If there were multiple datapoints for a specific date (`date`) for a specific patient (`ID`), the values were statistically processed (`sum`, `avg`, etc.) to a representation for the day\n",
    "- Questionnaire data was treated as a 'semi-trait' variable  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dbe912",
   "metadata": {},
   "source": [
    "## Scraped Data Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aab7722c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables: 75\n",
      "   Demographic variables: 8\n",
      "   Daily log variables: 13\n",
      "   Life log variables: 37\n",
      "   Questionnaire variables: 17\n"
     ]
    }
   ],
   "source": [
    "features_dict = { \n",
    "\t\"demography\": [\n",
    "\t\t'gender', 'age', 'marriage', 'job', 'smkHx', 'drinkHx', 'suicideHx', 'suicide_need'\n",
    "\t],\n",
    "\t\"dailylog\": [\n",
    "\t\t'panic', 'severity', # NOTE: Caution when constructing dataset as these values are typically labels\n",
    "  \t\t'exercise', 'alcohol', 'coffee', 'menstruation', 'smoking',\n",
    "    \t'positive_feeling', 'negative_feeling', 'positive_E', 'negative_E', 'anxiety', 'annoying' # mood\n",
    "\t],\n",
    "\t\"mood\": [\n",
    "\t\t'positive_feeling', 'negative_feeling', 'positive_E', 'negative_E',\n",
    "\t\t'anxiety', 'annoying'\n",
    "\t],\n",
    "\t\"dailylog_life\": [\n",
    "\t\t'exercise', 'alcohol', 'coffee', 'menstruation', 'smoking'\n",
    "\t],\n",
    "\t\"lifelog\": [\n",
    "        'HR_var', 'HR_max', 'HR_mean', 'HR_hvar_mean', 'HR_acrophase', 'HR_amplitude', 'HR_mesor',\n",
    "        'HR_acrophase_difference', 'HR_acrophase_difference_2d', 'HR_amplitude_difference',\n",
    "        'HR_amplitude_difference_2d', 'HR_mesor_difference', 'HR_mesor_difference_2d',\n",
    "        'bandpower(0.001-0.0005Hz)', 'bandpower(0.0005-0.0001Hz)', 'bandpower(0.0001-0.00005Hz)', 'bandpower(0.00005-0.00001Hz)',\n",
    "        'steps', 'SLT1', 'SLT2', 'SLT3', 'SLT4', 'SLT5', 'SLT6', 'total_sleep',\n",
    "        'steps_maximum', 'steps_mean', 'step_hvar_mean', 'step_delta',\n",
    "        'step_max_delta', 'step_mean_delta', 'step_hvar_mean_delta',\n",
    "        'step_delta2', 'step_max_delta2', 'step_mean_delta2', 'step_hvar_mean_delta2', 'steps_variance'\n",
    "\t],\n",
    "\t\"lifelog_HR\": [\n",
    "        'HR_var', 'HR_max', 'HR_mean', 'HR_hvar_mean', 'HR_acrophase', 'HR_amplitude', 'HR_mesor',\n",
    "        'HR_acrophase_difference', 'HR_acrophase_difference_2d', 'HR_amplitude_difference',\n",
    "        'HR_amplitude_difference_2d', 'HR_mesor_difference', 'HR_mesor_difference_2d',\n",
    "        'bandpower(0.001-0.0005Hz)', 'bandpower(0.0005-0.0001Hz)', 'bandpower(0.0001-0.00005Hz)', 'bandpower(0.00005-0.00001Hz)',\n",
    "\t],\n",
    " \t\"lifelog_steps\": [\n",
    "\t\t'steps', 'steps_maximum', 'steps_mean', 'step_hvar_mean', 'step_delta',\n",
    "        'step_max_delta', 'step_mean_delta', 'step_hvar_mean_delta',\n",
    "        'step_delta2', 'step_max_delta2', 'step_mean_delta2', 'step_hvar_mean_delta2', 'steps_variance'\n",
    " \t],\n",
    "    \"lifelog_sleep\": [\n",
    "\t\t'SLT1', 'SLT2', 'SLT3', 'SLT4', 'SLT5', 'SLT6', 'total_sleep'\n",
    "    ],\n",
    "\t\"questionnaire\": [\n",
    "\t\t'PHQ_9', 'STAI_X2', 'CSM', 'CTQ_1', 'CTQ_2', 'CTQ_3', 'CTQ_4', 'CTQ_5', 'KRQ', 'MDQ',\n",
    "\t\t'ACQ', 'APPQ_1', 'APPQ_2', 'APPQ_3', 'BSQ', 'GAD_7', 'BRIAN'\n",
    "\t],\n",
    "\t\"excluded\": [ # Dropped as variables were only in SYM dataset\n",
    "\t\t'SPAQ_1', 'SPAQ_2', 'BFNE', 'CES_D', 'KOSSSF', 'SADS', 'STAI_X1', 'medication_in_month',\n",
    "        'Unnamed: 0' # Placeholder column\n",
    "\t],\n",
    "    \"id\": [\n",
    "        'ID', 'date'\n",
    "    ],\n",
    "    \"label\": [\n",
    "        'panic', 'severity'\n",
    "    ],\n",
    "    \"metadata\": []\n",
    "}\n",
    "\n",
    "demo_vars = features_dict[\"demography\"]\n",
    "dailylog_vars = features_dict[\"dailylog\"]\n",
    "lifelog_vars = features_dict[\"lifelog\"]\n",
    "questionnaire_vars = features_dict[\"questionnaire\"]\n",
    "\n",
    "state_vars = demo_vars\n",
    "trait_vars = dailylog_vars + lifelog_vars + questionnaire_vars\n",
    "all_vars = state_vars + dailylog_vars + lifelog_vars + questionnaire_vars\n",
    "all_cols = features_dict[\"id\"] + all_vars\n",
    "\n",
    "print(f'Number of variables: {len(all_vars)}')\n",
    "print(f'   Demographic variables: {len(state_vars)}')\n",
    "print(f'   Daily log variables: {len(dailylog_vars)}')\n",
    "print(f'   Life log variables: {len(lifelog_vars)}')\n",
    "print(f'   Questionnaire variables: {len(questionnaire_vars)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81218b4a",
   "metadata": {},
   "source": [
    "## Load Scraped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a279cfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (1268328867.py) <module>: All expected columns are present in scraped_data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 29143\n",
      "Number of columns: 77\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\tscraped_data = read_csv(get_file_path(DATA_PATH, scraped_data_filename + '.csv'))\n",
    "except FileNotFoundError:\n",
    "\traise FileNotFoundError(f\"File not found: {get_file_path(DATA_PATH, scraped_data_filename + '.csv')}. Please run data scraping first.\")\n",
    "\n",
    "# check if all columns are present\n",
    "missing_cols = [col for col in all_vars if col not in scraped_data.columns]\n",
    "if missing_cols:\n",
    "\tlogging.warning(f\"Missing columns in scraped_data: {missing_cols}\")\n",
    "else:\n",
    "\tlogging.info(\"All expected columns are present in scraped_data.\")\n",
    "extra_cols = [col for col in scraped_data.columns if col not in all_cols + features_dict[\"excluded\"]]\n",
    "if extra_cols:\n",
    "\tlogging.warning(f\"Extra columns in scraped_data: {extra_cols}\")\n",
    "\n",
    "# convert date column to datetime format\n",
    "scraped_data['date'] = pd.to_datetime(scraped_data['date'], format='%Y-%m-%d', errors='coerce')\n",
    "# remove_columns(scraped_data, ['Unnamed: 0'])\n",
    "\n",
    "# remove any of the columns in features_dict[\"excluded\"] if they exist\n",
    "for col in features_dict[\"excluded\"]:\n",
    "\tif col in scraped_data.columns:\n",
    "\t\tlogging.info(f\"Removing excluded column: {col}\")\n",
    "\t\tscraped_data.drop(columns=[col], inplace=True)\n",
    "\n",
    "print(f\"Number of rows: {scraped_data.shape[0]}\")\n",
    "print(f\"Number of columns: {scraped_data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6024277b",
   "metadata": {},
   "source": [
    "# ‚öíÔ∏è | Data Preprocessing\n",
    "\n",
    "Changes from scraped data:\n",
    "- add `entry_id` to identify each entry: `'ID'_'date'`\n",
    "- add `dataset` to identify source: `SYM1`, `SYM2`, `PXPN`\n",
    "- convert `panic` (`0`, `1`, `2` = panic) to days before panic (`dbp`) (panic = `0`, `1`, `2`)\n",
    "  - dbp removed and only added in metdata (`20250626`)\n",
    "- add `panic_label` : whether a panic occurred in the entry (`boolean`)\n",
    "- demographic features were removed from preprocessed data (`data_pre`) and extracted\n",
    "- the data was filtered to remove entries with only demgraphic data (no `dailylog`, `lifelog`, `questionnaire`, or `diary` entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5b1f06",
   "metadata": {},
   "source": [
    "## Initialize Preprocessed Data\n",
    "\n",
    "- add `entry_id` to identify each entry: `'ID'_'date'`\n",
    "- add `dataset` to identify source: `SYM1`, `SYM2`, `PXPN`\n",
    "- add `panic_label` (boolean)\n",
    "- keep `panic` column instead of removing it (`20250617`)\n",
    "> If using `panic` column as a label this must be removed as a feature from final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d5a6ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique entry IDs: 29143\n",
      "Scraped data shape: (29143, 77)\n",
      "Initialized preprocessed data shape: (29143, 80)\n"
     ]
    }
   ],
   "source": [
    "data_pre_init = create_empty_df()\n",
    "data_pre_init = scraped_data.copy()\n",
    "\n",
    "# Add 'entry_id' column: unique identifier for each row\n",
    "data_pre_init['entry_id'] = data_pre_init['ID'] + '_' + data_pre_init['date'].astype(str)\n",
    "instance_id_unique = data_pre_init['entry_id'].unique()\n",
    "move_column(data_pre_init, 'entry_id', 0)\n",
    "print(\"Number of unique entry IDs:\", len(instance_id_unique))\n",
    "# Check if 'entry_id' is unique\n",
    "if data_pre_init['entry_id'].duplicated().any():\n",
    "\t# return the rows with duplicate 'entry_id'\n",
    "\tduplicates = data_pre_init[data_pre_init['entry_id'].duplicated(keep=False)]\n",
    "\tdisplay(duplicates.head(5))\n",
    "\tsave_as_csv(duplicates, TMP_PATH, f\"duplicates_{scraped_data_filename}\")\n",
    "\traise ValueError(\"Duplicate 'entry_id' found in the data. Please resolve this issue before proceeding.\")\n",
    "\n",
    "# Add 'dataset' column: source of data\n",
    "data_pre_init['dataset'] = data_pre_init['ID'].str.split('_').str[0]\n",
    "data_pre_init['dataset'] = data_pre_init['dataset'].str.split('-').str[0]\n",
    "move_column(data_pre_init, 'dataset', 1)\n",
    "\n",
    "# Add panic_label column\n",
    "data_pre_init['panic_label'] = data_pre_init['panic'].apply(lambda x: 1 if x == 2 else 0)\n",
    "\n",
    "# Update the features_dict\n",
    "if 'entry_id' not in features_dict['id']:\n",
    "\tfeatures_dict['id'].insert(0, 'entry_id')\n",
    "if 'dataset' not in features_dict['id']:\n",
    "\tfeatures_dict['id'].append('dataset')\n",
    "if 'panic_label' not in features_dict['label']:\n",
    "\tfeatures_dict['label'].append('panic_label')\n",
    "# Remove 'panic' from dailylog features (as it is a label) #NOTE: Need to remove as panic null values were filled with 0 in scraped_data\n",
    "if 'panic' in features_dict['dailylog']:\n",
    "\tfeatures_dict['dailylog'].remove('panic')\n",
    "\n",
    "# print scraped_data shape\n",
    "print(f\"Scraped data shape: {scraped_data.shape}\")\n",
    "print(f\"Initialized preprocessed data shape: {data_pre_init.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "276b12c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>panic</th>\n",
       "      <th>gender</th>\n",
       "      <th>marriage</th>\n",
       "      <th>job</th>\n",
       "      <th>smkHx</th>\n",
       "      <th>drinkHx</th>\n",
       "      <th>...</th>\n",
       "      <th>SLT1</th>\n",
       "      <th>SLT2</th>\n",
       "      <th>SLT3</th>\n",
       "      <th>SLT4</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>smoking</th>\n",
       "      <th>menstruation</th>\n",
       "      <th>panic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SYM1-1-100_2021-03-02</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>SYM1-1-100</td>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SYM1-1-100_2021-03-03</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>SYM1-1-100</td>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                entry_id dataset          ID       date  panic  gender  \\\n",
       "0  SYM1-1-100_2021-03-02    SYM1  SYM1-1-100 2021-03-02    2.0       1   \n",
       "1  SYM1-1-100_2021-03-03    SYM1  SYM1-1-100 2021-03-03    2.0       1   \n",
       "\n",
       "   marriage  job  smkHx  drinkHx  ...  SLT1  SLT2  SLT3  SLT4  SLT5  SLT6  \\\n",
       "0       0.0  0.0    0.0      0.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1       0.0  0.0    0.0      0.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "   total_sleep  smoking  menstruation  panic_label  \n",
       "0          NaN      NaN           NaN            1  \n",
       "1          NaN      NaN           NaN            1  \n",
       "\n",
       "[2 rows x 80 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique sources in metadata_ljy:  ['SYM1' 'SYM2' 'PXPN']\n",
      "Number of entries in metadata_ljy: 29143\n",
      "    SYM entries: 28163\n",
      "    PXPN entries: 980\n",
      "Number of unique IDs in metadata_ljy: 434\n",
      "    SYM IDs:  400\n",
      "    PXPN IDs:  34\n",
      "Number of panic events (panic_label = 1): 866\n"
     ]
    }
   ],
   "source": [
    "display(data_pre_init.head(2))\n",
    "print(\"Unique sources in metadata_ljy: \", data_pre_init['dataset'].unique())\n",
    "print(\"Number of entries in metadata_ljy:\", data_pre_init.shape[0])\n",
    "sym1_n = data_pre_init[data_pre_init['dataset'] == 'SYM1'].shape[0]\n",
    "sym2_n = data_pre_init[data_pre_init['dataset'] == 'SYM2'].shape[0]\n",
    "print(\"    SYM entries:\", sym1_n+sym2_n)\n",
    "print(\"    PXPN entries:\", data_pre_init[data_pre_init['dataset'] == 'PXPN'].shape[0])\n",
    "print(\"Number of unique IDs in metadata_ljy:\", len(data_pre_init['ID'].unique()))\n",
    "# find the unique IDs for SYM1 and SYM2\n",
    "sym1_ids = data_pre_init[data_pre_init['dataset'] == 'SYM1']['ID'].unique()\n",
    "sym2_ids = data_pre_init[data_pre_init['dataset'] == 'SYM2']['ID'].unique()\n",
    "print(\"    SYM IDs: \", len(sym1_ids)+len(sym2_ids))\n",
    "print(\"    PXPN IDs: \", len(data_pre_init[data_pre_init['dataset'] == 'PXPN']['ID'].unique()))\n",
    "print(\"Number of panic events (panic_label = 1):\", data_pre_init[data_pre_init['panic_label'] == 1].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7cac54",
   "metadata": {},
   "source": [
    "## Initialize Metadata\n",
    "\n",
    "initialize `metadata` by adding\n",
    "- `demography_data` : whether demography data exists in the entry (`boolean`)\n",
    "- `dailylog_data`, `lifelog_data`, `questionnaire_data` : whether each data group exists in the entry (`boolean`)\n",
    "- `dtype_n` : how many of the 3 `state` groups exists in the entry (`int`)\n",
    "- `diary_data`: whether panic diary data group exists in the entry (`boolean`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ed181f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>panic</th>\n",
       "      <th>gender</th>\n",
       "      <th>marriage</th>\n",
       "      <th>job</th>\n",
       "      <th>dtype_n</th>\n",
       "      <th>smkHx</th>\n",
       "      <th>...</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>smoking</th>\n",
       "      <th>menstruation</th>\n",
       "      <th>panic_label</th>\n",
       "      <th>demography_data</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SYM1-1-100_2021-03-02</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>SYM1-1-100</td>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SYM1-1-100_2021-03-03</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>SYM1-1-100</td>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                entry_id dataset          ID       date  panic  gender  \\\n",
       "0  SYM1-1-100_2021-03-02    SYM1  SYM1-1-100 2021-03-02    2.0       1   \n",
       "1  SYM1-1-100_2021-03-03    SYM1  SYM1-1-100 2021-03-03    2.0       1   \n",
       "\n",
       "   marriage  job  dtype_n  smkHx  ...  SLT5  SLT6  total_sleep  smoking  \\\n",
       "0       0.0  0.0        2    0.0  ...   NaN   NaN          NaN      NaN   \n",
       "1       0.0  0.0        1    0.0  ...   NaN   NaN          NaN      NaN   \n",
       "\n",
       "   menstruation  panic_label  demography_data  dailylog_data  lifelog_data  \\\n",
       "0           NaN            1                1              1             0   \n",
       "1           NaN            1                1              1             0   \n",
       "\n",
       "   questionnaire_data  \n",
       "0                   1  \n",
       "1                   0  \n",
       "\n",
       "[2 rows x 85 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata_init = create_empty_df()\n",
    "metadata_init = data_pre_init.copy()\n",
    "\n",
    "metadata_init['demography_data'] = metadata_init[features_dict['demography']].notnull().any(axis=1).astype(int)\n",
    "metadata_init['dailylog_data'] = metadata_init[features_dict['dailylog']].notnull().any(axis=1).astype(int)\n",
    "metadata_init['lifelog_data'] = metadata_init[features_dict['lifelog']].notnull().any(axis=1).astype(int)\n",
    "metadata_init['questionnaire_data'] = metadata_init[features_dict['questionnaire']].notnull().any(axis=1).astype(int)\n",
    "\n",
    "metadata_init['dtype_n'] = metadata_init['dailylog_data'] + metadata_init['lifelog_data'] + metadata_init['questionnaire_data']\n",
    "move_column(metadata_init, 'dtype_n', 8)\n",
    "\n",
    "add_list = ['dailylog_data', 'lifelog_data', 'questionnaire_data', 'dtype_n']\n",
    "for item in add_list:\n",
    "\tif item not in features_dict['metadata']:\n",
    "\t\tfeatures_dict['metadata'].append(item)\n",
    "del add_list\n",
    "\n",
    "display(metadata_init.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dccf3dc",
   "metadata": {},
   "source": [
    "## Extract Demography Data\n",
    "\n",
    "- All patients within the scraped data were confirmed to have demographic data (`demography_data` = `True`)\n",
    "- as such demography_data will not be included in the `metadata`\n",
    "- demographic features were removed from preprocessed data (`data_pre`)\n",
    "- Demography data was extracted and saved as `demography.csv` to the `output` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efc9a7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All demographic columns are unique for each ID in demo_data.\n",
      "Number of rows in demo_data: 434\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>marriage</th>\n",
       "      <th>job</th>\n",
       "      <th>smkHx</th>\n",
       "      <th>drinkHx</th>\n",
       "      <th>suicideHx</th>\n",
       "      <th>suicide_need</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10007</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PXPN_10008</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PXPN_10009</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PXPN_10010</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  gender  age  marriage  job  smkHx  drinkHx  suicideHx  \\\n",
       "0  PXPN_10006       0   32       0.0  1.0    1.0      1.0        0.0   \n",
       "1  PXPN_10007       1   38       1.0  1.0    0.0      0.0        0.0   \n",
       "2  PXPN_10008       0   38       1.0  0.0    0.0      1.0        0.0   \n",
       "3  PXPN_10009       1   28       0.0  0.0    1.0      0.0        1.0   \n",
       "4  PXPN_10010       1   21       0.0  0.0    1.0      1.0        0.0   \n",
       "\n",
       "   suicide_need  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - (text_utils.py) save_as_csv: Saved panic_demography_data.csv to C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\data\n"
     ]
    }
   ],
   "source": [
    "agg_matrix = [\n",
    "\t('gender_n', 'gender', 'nunique'),\n",
    "\t('age_n', 'age', 'nunique'),\n",
    "\t('marriage_n', 'marriage', 'nunique'),\n",
    "\t('job_n', 'job', 'nunique'),\n",
    "\t('smkHx_n', 'smkHx', 'nunique'),\n",
    "\t('drinkHx_n', 'drinkHx', 'nunique'),\n",
    "\t('suicideHx_n', 'suicideHx', 'nunique'),\n",
    "\t('suicide_need_n', 'suicide_need', 'nunique'),\n",
    "    ('gender', 'gender', 'first'),\n",
    "\t('age', 'age', 'first'),\n",
    "\t('marriage', 'marriage', 'first'),\n",
    "\t('job', 'job', 'first'),\n",
    "\t('smkHx', 'smkHx', 'first'),\n",
    "\t('drinkHx', 'drinkHx', 'first'),\n",
    "\t('suicideHx', 'suicideHx', 'first'),\n",
    "\t('suicide_need', 'suicide_need', 'first'),\n",
    "]\n",
    "demo_data = create_empty_df()\n",
    "demo_data = aggregate_by_column(metadata_init, 'ID', agg_matrix)\n",
    "\n",
    "# check if the length of each unique value is 1\n",
    "non_unique_cols = []\n",
    "for col in features_dict['demography']:\n",
    "\tif demo_data[col+'_n'].apply(lambda x: x > 1).any():\n",
    "\t\tnon_unique_cols.append(col)\n",
    "if non_unique_cols:\n",
    "\traise ValueError(f\"Demographic columns {non_unique_cols} are not unique for each ID in demo_data.\")\n",
    "else:\n",
    "\tprint(\"All demographic columns are unique for each ID in demo_data.\")\n",
    "\n",
    "for col in features_dict['demography']:\n",
    "\tremove_columns(demo_data, [col+'_n'])\n",
    "print(f\"Number of rows in demo_data: {demo_data.shape[0]}\")\n",
    "display(demo_data.head(5))\n",
    "\n",
    "save_as_csv(demo_data, OUTPUT_PATH, f\"panic_demography_data{file_desc}\")\n",
    "\n",
    "# Remove demographic features from data_proc\n",
    "remove_columns(data_pre_init, features_dict['demography'], ignore_missing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd52f179",
   "metadata": {},
   "source": [
    "## Construct Intermediate Metadata\n",
    "- the current `metadata` (`metadata_init`) was filtered to include only columns for identification, added columns for metadata, and labels\n",
    "- the `metadata` was also filtered to get rid of all entries that only have demography data (`dtype_n` = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95b509aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "      <th>dtype_n</th>\n",
       "      <th>panic</th>\n",
       "      <th>severity</th>\n",
       "      <th>panic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SYM1-1-100_2021-03-02</td>\n",
       "      <td>SYM1-1-100</td>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SYM1-1-100_2021-03-03</td>\n",
       "      <td>SYM1-1-100</td>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SYM1-1-100_2021-03-19</td>\n",
       "      <td>SYM1-1-100</td>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>SYM1-1-100_2021-08-12</td>\n",
       "      <td>SYM1-1-100</td>\n",
       "      <td>2021-08-12</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>SYM1-1-103_2021-02-16</td>\n",
       "      <td>SYM1-1-103</td>\n",
       "      <td>2021-02-16</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  entry_id          ID       date dataset  dailylog_data  \\\n",
       "0    SYM1-1-100_2021-03-02  SYM1-1-100 2021-03-02    SYM1              1   \n",
       "1    SYM1-1-100_2021-03-03  SYM1-1-100 2021-03-03    SYM1              1   \n",
       "17   SYM1-1-100_2021-03-19  SYM1-1-100 2021-03-19    SYM1              0   \n",
       "163  SYM1-1-100_2021-08-12  SYM1-1-100 2021-08-12    SYM1              0   \n",
       "165  SYM1-1-103_2021-02-16  SYM1-1-103 2021-02-16    SYM1              0   \n",
       "\n",
       "     lifelog_data  questionnaire_data  dtype_n  panic  severity  panic_label  \n",
       "0               0                   1        2    2.0       4.0            1  \n",
       "1               0                   0        1    2.0       4.0            1  \n",
       "17              1                   0        1    0.0       NaN            0  \n",
       "163             1                   0        1    0.0       NaN            0  \n",
       "165             1                   0        1    0.0       NaN            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata_int = create_empty_df()\n",
    "metadata_int = metadata_init.copy()\n",
    "\n",
    "metadata_int = metadata_int[features_dict['id'] + features_dict['metadata'] + features_dict['label']]\n",
    "move_column(metadata_int, 'severity', -1)\n",
    "move_column(metadata_int, 'panic_label', -1)\n",
    "metadata_int = metadata_int[metadata_int['dtype_n'] > 0]\n",
    "metadata_int = metadata_int[metadata_int['date'].notnull()]\n",
    "display(metadata_int.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c967c9",
   "metadata": {},
   "source": [
    "## Filter Preprocessed Data\n",
    "\n",
    "- the data was filtered to remove entries with only demgraphic data\n",
    "- the removed IDs were checked to see if no relevant entries were discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e29ca52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>bandpower(0.001-0.0005Hz)</th>\n",
       "      <th>bandpower(0.0005-0.0001Hz)</th>\n",
       "      <th>bandpower(0.0001-0.00005Hz)</th>\n",
       "      <th>bandpower(0.00005-0.00001Hz)</th>\n",
       "      <th>HR_acrophase</th>\n",
       "      <th>...</th>\n",
       "      <th>SLT3</th>\n",
       "      <th>SLT4</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>smoking</th>\n",
       "      <th>menstruation</th>\n",
       "      <th>panic</th>\n",
       "      <th>severity</th>\n",
       "      <th>panic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SYM1-1-100_2021-03-02</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>SYM1-1-100</td>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SYM1-1-100_2021-03-03</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>SYM1-1-100</td>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SYM1-1-100_2021-03-19</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>SYM1-1-100</td>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 entry_id dataset          ID       date  alcohol  \\\n",
       "0   SYM1-1-100_2021-03-02    SYM1  SYM1-1-100 2021-03-02      3.0   \n",
       "1   SYM1-1-100_2021-03-03    SYM1  SYM1-1-100 2021-03-03      3.0   \n",
       "17  SYM1-1-100_2021-03-19    SYM1  SYM1-1-100 2021-03-19      NaN   \n",
       "\n",
       "    bandpower(0.001-0.0005Hz)  bandpower(0.0005-0.0001Hz)  \\\n",
       "0                         NaN                         NaN   \n",
       "1                         NaN                         NaN   \n",
       "17                        NaN                         NaN   \n",
       "\n",
       "    bandpower(0.0001-0.00005Hz)  bandpower(0.00005-0.00001Hz)  HR_acrophase  \\\n",
       "0                           NaN                           NaN           NaN   \n",
       "1                           NaN                           NaN           NaN   \n",
       "17                          NaN                           NaN           NaN   \n",
       "\n",
       "    ...  SLT3  SLT4  SLT5  SLT6  total_sleep  smoking  menstruation  panic  \\\n",
       "0   ...   NaN   NaN   NaN   NaN          NaN      NaN           NaN    2.0   \n",
       "1   ...   NaN   NaN   NaN   NaN          NaN      NaN           NaN    2.0   \n",
       "17  ...   0.0   0.0   0.0   0.0          8.0      NaN           NaN    0.0   \n",
       "\n",
       "    severity  panic_label  \n",
       "0        4.0            1  \n",
       "1        4.0            1  \n",
       "17       NaN            0  \n",
       "\n",
       "[3 rows x 72 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_pre = create_empty_df()\n",
    "data_pre = data_pre_init.copy()\n",
    "\n",
    "# Filter data_proc to keep only rows with entry IDs present in metadata_int\n",
    "metadata_int_unique_ids = metadata_int['entry_id'].unique()\n",
    "data_pre = data_pre[data_pre['entry_id'].isin(metadata_int_unique_ids)]\n",
    "\n",
    "# remove rows with null dates\n",
    "data_pre = data_pre[data_pre['date'].notnull()]\n",
    "\n",
    "# Move label columns to the end\n",
    "move_column(data_pre, 'panic', -1)\n",
    "move_column(data_pre, 'severity', -1)\n",
    "move_column(data_pre, 'panic_label', -1)\n",
    "\n",
    "display(data_pre.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cc84e1",
   "metadata": {},
   "source": [
    "## üíæ | Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2daa5322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - (text_utils.py) save_as_csv: Saved panic_pre_data.csv to C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>bandpower(0.001-0.0005Hz)</th>\n",
       "      <th>bandpower(0.0005-0.0001Hz)</th>\n",
       "      <th>bandpower(0.0001-0.00005Hz)</th>\n",
       "      <th>bandpower(0.00005-0.00001Hz)</th>\n",
       "      <th>HR_acrophase</th>\n",
       "      <th>...</th>\n",
       "      <th>SLT3</th>\n",
       "      <th>SLT4</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>smoking</th>\n",
       "      <th>menstruation</th>\n",
       "      <th>panic</th>\n",
       "      <th>severity</th>\n",
       "      <th>panic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SYM1-1-100_2021-03-02</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>SYM1-1-100</td>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SYM1-1-100_2021-03-03</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>SYM1-1-100</td>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SYM1-1-100_2021-03-19</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>SYM1-1-100</td>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 entry_id dataset          ID       date  alcohol  \\\n",
       "0   SYM1-1-100_2021-03-02    SYM1  SYM1-1-100 2021-03-02      3.0   \n",
       "1   SYM1-1-100_2021-03-03    SYM1  SYM1-1-100 2021-03-03      3.0   \n",
       "17  SYM1-1-100_2021-03-19    SYM1  SYM1-1-100 2021-03-19      NaN   \n",
       "\n",
       "    bandpower(0.001-0.0005Hz)  bandpower(0.0005-0.0001Hz)  \\\n",
       "0                         NaN                         NaN   \n",
       "1                         NaN                         NaN   \n",
       "17                        NaN                         NaN   \n",
       "\n",
       "    bandpower(0.0001-0.00005Hz)  bandpower(0.00005-0.00001Hz)  HR_acrophase  \\\n",
       "0                           NaN                           NaN           NaN   \n",
       "1                           NaN                           NaN           NaN   \n",
       "17                          NaN                           NaN           NaN   \n",
       "\n",
       "    ...  SLT3  SLT4  SLT5  SLT6  total_sleep  smoking  menstruation  panic  \\\n",
       "0   ...   NaN   NaN   NaN   NaN          NaN      NaN           NaN    2.0   \n",
       "1   ...   NaN   NaN   NaN   NaN          NaN      NaN           NaN    2.0   \n",
       "17  ...   0.0   0.0   0.0   0.0          8.0      NaN           NaN    0.0   \n",
       "\n",
       "    severity  panic_label  \n",
       "0        4.0            1  \n",
       "1        4.0            1  \n",
       "17       NaN            0  \n",
       "\n",
       "[3 rows x 72 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Total entries in original:  29143\n",
      "    SYM entries: 28163\n",
      "    PXPN entries: 980\n",
      "Number of unique IDs in original: 434\n",
      "    SYM IDs:  400\n",
      "    PXPN IDs:  34\n",
      "Number of panic events (panic_label = 1): 866\n",
      "--------------------------------------------------------\n",
      "Total entries in filtered:  19507\n",
      "    SYM entries: 18687\n",
      "    PXPN entries: 820\n",
      "Number of unique IDs in filtered: 279\n",
      "    SYM IDs:  245\n",
      "    PXPN IDs:  34\n",
      "Number of panic events (panic_label = 1): 866\n"
     ]
    }
   ],
   "source": [
    "# save data_pre to CSV\n",
    "save_as_csv(data_pre, OUTPUT_PATH, f\"panic_pre_data{file_desc}\")\n",
    "\n",
    "display(data_pre.head(3))\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"Total entries in original: \", data_pre_init.shape[0])\n",
    "sym1_n = data_pre_init[data_pre_init['dataset'] == 'SYM1'].shape[0]\n",
    "sym2_n = data_pre_init[data_pre_init['dataset'] == 'SYM2'].shape[0]\n",
    "print(\"    SYM entries:\", sym1_n+sym2_n)\n",
    "print(\"    PXPN entries:\", data_pre_init[data_pre_init['dataset'] == 'PXPN'].shape[0])\n",
    "print(\"Number of unique IDs in original:\", len(data_pre_init['ID'].unique()))\n",
    "# find the unique IDs for SYM1 and SYM2\n",
    "sym1_ids = data_pre_init[data_pre_init['dataset'] == 'SYM1']['ID'].unique()\n",
    "sym2_ids = data_pre_init[data_pre_init['dataset'] == 'SYM2']['ID'].unique()\n",
    "print(\"    SYM IDs: \", len(sym1_ids)+len(sym2_ids))\n",
    "print(\"    PXPN IDs: \", len(data_pre_init[data_pre_init['dataset'] == 'PXPN']['ID'].unique()))\n",
    "print(\"Number of panic events (panic_label = 1):\", data_pre_init[data_pre_init['panic_label'] == 1].shape[0])\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"Total entries in filtered: \", data_pre.shape[0])\n",
    "sym1_n = data_pre[data_pre['dataset'] == 'SYM1'].shape[0]\n",
    "sym2_n = data_pre[data_pre['dataset'] == 'SYM2'].shape[0]\n",
    "print(\"    SYM entries:\", sym1_n+sym2_n)\n",
    "print(\"    PXPN entries:\", data_pre[data_pre['dataset'] == 'PXPN'].shape[0])\n",
    "print(\"Number of unique IDs in filtered:\", len(data_pre['ID'].unique()))\n",
    "# find the unique IDs for SYM1 and SYM2\n",
    "sym1_ids = data_pre[data_pre['dataset'] == 'SYM1']['ID'].unique()\n",
    "sym2_ids = data_pre[data_pre['dataset'] == 'SYM2']['ID'].unique()\n",
    "print(\"    SYM IDs: \", len(sym1_ids)+len(sym2_ids))\n",
    "print(\"    PXPN IDs: \", len(data_pre[data_pre['dataset'] == 'PXPN']['ID'].unique()))\n",
    "print(\"Number of panic events (panic_label = 1):\", data_pre[data_pre['panic_label'] == 1].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7e6270",
   "metadata": {},
   "source": [
    "# üìñ | Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a16be3",
   "metadata": {},
   "source": [
    "**Description**\n",
    "- `entry_id`: ID for each entry `'ID'_'date'`\n",
    "- `ID`: ID for each patient\n",
    "- `date`: logging date of each entry\n",
    "- `dataset`: source of entry (`SYM1`, `SYM2`, `PXPN`)\n",
    "- `dailylog_data`: whether daily log data exists in the entry (`boolean`)\n",
    "- `lifelog_data`: whether life log data exists in the entry (`boolean`)\n",
    "- `questionnaire_data`: whether questionnaire data exists in the entry (`boolean`)\n",
    "- `dtype_n`: how many of the 3 `state` groups exists in the entry (`int`)\n",
    "- `diary_data`: whether panic diary data exists in the entry (`boolean`)\n",
    "- `dbp`: number of consecutive days prior to panic. i.e. panic day = 0; 1 day prior = 1; etc. (up to 3)\n",
    "- `n_prior_data`: number of existing consecutive prior (days) entries\n",
    "- `ref_event_id`: the `entry_id` to which days before panic (`dbp`) is referencing\n",
    "- `valid_entry_3`: whether the entry has 3 consecutive days of prior data (`n_prior_data`)\n",
    "- `valid_entry_2`: whether the entry has 2 consecutive days of prior data (`n_prior_data`)\n",
    "- `valid_entry_1`: whether the entry has 1 consecutive days of prior data (`n_prior_data`)\n",
    "- `panic_label`: whether a panic occured in the entry (`boolean`)\n",
    "- `severity`: severity of the panic (1 ~ 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277e7f97",
   "metadata": {},
   "source": [
    "## Calculate Days Before Panic (``dbp``) and Prior Consecutive Days (``n_prior_data``)\n",
    "\n",
    "- calculate the consecutive 'days before panic' (`dbp`):\n",
    "  - day when panic occured -> `dbp` = 0\n",
    "  - 1 day before panic -> `dbp` = 1\n",
    "  - 2 day before panic -> `dbp` = 2\n",
    "  - 3 day before panic -> `dbp` = 3 (etc)\n",
    "  - stop calculating at a set limit (`delta_days`) or if a panic occurred within the limit\n",
    "- calculate the number of existing prior consecutive (days) entries (`n_prior_data`) (Default: 3)\n",
    "  - stop calculating at a certain limit (`lookback_limit`) (Default: 7)\n",
    "\n",
    "> May take ~ 1 to 2 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f133fed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 100.00% complete\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\utils\\preproc_utils.py:50: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['n_prior_data'] = df['n_prior_data'].fillna(0).astype(int)\n"
     ]
    }
   ],
   "source": [
    "from utils.preproc_utils import process_calculate_days_before_panic\n",
    "\n",
    "metadata_calc = create_empty_df()\n",
    "metadata_calc = metadata_int.copy()\n",
    "\n",
    "metadata_calc['n_prior_data']    = None\n",
    "metadata_calc['ref_event_id']    = None\n",
    "metadata_calc['dbp'] = None  # days before panic\n",
    "move_column(metadata_calc, 'panic_label', -1)\n",
    "move_column(metadata_calc, 'severity', -1)\n",
    "metadata_calc.sort_values(by=['ID', 'date'], ascending=False, inplace=True)\n",
    "\n",
    "d_days = 3\n",
    "l_back_lim = 7\n",
    "\n",
    "metadata_int = process_calculate_days_before_panic(metadata_calc, delta_days=d_days, lookback_limit=l_back_lim)\n",
    "\n",
    "# update features_dict with metadata columns\n",
    "if 'ref_event_id' not in features_dict['metadata']:\n",
    "\tfeatures_dict['metadata'].append('ref_event_id')\n",
    "if 'n_prior_data' not in features_dict['metadata']:\n",
    "\tfeatures_dict['metadata'].append('n_prior_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded18a26",
   "metadata": {},
   "source": [
    "## Find Valid Entries\n",
    "- add `valid_entry_3`: whether the entry has 3 consecutive days of prior data (`n_prior_data`)\n",
    "- add `valid_entry_2`: whether the entry has 2 consecutive days of prior data (`n_prior_data`)\n",
    "- add `valid_entry_1`: whether the entry has 1 consecutive days of prior data (`n_prior_data`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3cb3f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "      <th>dtype_n</th>\n",
       "      <th>panic</th>\n",
       "      <th>n_prior_data</th>\n",
       "      <th>dbp</th>\n",
       "      <th>valid_entry_3</th>\n",
       "      <th>valid_entry_2</th>\n",
       "      <th>valid_entry_1</th>\n",
       "      <th>ref_event_id</th>\n",
       "      <th>panic_label</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28162</th>\n",
       "      <td>SYM2-1-96_2021-08-04</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28161</th>\n",
       "      <td>SYM2-1-96_2021-08-03</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28160</th>\n",
       "      <td>SYM2-1-96_2021-08-02</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-02</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   entry_id         ID       date dataset  dailylog_data  \\\n",
       "28162  SYM2-1-96_2021-08-04  SYM2-1-96 2021-08-04    SYM2              0   \n",
       "28161  SYM2-1-96_2021-08-03  SYM2-1-96 2021-08-03    SYM2              0   \n",
       "28160  SYM2-1-96_2021-08-02  SYM2-1-96 2021-08-02    SYM2              0   \n",
       "\n",
       "       lifelog_data  questionnaire_data  dtype_n  panic  n_prior_data   dbp  \\\n",
       "28162             1                   0        1    0.0             2  None   \n",
       "28161             1                   0        1    0.0             1  None   \n",
       "28160             1                   0        1    0.0             0  None   \n",
       "\n",
       "       valid_entry_3  valid_entry_2  valid_entry_1 ref_event_id  panic_label  \\\n",
       "28162              0              1              1         None            0   \n",
       "28161              0              0              1         None            0   \n",
       "28160              0              0              0         None            0   \n",
       "\n",
       "       severity  \n",
       "28162       NaN  \n",
       "28161       NaN  \n",
       "28160       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata_int['valid_entry_3'] = metadata_int.apply(\n",
    "\tlambda row: 1 if row['n_prior_data'] >= 3 else 0,\n",
    "\taxis=1\n",
    ")\n",
    "metadata_int['valid_entry_2'] = metadata_int.apply(\n",
    "\tlambda row: 1 if row['n_prior_data'] >= 2 else 0,\n",
    "\taxis=1\n",
    ")\n",
    "metadata_int['valid_entry_1'] = metadata_int.apply(\n",
    "\tlambda row: 1 if row['n_prior_data'] >= 1 else 0,\n",
    "\taxis=1\n",
    ")\n",
    "move_column(metadata_int, 'ref_event_id', -1)\n",
    "move_column(metadata_int, 'panic_label', -1)\n",
    "move_column(metadata_int, 'severity', -1)\n",
    "display(metadata_int.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "262ff9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for panic labeling consistency\n",
    "# Panic events should have dbp = 0, panic = 2\n",
    "test_panic_dbpnot0 = metadata_int[(metadata_int['panic'] == 2) & (metadata_int['dbp'] != 0)]['entry_id'].unique()\n",
    "test_panic_dbp1 = metadata_int[(metadata_int['panic'] == 1) & (metadata_int['dbp'] != 1)]['entry_id'].unique()\n",
    "if len(test_panic_dbpnot0) != 0:\n",
    "\traise ValueError(\"Entries found with dbp != 0 for panic events. Please check the data.\")\n",
    "if len(test_panic_dbp1) != 0:\n",
    "\traise ValueError(\"Entries found with dbp != 1 for panic = 1. Please check the data.\")\n",
    "del test_panic_dbpnot0, test_panic_dbp1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dea337",
   "metadata": {},
   "source": [
    "## üíæ | Save Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f69eeb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - (text_utils.py) save_as_csv: Saved panic_metadata.csv to C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\data\n",
      "DEBUG - (json_utils.py) save_dict_to_file: Dictionary saved successfully to C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\data\\panic_features_dict.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "      <th>dtype_n</th>\n",
       "      <th>panic</th>\n",
       "      <th>n_prior_data</th>\n",
       "      <th>dbp</th>\n",
       "      <th>valid_entry_3</th>\n",
       "      <th>valid_entry_2</th>\n",
       "      <th>valid_entry_1</th>\n",
       "      <th>ref_event_id</th>\n",
       "      <th>panic_label</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28162</th>\n",
       "      <td>SYM2-1-96_2021-08-04</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28161</th>\n",
       "      <td>SYM2-1-96_2021-08-03</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28160</th>\n",
       "      <td>SYM2-1-96_2021-08-02</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-02</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   entry_id         ID       date dataset  dailylog_data  \\\n",
       "28162  SYM2-1-96_2021-08-04  SYM2-1-96 2021-08-04    SYM2              0   \n",
       "28161  SYM2-1-96_2021-08-03  SYM2-1-96 2021-08-03    SYM2              0   \n",
       "28160  SYM2-1-96_2021-08-02  SYM2-1-96 2021-08-02    SYM2              0   \n",
       "\n",
       "       lifelog_data  questionnaire_data  dtype_n  panic  n_prior_data   dbp  \\\n",
       "28162             1                   0        1    0.0             2  None   \n",
       "28161             1                   0        1    0.0             1  None   \n",
       "28160             1                   0        1    0.0             0  None   \n",
       "\n",
       "       valid_entry_3  valid_entry_2  valid_entry_1 ref_event_id  panic_label  \\\n",
       "28162              0              1              1         None            0   \n",
       "28161              0              0              1         None            0   \n",
       "28160              0              0              0         None            0   \n",
       "\n",
       "       severity  \n",
       "28162       NaN  \n",
       "28161       NaN  \n",
       "28160       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata = create_empty_df()\n",
    "metadata = metadata_int.copy()\n",
    "\n",
    "save_as_csv(metadata, OUTPUT_PATH, f\"panic_metadata{file_desc}\")\n",
    "save_dict_to_file(features_dict, OUT_FILE_PATH, \"panic_features_dict\")\n",
    "\n",
    "display(metadata.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "489556bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - (json_utils.py) save_dict_to_file: Dictionary saved successfully to C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\_tmp\\current_config.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/cyshi/OneDrive/Documents/GitHub/Panic-Project-CYS/_tmp/current_config.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dict_to_file(current_config, OUT_PATH, \"current_config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef5553a",
   "metadata": {},
   "source": [
    "# üîç | Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c518179e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped Unique IDs: 434 -> 279 after preprocessing. discarded 155 IDs.\n",
      "Scraped Entries: 29143 -> 19507 after preprocessing. discarded 9636 entries.\n",
      "Scraped Panic Events: 866 -> 866 after preprocessing. discarded 0 panic events.\n"
     ]
    }
   ],
   "source": [
    "scraped_unique_ids = scraped_data['ID'].unique()\n",
    "data_pre_unique_ids = data_pre['ID'].unique()\n",
    "print(f\"Scraped Unique IDs: {len(scraped_unique_ids)} -> {len(data_pre_unique_ids)} after preprocessing. discarded {len(scraped_unique_ids) - len(data_pre_unique_ids)} IDs.\")\n",
    "scraped_data_n = len(scraped_data)\n",
    "data_pre_entry_ids = data_pre['entry_id'].unique()\n",
    "print(f\"Scraped Entries: {scraped_data_n} -> {len(data_pre_entry_ids)} after preprocessing. discarded {scraped_data_n - len(data_pre_entry_ids)} entries.\")\n",
    "scraped_panic_events = scraped_data[scraped_data['panic'] == 2].shape[0]\n",
    "data_pre_panic_events = data_pre[data_pre['panic'] == 2].shape[0]\n",
    "data_pre_dbp_panic_events = metadata[metadata['dbp'] == 0].shape[0]\n",
    "data_pre_label_panic_events = data_pre[data_pre['panic_label'] == 1].shape[0]\n",
    "if data_pre_dbp_panic_events != data_pre_panic_events:\n",
    "\traise ValueError(\"Mismatch in panic events count: dbp panic events and panic events do not match.\")\n",
    "if data_pre_label_panic_events != data_pre_panic_events:\n",
    "\traise ValueError(\"Mismatch in panic events count: label panic events and panic events do not match.\")\n",
    "print(f\"Scraped Panic Events: {scraped_panic_events} -> {data_pre_panic_events} after preprocessing. discarded {scraped_panic_events - data_pre_panic_events} panic events.\")\n",
    "\n",
    "if save_removed_data:\n",
    "\t# find the entry_ids in scraped_data that are not in pre_data\n",
    "\tmissing_entry_ids = set(data_pre_init['entry_id']) - set(data_pre['entry_id'])\n",
    "\tif len(missing_entry_ids) > 0:\n",
    "\t\tlogging.info(f\"Saving removed data... {len(missing_entry_ids)} missing entry IDs\")\n",
    "\t\tremoved_data = data_pre_init[data_pre_init['entry_id'].isin(missing_entry_ids)]\n",
    "\t\tsave_as_csv(removed_data, TMP_PATH, f\"removed_data_{scraped_data_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adb68775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of daily log entries: 14968 / 19507 (76.73%)\n",
      "Total number of life log entries: 12445 / 19507 (63.80%)\n",
      "Total number of questionnaire entries: 638 / 19507 (3.27%)\n"
     ]
    }
   ],
   "source": [
    "data_pre_entry_ids = data_pre['entry_id'].unique()\n",
    "print(f\"Total number of daily log entries: {metadata[metadata['dailylog_data'] == 1].shape[0]} / {len(data_pre_entry_ids)} ({metadata[metadata['dailylog_data'] == 1].shape[0] / len(data_pre_entry_ids) * 100:.2f}%)\")\n",
    "print(f\"Total number of life log entries: {metadata[metadata['lifelog_data'] == 1].shape[0]} / {len(data_pre_entry_ids)} ({metadata[metadata['lifelog_data'] == 1].shape[0] / len(data_pre_entry_ids) * 100:.2f}%)\")\n",
    "print(f\"Total number of questionnaire entries: {metadata[metadata['questionnaire_data'] == 1].shape[0]} / {len(data_pre_entry_ids)} ({metadata[metadata['questionnaire_data'] == 1].shape[0] / len(data_pre_entry_ids) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28531a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of panic patients: 110\n",
      "Total number of entries with dbp = 1 (panic = 1): 462 / 19507 (2.37%)\n",
      "Total number of entries with dbp = 2: 349 / 19507 (1.79%)\n",
      "Total number of entries with dbp = 3: 293 / 19507 (1.50%)\n",
      "Total number of entries with panic = 0: 18179 / 19507 (93.19%)\n"
     ]
    }
   ],
   "source": [
    "panic_patients = metadata[metadata['panic'] == 2]['ID'].unique()\n",
    "print(f\"Total number of panic patients: {len(panic_patients)}\")\n",
    "panic_1_entries = metadata[metadata['panic'] == 1].shape[0]\n",
    "dbp_1_entries = metadata[metadata['dbp'] == 1].shape[0]\n",
    "if panic_1_entries != dbp_1_entries:\n",
    "\traise ValueError(\"Mismatch in panic entries count: panic entries and dbp entries do not match.\")\n",
    "if len(metadata) != len(data_pre):\n",
    "    raise ValueError(\"Error\")\n",
    "print(f\"Total number of entries with dbp = 1 (panic = 1): {panic_1_entries} / {len(data_pre_entry_ids)} ({panic_1_entries / len(data_pre_entry_ids) * 100:.2f}%)\")\n",
    "dbp_2_entries = metadata[metadata['dbp'] == 2].shape[0]\n",
    "print(f\"Total number of entries with dbp = 2: {dbp_2_entries} / {len(data_pre_entry_ids)} ({dbp_2_entries / len(data_pre_entry_ids) * 100:.2f}%)\")\n",
    "dbp_3_entries = metadata[metadata['dbp'] == 3].shape[0]\n",
    "print(f\"Total number of entries with dbp = 3: {dbp_3_entries} / {len(data_pre_entry_ids)} ({dbp_3_entries / len(data_pre_entry_ids) * 100:.2f}%)\")\n",
    "panic_0_entries = metadata[metadata['panic'] == 0].shape[0]\n",
    "print(f\"Total number of entries with panic = 0: {panic_0_entries} / {len(data_pre_entry_ids)} ({panic_0_entries / len(data_pre_entry_ids) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf6ff081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped data shape: (29143, 77)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>panic</th>\n",
       "      <th>gender</th>\n",
       "      <th>marriage</th>\n",
       "      <th>job</th>\n",
       "      <th>smkHx</th>\n",
       "      <th>drinkHx</th>\n",
       "      <th>suicideHx</th>\n",
       "      <th>suicide_need</th>\n",
       "      <th>...</th>\n",
       "      <th>PHQ_9</th>\n",
       "      <th>SLT1</th>\n",
       "      <th>SLT2</th>\n",
       "      <th>SLT3</th>\n",
       "      <th>SLT4</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>smoking</th>\n",
       "      <th>menstruation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SYM1-1-100</td>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SYM1-1-100</td>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID       date  panic  gender  marriage  job  smkHx  drinkHx  \\\n",
       "0  SYM1-1-100 2021-03-02    2.0       1       0.0  0.0    0.0      0.0   \n",
       "1  SYM1-1-100 2021-03-03    2.0       1       0.0  0.0    0.0      0.0   \n",
       "\n",
       "   suicideHx  suicide_need  ...  PHQ_9  SLT1  SLT2  SLT3  SLT4  SLT5  SLT6  \\\n",
       "0        0.0           0.0  ...    NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1        0.0           0.0  ...    NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "   total_sleep  smoking  menstruation  \n",
       "0          NaN      NaN           NaN  \n",
       "1          NaN      NaN           NaN  \n",
       "\n",
       "[2 rows x 77 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessed shape: (19507, 72)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>bandpower(0.001-0.0005Hz)</th>\n",
       "      <th>bandpower(0.0005-0.0001Hz)</th>\n",
       "      <th>bandpower(0.0001-0.00005Hz)</th>\n",
       "      <th>bandpower(0.00005-0.00001Hz)</th>\n",
       "      <th>HR_acrophase</th>\n",
       "      <th>...</th>\n",
       "      <th>SLT3</th>\n",
       "      <th>SLT4</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>smoking</th>\n",
       "      <th>menstruation</th>\n",
       "      <th>panic</th>\n",
       "      <th>severity</th>\n",
       "      <th>panic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SYM1-1-100_2021-03-02</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>SYM1-1-100</td>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SYM1-1-100_2021-03-03</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>SYM1-1-100</td>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                entry_id dataset          ID       date  alcohol  \\\n",
       "0  SYM1-1-100_2021-03-02    SYM1  SYM1-1-100 2021-03-02      3.0   \n",
       "1  SYM1-1-100_2021-03-03    SYM1  SYM1-1-100 2021-03-03      3.0   \n",
       "\n",
       "   bandpower(0.001-0.0005Hz)  bandpower(0.0005-0.0001Hz)  \\\n",
       "0                        NaN                         NaN   \n",
       "1                        NaN                         NaN   \n",
       "\n",
       "   bandpower(0.0001-0.00005Hz)  bandpower(0.00005-0.00001Hz)  HR_acrophase  \\\n",
       "0                          NaN                           NaN           NaN   \n",
       "1                          NaN                           NaN           NaN   \n",
       "\n",
       "   ...  SLT3  SLT4  SLT5  SLT6  total_sleep  smoking  menstruation  panic  \\\n",
       "0  ...   NaN   NaN   NaN   NaN          NaN      NaN           NaN    2.0   \n",
       "1  ...   NaN   NaN   NaN   NaN          NaN      NaN           NaN    2.0   \n",
       "\n",
       "   severity  panic_label  \n",
       "0       4.0            1  \n",
       "1       4.0            1  \n",
       "\n",
       "[2 rows x 72 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata shape: (19507, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "      <th>dtype_n</th>\n",
       "      <th>panic</th>\n",
       "      <th>n_prior_data</th>\n",
       "      <th>dbp</th>\n",
       "      <th>valid_entry_3</th>\n",
       "      <th>valid_entry_2</th>\n",
       "      <th>valid_entry_1</th>\n",
       "      <th>ref_event_id</th>\n",
       "      <th>panic_label</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28162</th>\n",
       "      <td>SYM2-1-96_2021-08-04</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28161</th>\n",
       "      <td>SYM2-1-96_2021-08-03</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   entry_id         ID       date dataset  dailylog_data  \\\n",
       "28162  SYM2-1-96_2021-08-04  SYM2-1-96 2021-08-04    SYM2              0   \n",
       "28161  SYM2-1-96_2021-08-03  SYM2-1-96 2021-08-03    SYM2              0   \n",
       "\n",
       "       lifelog_data  questionnaire_data  dtype_n  panic  n_prior_data   dbp  \\\n",
       "28162             1                   0        1    0.0             2  None   \n",
       "28161             1                   0        1    0.0             1  None   \n",
       "\n",
       "       valid_entry_3  valid_entry_2  valid_entry_1 ref_event_id  panic_label  \\\n",
       "28162              0              1              1         None            0   \n",
       "28161              0              0              1         None            0   \n",
       "\n",
       "       severity  \n",
       "28162       NaN  \n",
       "28161       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Scraped data shape:\", scraped_data.shape)\n",
    "display(scraped_data.head(2))\n",
    "print(\"Data preprocessed shape:\", data_pre.shape)\n",
    "display(data_pre.head(2))\n",
    "print(\"Metadata shape:\", metadata.shape)\n",
    "display(metadata.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a41c8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of panic entries without severity: 55\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>bandpower(0.001-0.0005Hz)</th>\n",
       "      <th>bandpower(0.0005-0.0001Hz)</th>\n",
       "      <th>bandpower(0.0001-0.00005Hz)</th>\n",
       "      <th>bandpower(0.00005-0.00001Hz)</th>\n",
       "      <th>HR_acrophase</th>\n",
       "      <th>...</th>\n",
       "      <th>SLT3</th>\n",
       "      <th>SLT4</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>smoking</th>\n",
       "      <th>menstruation</th>\n",
       "      <th>panic</th>\n",
       "      <th>severity</th>\n",
       "      <th>panic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29002</th>\n",
       "      <td>PXPN_10041_2025-04-24</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10041</td>\n",
       "      <td>2025-04-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29008</th>\n",
       "      <td>PXPN_10041_2025-04-30</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10041</td>\n",
       "      <td>2025-04-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29009</th>\n",
       "      <td>PXPN_10041_2025-05-01</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10041</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29012</th>\n",
       "      <td>PXPN_10041_2025-05-04</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10041</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29016</th>\n",
       "      <td>PXPN_10041_2025-05-08</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10041</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29020</th>\n",
       "      <td>PXPN_10041_2025-05-12</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10041</td>\n",
       "      <td>2025-05-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29021</th>\n",
       "      <td>PXPN_10041_2025-05-13</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10041</td>\n",
       "      <td>2025-05-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29028</th>\n",
       "      <td>PXPN_10041_2025-05-20</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10041</td>\n",
       "      <td>2025-05-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29032</th>\n",
       "      <td>PXPN_10042_2025-05-29</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10042</td>\n",
       "      <td>2025-05-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29034</th>\n",
       "      <td>PXPN_10042_2025-05-31</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10042</td>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29035</th>\n",
       "      <td>PXPN_10042_2025-06-01</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10042</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29047</th>\n",
       "      <td>PXPN_10042_2025-06-13</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10042</td>\n",
       "      <td>2025-06-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29048</th>\n",
       "      <td>PXPN_10042_2025-06-14</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10042</td>\n",
       "      <td>2025-06-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29049</th>\n",
       "      <td>PXPN_10042_2025-06-15</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10042</td>\n",
       "      <td>2025-06-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29053</th>\n",
       "      <td>PXPN_10042_2025-06-19</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10042</td>\n",
       "      <td>2025-06-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29054</th>\n",
       "      <td>PXPN_10042_2025-06-20</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10042</td>\n",
       "      <td>2025-06-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29055</th>\n",
       "      <td>PXPN_10042_2025-06-21</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10042</td>\n",
       "      <td>2025-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29059</th>\n",
       "      <td>PXPN_10043_2025-05-28</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10043</td>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29060</th>\n",
       "      <td>PXPN_10043_2025-05-29</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10043</td>\n",
       "      <td>2025-05-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29061</th>\n",
       "      <td>PXPN_10043_2025-05-30</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10043</td>\n",
       "      <td>2025-05-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29063</th>\n",
       "      <td>PXPN_10043_2025-06-01</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10043</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29064</th>\n",
       "      <td>PXPN_10043_2025-06-02</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10043</td>\n",
       "      <td>2025-06-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29065</th>\n",
       "      <td>PXPN_10043_2025-06-03</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10043</td>\n",
       "      <td>2025-06-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29068</th>\n",
       "      <td>PXPN_10043_2025-06-06</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10043</td>\n",
       "      <td>2025-06-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29069</th>\n",
       "      <td>PXPN_10043_2025-06-07</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10043</td>\n",
       "      <td>2025-06-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29070</th>\n",
       "      <td>PXPN_10043_2025-06-08</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10043</td>\n",
       "      <td>2025-06-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29071</th>\n",
       "      <td>PXPN_10043_2025-06-09</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10043</td>\n",
       "      <td>2025-06-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29072</th>\n",
       "      <td>PXPN_10043_2025-06-10</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10043</td>\n",
       "      <td>2025-06-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29073</th>\n",
       "      <td>PXPN_10043_2025-06-11</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10043</td>\n",
       "      <td>2025-06-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29074</th>\n",
       "      <td>PXPN_10043_2025-06-12</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10043</td>\n",
       "      <td>2025-06-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29075</th>\n",
       "      <td>PXPN_10043_2025-06-13</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10043</td>\n",
       "      <td>2025-06-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29076</th>\n",
       "      <td>PXPN_10043_2025-06-14</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10043</td>\n",
       "      <td>2025-06-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29077</th>\n",
       "      <td>PXPN_10043_2025-06-15</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10043</td>\n",
       "      <td>2025-06-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29078</th>\n",
       "      <td>PXPN_10043_2025-06-16</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10043</td>\n",
       "      <td>2025-06-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29080</th>\n",
       "      <td>PXPN_10043_2025-06-18</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10043</td>\n",
       "      <td>2025-06-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29081</th>\n",
       "      <td>PXPN_10043_2025-06-19</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10043</td>\n",
       "      <td>2025-06-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29082</th>\n",
       "      <td>PXPN_10043_2025-06-20</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10043</td>\n",
       "      <td>2025-06-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29083</th>\n",
       "      <td>PXPN_10043_2025-06-21</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10043</td>\n",
       "      <td>2025-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29084</th>\n",
       "      <td>PXPN_10043_2025-06-22</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10043</td>\n",
       "      <td>2025-06-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29086</th>\n",
       "      <td>PXPN_10043_2025-06-24</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10043</td>\n",
       "      <td>2025-06-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29099</th>\n",
       "      <td>PXPN_10044_2025-06-09</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10044</td>\n",
       "      <td>2025-06-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29100</th>\n",
       "      <td>PXPN_10044_2025-06-10</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10044</td>\n",
       "      <td>2025-06-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29105</th>\n",
       "      <td>PXPN_10044_2025-06-15</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10044</td>\n",
       "      <td>2025-06-15</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29109</th>\n",
       "      <td>PXPN_10044_2025-06-19</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10044</td>\n",
       "      <td>2025-06-19</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29111</th>\n",
       "      <td>PXPN_10044_2025-06-21</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10044</td>\n",
       "      <td>2025-06-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29116</th>\n",
       "      <td>PXPN_10046_2025-06-10</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10046</td>\n",
       "      <td>2025-06-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29117</th>\n",
       "      <td>PXPN_10046_2025-06-11</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10046</td>\n",
       "      <td>2025-06-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29119</th>\n",
       "      <td>PXPN_10046_2025-06-13</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10046</td>\n",
       "      <td>2025-06-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29120</th>\n",
       "      <td>PXPN_10046_2025-06-14</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10046</td>\n",
       "      <td>2025-06-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29121</th>\n",
       "      <td>PXPN_10046_2025-06-15</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10046</td>\n",
       "      <td>2025-06-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29126</th>\n",
       "      <td>PXPN_10046_2025-06-20</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10046</td>\n",
       "      <td>2025-06-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29128</th>\n",
       "      <td>PXPN_10046_2025-06-22</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10046</td>\n",
       "      <td>2025-06-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29129</th>\n",
       "      <td>PXPN_10046_2025-06-23</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10046</td>\n",
       "      <td>2025-06-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29138</th>\n",
       "      <td>PXPN_10046_2025-07-02</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10046</td>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29142</th>\n",
       "      <td>PXPN_10046_2025-07-06</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10046</td>\n",
       "      <td>2025-07-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55 rows √ó 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    entry_id dataset          ID       date  alcohol  \\\n",
       "29002  PXPN_10041_2025-04-24    PXPN  PXPN_10041 2025-04-24      NaN   \n",
       "29008  PXPN_10041_2025-04-30    PXPN  PXPN_10041 2025-04-30      NaN   \n",
       "29009  PXPN_10041_2025-05-01    PXPN  PXPN_10041 2025-05-01      NaN   \n",
       "29012  PXPN_10041_2025-05-04    PXPN  PXPN_10041 2025-05-04      NaN   \n",
       "29016  PXPN_10041_2025-05-08    PXPN  PXPN_10041 2025-05-08      NaN   \n",
       "29020  PXPN_10041_2025-05-12    PXPN  PXPN_10041 2025-05-12      NaN   \n",
       "29021  PXPN_10041_2025-05-13    PXPN  PXPN_10041 2025-05-13      NaN   \n",
       "29028  PXPN_10041_2025-05-20    PXPN  PXPN_10041 2025-05-20      NaN   \n",
       "29032  PXPN_10042_2025-05-29    PXPN  PXPN_10042 2025-05-29      NaN   \n",
       "29034  PXPN_10042_2025-05-31    PXPN  PXPN_10042 2025-05-31      NaN   \n",
       "29035  PXPN_10042_2025-06-01    PXPN  PXPN_10042 2025-06-01      NaN   \n",
       "29047  PXPN_10042_2025-06-13    PXPN  PXPN_10042 2025-06-13      NaN   \n",
       "29048  PXPN_10042_2025-06-14    PXPN  PXPN_10042 2025-06-14      NaN   \n",
       "29049  PXPN_10042_2025-06-15    PXPN  PXPN_10042 2025-06-15      NaN   \n",
       "29053  PXPN_10042_2025-06-19    PXPN  PXPN_10042 2025-06-19      NaN   \n",
       "29054  PXPN_10042_2025-06-20    PXPN  PXPN_10042 2025-06-20      NaN   \n",
       "29055  PXPN_10042_2025-06-21    PXPN  PXPN_10042 2025-06-21      NaN   \n",
       "29059  PXPN_10043_2025-05-28    PXPN  PXPN_10043 2025-05-28      NaN   \n",
       "29060  PXPN_10043_2025-05-29    PXPN  PXPN_10043 2025-05-29      NaN   \n",
       "29061  PXPN_10043_2025-05-30    PXPN  PXPN_10043 2025-05-30      NaN   \n",
       "29063  PXPN_10043_2025-06-01    PXPN  PXPN_10043 2025-06-01      NaN   \n",
       "29064  PXPN_10043_2025-06-02    PXPN  PXPN_10043 2025-06-02      NaN   \n",
       "29065  PXPN_10043_2025-06-03    PXPN  PXPN_10043 2025-06-03      NaN   \n",
       "29068  PXPN_10043_2025-06-06    PXPN  PXPN_10043 2025-06-06      NaN   \n",
       "29069  PXPN_10043_2025-06-07    PXPN  PXPN_10043 2025-06-07      NaN   \n",
       "29070  PXPN_10043_2025-06-08    PXPN  PXPN_10043 2025-06-08      NaN   \n",
       "29071  PXPN_10043_2025-06-09    PXPN  PXPN_10043 2025-06-09      NaN   \n",
       "29072  PXPN_10043_2025-06-10    PXPN  PXPN_10043 2025-06-10      1.0   \n",
       "29073  PXPN_10043_2025-06-11    PXPN  PXPN_10043 2025-06-11      NaN   \n",
       "29074  PXPN_10043_2025-06-12    PXPN  PXPN_10043 2025-06-12      NaN   \n",
       "29075  PXPN_10043_2025-06-13    PXPN  PXPN_10043 2025-06-13      NaN   \n",
       "29076  PXPN_10043_2025-06-14    PXPN  PXPN_10043 2025-06-14      NaN   \n",
       "29077  PXPN_10043_2025-06-15    PXPN  PXPN_10043 2025-06-15      NaN   \n",
       "29078  PXPN_10043_2025-06-16    PXPN  PXPN_10043 2025-06-16      NaN   \n",
       "29080  PXPN_10043_2025-06-18    PXPN  PXPN_10043 2025-06-18      NaN   \n",
       "29081  PXPN_10043_2025-06-19    PXPN  PXPN_10043 2025-06-19      NaN   \n",
       "29082  PXPN_10043_2025-06-20    PXPN  PXPN_10043 2025-06-20      NaN   \n",
       "29083  PXPN_10043_2025-06-21    PXPN  PXPN_10043 2025-06-21      NaN   \n",
       "29084  PXPN_10043_2025-06-22    PXPN  PXPN_10043 2025-06-22      NaN   \n",
       "29086  PXPN_10043_2025-06-24    PXPN  PXPN_10043 2025-06-24      NaN   \n",
       "29099  PXPN_10044_2025-06-09    PXPN  PXPN_10044 2025-06-09      NaN   \n",
       "29100  PXPN_10044_2025-06-10    PXPN  PXPN_10044 2025-06-10      NaN   \n",
       "29105  PXPN_10044_2025-06-15    PXPN  PXPN_10044 2025-06-15      7.0   \n",
       "29109  PXPN_10044_2025-06-19    PXPN  PXPN_10044 2025-06-19     10.0   \n",
       "29111  PXPN_10044_2025-06-21    PXPN  PXPN_10044 2025-06-21      NaN   \n",
       "29116  PXPN_10046_2025-06-10    PXPN  PXPN_10046 2025-06-10      NaN   \n",
       "29117  PXPN_10046_2025-06-11    PXPN  PXPN_10046 2025-06-11      NaN   \n",
       "29119  PXPN_10046_2025-06-13    PXPN  PXPN_10046 2025-06-13      NaN   \n",
       "29120  PXPN_10046_2025-06-14    PXPN  PXPN_10046 2025-06-14      NaN   \n",
       "29121  PXPN_10046_2025-06-15    PXPN  PXPN_10046 2025-06-15      NaN   \n",
       "29126  PXPN_10046_2025-06-20    PXPN  PXPN_10046 2025-06-20      NaN   \n",
       "29128  PXPN_10046_2025-06-22    PXPN  PXPN_10046 2025-06-22      NaN   \n",
       "29129  PXPN_10046_2025-06-23    PXPN  PXPN_10046 2025-06-23      NaN   \n",
       "29138  PXPN_10046_2025-07-02    PXPN  PXPN_10046 2025-07-02      NaN   \n",
       "29142  PXPN_10046_2025-07-06    PXPN  PXPN_10046 2025-07-06      NaN   \n",
       "\n",
       "       bandpower(0.001-0.0005Hz)  bandpower(0.0005-0.0001Hz)  \\\n",
       "29002                        NaN                         NaN   \n",
       "29008                        NaN                         NaN   \n",
       "29009                        NaN                         NaN   \n",
       "29012                        NaN                         NaN   \n",
       "29016                        NaN                         NaN   \n",
       "29020                        NaN                         NaN   \n",
       "29021                        NaN                         NaN   \n",
       "29028                        NaN                         NaN   \n",
       "29032                        NaN                         NaN   \n",
       "29034                        NaN                         NaN   \n",
       "29035                        NaN                         NaN   \n",
       "29047                        NaN                         NaN   \n",
       "29048                        NaN                         NaN   \n",
       "29049                        NaN                         NaN   \n",
       "29053                        NaN                         NaN   \n",
       "29054                        NaN                         NaN   \n",
       "29055                        NaN                         NaN   \n",
       "29059                        NaN                         NaN   \n",
       "29060                        NaN                         NaN   \n",
       "29061                        NaN                         NaN   \n",
       "29063                        NaN                         NaN   \n",
       "29064                        NaN                         NaN   \n",
       "29065                        NaN                         NaN   \n",
       "29068                        NaN                         NaN   \n",
       "29069                        NaN                         NaN   \n",
       "29070                        NaN                         NaN   \n",
       "29071                        NaN                         NaN   \n",
       "29072                        NaN                         NaN   \n",
       "29073                        NaN                         NaN   \n",
       "29074                        NaN                         NaN   \n",
       "29075                        NaN                         NaN   \n",
       "29076                        NaN                         NaN   \n",
       "29077                        NaN                         NaN   \n",
       "29078                        NaN                         NaN   \n",
       "29080                        NaN                         NaN   \n",
       "29081                        NaN                         NaN   \n",
       "29082                        NaN                         NaN   \n",
       "29083                        NaN                         NaN   \n",
       "29084                        NaN                         NaN   \n",
       "29086                        NaN                         NaN   \n",
       "29099                        NaN                         NaN   \n",
       "29100                        NaN                         NaN   \n",
       "29105                        NaN                         NaN   \n",
       "29109                        NaN                         NaN   \n",
       "29111                        NaN                         NaN   \n",
       "29116                        NaN                         NaN   \n",
       "29117                        NaN                         NaN   \n",
       "29119                        NaN                         NaN   \n",
       "29120                        NaN                         NaN   \n",
       "29121                        NaN                         NaN   \n",
       "29126                        NaN                         NaN   \n",
       "29128                        NaN                         NaN   \n",
       "29129                        NaN                         NaN   \n",
       "29138                        NaN                         NaN   \n",
       "29142                        NaN                         NaN   \n",
       "\n",
       "       bandpower(0.0001-0.00005Hz)  bandpower(0.00005-0.00001Hz)  \\\n",
       "29002                          NaN                           NaN   \n",
       "29008                          NaN                           NaN   \n",
       "29009                          NaN                           NaN   \n",
       "29012                          NaN                           NaN   \n",
       "29016                          NaN                           NaN   \n",
       "29020                          NaN                           NaN   \n",
       "29021                          NaN                           NaN   \n",
       "29028                          NaN                           NaN   \n",
       "29032                          NaN                           NaN   \n",
       "29034                          NaN                           NaN   \n",
       "29035                          NaN                           NaN   \n",
       "29047                          NaN                           NaN   \n",
       "29048                          NaN                           NaN   \n",
       "29049                          NaN                           NaN   \n",
       "29053                          NaN                           NaN   \n",
       "29054                          NaN                           NaN   \n",
       "29055                          NaN                           NaN   \n",
       "29059                          NaN                           NaN   \n",
       "29060                          NaN                           NaN   \n",
       "29061                          NaN                           NaN   \n",
       "29063                          NaN                           NaN   \n",
       "29064                          NaN                           NaN   \n",
       "29065                          NaN                           NaN   \n",
       "29068                          NaN                           NaN   \n",
       "29069                          NaN                           NaN   \n",
       "29070                          NaN                           NaN   \n",
       "29071                          NaN                           NaN   \n",
       "29072                          NaN                           NaN   \n",
       "29073                          NaN                           NaN   \n",
       "29074                          NaN                           NaN   \n",
       "29075                          NaN                           NaN   \n",
       "29076                          NaN                           NaN   \n",
       "29077                          NaN                           NaN   \n",
       "29078                          NaN                           NaN   \n",
       "29080                          NaN                           NaN   \n",
       "29081                          NaN                           NaN   \n",
       "29082                          NaN                           NaN   \n",
       "29083                          NaN                           NaN   \n",
       "29084                          NaN                           NaN   \n",
       "29086                          NaN                           NaN   \n",
       "29099                          NaN                           NaN   \n",
       "29100                          NaN                           NaN   \n",
       "29105                          NaN                           NaN   \n",
       "29109                          NaN                           NaN   \n",
       "29111                          NaN                           NaN   \n",
       "29116                          NaN                           NaN   \n",
       "29117                          NaN                           NaN   \n",
       "29119                          NaN                           NaN   \n",
       "29120                          NaN                           NaN   \n",
       "29121                          NaN                           NaN   \n",
       "29126                          NaN                           NaN   \n",
       "29128                          NaN                           NaN   \n",
       "29129                          NaN                           NaN   \n",
       "29138                          NaN                           NaN   \n",
       "29142                          NaN                           NaN   \n",
       "\n",
       "       HR_acrophase  ...  SLT3  SLT4  SLT5  SLT6  total_sleep  smoking  \\\n",
       "29002           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29008           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29009           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29012           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29016           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29020           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29021           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29028           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29032           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29034           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29035           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29047           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29048           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29049           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29053           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29054           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29055           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29059           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29060           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29061           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29063           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29064           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29065           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29068           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29069           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29070           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29071           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29072           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29073           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29074           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29075           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29076           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29077           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29078           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29080           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29081           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29082           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29083           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29084           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29086           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29099           NaN  ...   NaN   NaN   NaN   NaN          NaN    900.0   \n",
       "29100           NaN  ...   NaN   NaN   NaN   NaN          NaN    900.0   \n",
       "29105           NaN  ...   NaN   NaN   NaN   NaN          NaN    900.0   \n",
       "29109           NaN  ...   NaN   NaN   NaN   NaN          NaN    900.0   \n",
       "29111           NaN  ...   NaN   NaN   NaN   NaN          NaN    900.0   \n",
       "29116           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29117           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29119           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29120           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29121           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29126           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29128           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29129           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29138           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "29142           NaN  ...   NaN   NaN   NaN   NaN          NaN      NaN   \n",
       "\n",
       "       menstruation  panic  severity  panic_label  \n",
       "29002           NaN    2.0       NaN            1  \n",
       "29008           NaN    2.0       NaN            1  \n",
       "29009           NaN    2.0       NaN            1  \n",
       "29012           NaN    2.0       NaN            1  \n",
       "29016           NaN    2.0       NaN            1  \n",
       "29020           NaN    2.0       NaN            1  \n",
       "29021           NaN    2.0       NaN            1  \n",
       "29028           1.0    2.0       NaN            1  \n",
       "29032           NaN    2.0       NaN            1  \n",
       "29034           NaN    2.0       NaN            1  \n",
       "29035           NaN    2.0       NaN            1  \n",
       "29047           NaN    2.0       NaN            1  \n",
       "29048           NaN    2.0       NaN            1  \n",
       "29049           NaN    2.0       NaN            1  \n",
       "29053           NaN    2.0       NaN            1  \n",
       "29054           NaN    2.0       NaN            1  \n",
       "29055           NaN    2.0       NaN            1  \n",
       "29059           NaN    2.0       NaN            1  \n",
       "29060           NaN    2.0       NaN            1  \n",
       "29061           NaN    2.0       NaN            1  \n",
       "29063           NaN    2.0       NaN            1  \n",
       "29064           NaN    2.0       NaN            1  \n",
       "29065           NaN    2.0       NaN            1  \n",
       "29068           NaN    2.0       NaN            1  \n",
       "29069           NaN    2.0       NaN            1  \n",
       "29070           NaN    2.0       NaN            1  \n",
       "29071           NaN    2.0       NaN            1  \n",
       "29072           NaN    2.0       NaN            1  \n",
       "29073           NaN    2.0       NaN            1  \n",
       "29074           NaN    2.0       NaN            1  \n",
       "29075           NaN    2.0       NaN            1  \n",
       "29076           NaN    2.0       NaN            1  \n",
       "29077           NaN    2.0       NaN            1  \n",
       "29078           NaN    2.0       NaN            1  \n",
       "29080           NaN    2.0       NaN            1  \n",
       "29081           NaN    2.0       NaN            1  \n",
       "29082           NaN    2.0       NaN            1  \n",
       "29083           NaN    2.0       NaN            1  \n",
       "29084           NaN    2.0       NaN            1  \n",
       "29086           NaN    2.0       NaN            1  \n",
       "29099           NaN    2.0       NaN            1  \n",
       "29100           NaN    2.0       NaN            1  \n",
       "29105           NaN    2.0       NaN            1  \n",
       "29109           NaN    2.0       NaN            1  \n",
       "29111           NaN    2.0       NaN            1  \n",
       "29116           NaN    2.0       NaN            1  \n",
       "29117           NaN    2.0       NaN            1  \n",
       "29119           NaN    2.0       NaN            1  \n",
       "29120           NaN    2.0       NaN            1  \n",
       "29121           NaN    2.0       NaN            1  \n",
       "29126           NaN    2.0       NaN            1  \n",
       "29128           NaN    2.0       NaN            1  \n",
       "29129           NaN    2.0       NaN            1  \n",
       "29138           NaN    2.0       NaN            1  \n",
       "29142           NaN    2.0       NaN            1  \n",
       "\n",
       "[55 rows x 72 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "panic_entries_no_severity = data_pre[(data_pre['panic'] == 2) & (data_pre['severity'].isnull())].copy()\n",
    "print(f\"Number of panic entries without severity: {panic_entries_no_severity.shape[0]}\")\n",
    "display(panic_entries_no_severity.head(55))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e13a41a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panic_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
