{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28551a76",
   "metadata": {},
   "source": [
    "# Panic Project (DHLAB) - Multiclass Classification PyCaret Model for Panic Severity Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdc63ef",
   "metadata": {},
   "source": [
    "author:  `@cyshin971`  \n",
    "\n",
    "date:    `2025-06-23`  \n",
    "\n",
    "version: `1-1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a49b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"1-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fec94e",
   "metadata": {},
   "source": [
    "# üìö | Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca28a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config as cfg\n",
    "import logging\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "\n",
    "from library.pandas_utils import move_column, remove_columns, create_empty_df, read_csv\n",
    "from library.text_utils import save_as_csv\n",
    "from library.json_utils import save_dict_to_file, load_dict_from_file\n",
    "from library.path_utils import get_file_path\n",
    "\n",
    "from pycaret.classification import *\n",
    "import shap\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83462d69",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è | Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6e7b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_data_filename = \"final_result_20250620_720\" # Name of the scraped data file without extension (.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7bf1ba",
   "metadata": {},
   "source": [
    "# üìÅ | Path Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61873106",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./_data\"\n",
    "TMP_PATH = \"./cys/_tmp\"\n",
    "OUT_PATH = \"./cys/_output\"\n",
    "\n",
    "try:\n",
    "\tfeatures_dict = load_dict_from_file(OUT_PATH, 'panic_features_dict')\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"File not found: {get_file_path(OUT_PATH, 'panic_features_dict')}. Please run data_analysis.ipynb first.\")\n",
    "print(f\"Loaded features dict with {len(features_dict)} keys:\")\n",
    "for k, v in features_dict.items():\n",
    "    if k == 'preproc_version':\n",
    "        preproc_version = v\n",
    "    if k == 'imputation_version':\n",
    "        imputation_version = v\n",
    "    elif k == 'analysis_version':\n",
    "        analysis_version = v\n",
    "        \n",
    "    else:\n",
    "        print(f'{k}: {features_dict[k]}')\n",
    "\n",
    "if scraped_data_filename is None:\n",
    "\traise ValueError(\"scraped_data_filename not found in features_dict\")\n",
    "\n",
    "PREPROC_PATH = f\"{OUT_PATH}/{scraped_data_filename}/preprocessed\"\n",
    "IMPUTED_PATH = f\"{OUT_PATH}/{scraped_data_filename}/imputed\"\n",
    "ANALYSIS_PATH = f\"{OUT_PATH}/{scraped_data_filename}/analysis\"\n",
    "OUTPUT_PATH = f\"{OUT_PATH}/severity_multiclass_pycaret\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b4473c",
   "metadata": {},
   "source": [
    "# üåê | Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e8af24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUTPUT:\n",
    "    num_classes = 3\n",
    "    class_names = ['Mild', 'Moderate', 'Severe']\n",
    "    \n",
    "    label2name = dict(enumerate(class_names))\n",
    "    name2label = {v: k for k, v in label2name.items()}\n",
    "    \n",
    "    plot_label2name = {\n",
    "\t\t'class_0': 'Mild',\n",
    "\t\t'class_1': 'Moderate',\n",
    "\t\t'class_2': 'Severe'\n",
    "\t}\n",
    "    plot_name2label = {v: k for k, v in plot_label2name.items()}\n",
    "\n",
    "    color_name2color = {\n",
    "\t\t'Mild': 'skyblue',\n",
    "\t\t'Moderate': 'orange',\n",
    "\t\t'Severe': 'lightcoral'\n",
    "\t}\n",
    "    \n",
    "    output_dict = {\n",
    "\t\t1: 'Mild',\n",
    "\t\t2: 'Mild',\n",
    "\t\t3: 'Moderate',\n",
    "\t\t4: 'Severe',\n",
    "\t\t5: 'Severe'\n",
    "\t}\n",
    "    \n",
    "    output_dict_inv = {v: k for k, v in output_dict.items()}\n",
    "\n",
    "    @staticmethod\n",
    "    def get_label_name(label):\n",
    "        return OUTPUT.label2name[label]\n",
    "    @staticmethod\n",
    "    def get_label_from_name(name):\n",
    "        return OUTPUT.name2label[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0172b789",
   "metadata": {},
   "source": [
    "# ‚öíÔ∏è | Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4319fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data = read_csv(get_file_path(IMPUTED_PATH, f'panic_pre_data_filled_{imputation_version}({scraped_data_filename}).csv'))\n",
    "display(pre_data.head(3))\n",
    "metadata = read_csv(get_file_path(PREPROC_PATH, f'panic_metadata_{preproc_version}({scraped_data_filename}).csv'))\n",
    "display(metadata.head(3))\n",
    "demography_data = read_csv(get_file_path(PREPROC_PATH, f'panic_demography_data_{preproc_version}({scraped_data_filename}).csv'))\n",
    "display(demography_data.head(3))\n",
    "# patient_data = read_csv(get_file_path(ANALYSIS_PATH, f'panic_patient_analysis_{analysis_version}({scraped_data_filename}).csv'))\n",
    "# display(patient_data.head(3))\n",
    "\n",
    "print(f\"Number of Demographic Features: {len(features_dict['demography'])}\")\n",
    "print(f\"Number of Daily Features: {len(features_dict['dailylog'])}\")\n",
    "print(f\"Number of Life Log Features: {len(features_dict['lifelog'])}\")\n",
    "print(f\"Number of Questionnaire Features: {len(features_dict['questionnaire'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d373b39",
   "metadata": {},
   "source": [
    "# üîÑÔ∏è | Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852adcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbp_param = 1\n",
    "\n",
    "filtered_metadata = create_empty_df()\n",
    "filtered_pre_data = create_empty_df()\n",
    "proc_data_init = create_empty_df()\n",
    "\n",
    "# Filter metadata for entries with at least dbp_param days of prior data\n",
    "print(f\"Found {len(metadata[metadata['panic_label'] == 1])} entries with panic label.\")\n",
    "proc_data_init = metadata[(metadata[f'panic_label'] == 1) &\n",
    "                          (metadata[f'valid_entry_{dbp_param}'] == 1)].copy()\n",
    "filtered_panic_metadata_entry_ids = proc_data_init['entry_id'].unique()\n",
    "filtered_metadata = metadata[(metadata['ref_event_id'].isin(filtered_panic_metadata_entry_ids)) &\n",
    "                             (metadata[f'dbp'] <= dbp_param)].copy()\n",
    "print(f\"Found {len(filtered_panic_metadata_entry_ids)} entries with panic label and at least {dbp_param} days of prior data.\")\n",
    "\n",
    "# Perform checks\n",
    "unique_dbp = filtered_metadata['dbp'].unique()\n",
    "if len(unique_dbp) != dbp_param:\n",
    "\traise ValueError(f\"Expected {dbp_param} unique DBP values, found {len(unique_dbp)}: {unique_dbp}\")\n",
    "del unique_dbp\n",
    "\n",
    "filtered_entry_ids = filtered_metadata['entry_id'].unique()\n",
    "filtered_panic_entry_ids = filtered_metadata['ref_event_id'].unique()\n",
    "# Filter pre_data for entries that reference panic events with at least dbp_param days of prior data\n",
    "filtered_pre_data = pre_data[pre_data['entry_id'].isin(filtered_entry_ids)].copy()\n",
    "\n",
    "# Perform checks\n",
    "if len(filtered_pre_data) != len(filtered_metadata):\n",
    "\traise ValueError(f\"Filtered pre_data length {len(filtered_pre_data)} does not match filtered_metadata length {len(filtered_metadata)}\")\n",
    "print(f\"Filtered data contains {len(filtered_panic_entry_ids)} unique panic events and {len(filtered_entry_ids)} unique entry IDs.\")\n",
    "print(f\"Filtered pre_data contains {len(filtered_pre_data['ID'].unique())} unique IDs.\")\n",
    "del filtered_entry_ids\n",
    "\n",
    "# Initialize processed data with correct entries\n",
    "proc_data_init = proc_data_init[features_dict['id']+features_dict['label']].copy()\n",
    "print(f\"Initial processed data contains {len(proc_data_init)} entries with {len(proc_data_init.columns)} columns.\")\n",
    "display(proc_data_init.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e0927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_data_int = create_empty_df()\n",
    "proc_data_int = proc_data_init.copy()\n",
    "\n",
    "# remove 'severity' from features_dict['dailylog]\n",
    "features_dict['dailylog'] = [f for f in features_dict['dailylog'] if f != 'severity']\n",
    "\n",
    "# use demography data to add demographic features to proc_data using ID (multiple entries per ID)\n",
    "proc_data_int = pd.merge(proc_data_int, demography_data, on='ID', how='left')\n",
    "\n",
    "for i in range(1, dbp_param + 1):\n",
    "    # make a dictionary of 'entry_id' : 'ref_event_id' for the current dbp\n",
    "\tdbp_dict = filtered_metadata[filtered_metadata['dbp'] == i].set_index('entry_id')['ref_event_id'].to_dict()\n",
    "\tprint(f\"Processing data for {i} days before panic.\")\n",
    "\n",
    "\tentry_ids = dbp_dict.keys()\n",
    "\tfiltered_pre_data_i = filtered_pre_data[filtered_pre_data['entry_id'].isin(entry_ids)].copy()\n",
    "\tif len(filtered_pre_data_i) != len(dbp_dict.keys()):\n",
    "\t\traise ValueError(f\"Filtered pre_data length {len(filtered_pre_data_i)} does not match filtered_metadata length {len(dbp_dict.keys())} for {i} days before panic\")\n",
    "  \t# Update 'entry_id' in filtered_pre_data_i to the corresponding 'ref_event_id' from dbp_dict\n",
    "\tfiltered_pre_data_i['entry_id'] = filtered_pre_data_i['entry_id'].map(dbp_dict)\n",
    "\t\n",
    "\tfeatures_list = ['entry_id']+features_dict['dailylog']+features_dict['lifelog']\n",
    "\tif i == dbp_param:\n",
    "\t\tfeatures_list += features_dict['questionnaire']\n",
    "\tfiltered_pre_data_i = filtered_pre_data_i[features_list].copy()\n",
    "\t# rename ALL non-ID columns to include the suffix\n",
    "\tcols_to_rename = [c for c in filtered_pre_data_i.columns if c != 'entry_id']\n",
    "\trename_map = {c: f\"{c}_{i}\" for c in cols_to_rename}\n",
    "\tfiltered_pre_data_i.rename(columns=rename_map, inplace=True)\n",
    "\t\n",
    "\tproc_data_int = pd.merge(proc_data_int, filtered_pre_data_i, on='entry_id', how='left', suffixes=('', f'_{i}'))\n",
    "\n",
    "# Use OUTPUT.output_dict to map severity labels\n",
    "proc_data_int['severity'] = proc_data_int['severity'].map(OUTPUT.output_dict)\n",
    "\n",
    "display(proc_data_int.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49c7abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_data = create_empty_df()\n",
    "proc_data = proc_data_int.copy()\n",
    "\n",
    "r_cols = ['panic',\n",
    "          'dbp',\n",
    "          'panic_label']\n",
    "remove_columns(proc_data, r_cols)\n",
    "move_column(proc_data, 'severity', -1)\n",
    "display(proc_data.head(3))\n",
    "save_as_csv(proc_data, OUTPUT_PATH, f'panic_severity_multi_proc_data_{dbp_param}days_{version}({scraped_data_filename})', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49957b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a histogram of the severity distribution\n",
    "plt.figure(figsize=(5, 3))\n",
    "severity_counts = proc_data['severity'].value_counts().sort_index()\n",
    "total_count = severity_counts.sum()\n",
    "colors = [OUTPUT.color_name2color['Mild'], OUTPUT.color_name2color['Moderate'], OUTPUT.color_name2color['Severe']]\n",
    "ax = severity_counts.plot(kind='bar', color=colors)\n",
    "plt.title('Severity Distribution')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Add labels with counts and percentages at the center of each bar\n",
    "for p in ax.patches:\n",
    "\tcount = p.get_height()\n",
    "\tpercentage = f\"{(count / total_count * 100):.1f}%\"\n",
    "\tax.annotate(f'{count}\\n{percentage}',\n",
    "\t\t\t\t(p.get_x() + p.get_width() / 2., p.get_height() / 2.),\n",
    "\t\t\t\tha='center', va='center', fontsize=10, color='black', xytext=(0, 0),\n",
    "\t\t\t\ttextcoords='offset points')\n",
    "\n",
    "# Remove the 'severity' label from the bottom\n",
    "ax.set_xlabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# pd.crosstab(proc_data['severity'], proc_data['dataset'], margins=True, margins_name='Total')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b01af17",
   "metadata": {},
   "source": [
    "# ü§ñ | Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4744a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = proc_data.copy()\n",
    "remove_columns(data, features_dict['id'])\n",
    "print(f\"Processed data contains {len(data)} entries with {len(data.columns)} columns after removing ID columns.\")\n",
    "display(data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249402fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyCaret setup\n",
    "clf = setup(\n",
    "    data=data,\n",
    "    target='severity',               # replace with your target column name\n",
    "    session_id=123,                  # for reproducibility\n",
    "    normalize=True,                  # scale numeric features\n",
    "    transformation=False,            # turn off power transformation\n",
    "    train_size=0.8,                  # 80/20 split\n",
    "    fold=5,                          # 5-fold cross-validation\n",
    "    fold_strategy='stratifiedkfold',\n",
    "    numeric_imputation='mean',\n",
    "    remove_multicollinearity=True,   # for small datasets, this is often helpful\n",
    "\tmulticollinearity_threshold=0.9, # threshold for removing multicollinear features\n",
    "\t# html=False,                    # do not generate HTML report (use plain-text output)\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603bb323",
   "metadata": {},
   "source": [
    "# üöÇ | Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4eea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare baseline models and select the best by Accuracy\n",
    "best_model = compare_models(sort='Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4757a3b6",
   "metadata": {},
   "source": [
    "# üß™ | Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6e4fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pull()  # Get the latest output table as a DataFrame\n",
    "# Cross-Validation results\n",
    "print(\"Cross-Validation Results:\")\n",
    "display(results)  # Jupyter display (can further style if you want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48196744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on hold-out set (20% test split)\n",
    "holdout_results = predict_model(best_model)\n",
    "print(f\"Hold-out Set Results (20% test split) for {OUTPUT.num_classes} classes (test_size={len(holdout_results)}):\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9246934",
   "metadata": {},
   "source": [
    "# üîç | Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0084dcd0",
   "metadata": {},
   "source": [
    "## SHAP Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b9624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the best model is TreeExplainer-compatible\n",
    "tree_model_ids = ['et', 'rf', 'gbc', 'lightgbm', 'dt']\n",
    "tree_model_names = [\n",
    "    'Extra Trees Classifier', 'Random Forest Classifier',\n",
    "    'Gradient Boosting Classifier', 'Light Gradient Boosting Machine',\n",
    "    'Decision Tree Classifier'\n",
    "]\n",
    "\n",
    "# Function to check compatibility by class name\n",
    "def is_tree_model(model):\n",
    "    model_name = model.__class__.__name__.lower()\n",
    "    # Try common tree model keywords\n",
    "    return any(keyword in model_name for keyword in ['forest', 'tree', 'boost', 'lightgbm'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbc5b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP analysis only if TreeExplainer compatible\n",
    "is_compatible = is_tree_model(best_model)\n",
    "\n",
    "if is_compatible:\n",
    "    print(f\"Best model ({best_model.__class__.__name__}) is compatible with SHAP TreeExplainer.\")\n",
    "\n",
    "    # Extract features (remove prediction/score columns)\n",
    "    feature_cols = [col for col in holdout_results.columns if col in data.columns and col != 'severity']\n",
    "    X_holdout = holdout_results[feature_cols]\n",
    "\n",
    "    # --- Robust estimator unwrapping for ensembles ---\n",
    "    model_to_explain = best_model\n",
    "    base_estimator_key = None  # Track which base estimator is used\n",
    "    # Unwrap only if Voting or Stacking ensemble\n",
    "    if isinstance(model_to_explain, (VotingClassifier, StackingClassifier)):\n",
    "        named_estimators = dict(model_to_explain.named_estimators_)\n",
    "        # Try to select a tree-based model in order of preference\n",
    "        for key in ['rf', 'et', 'gbc', 'lightgbm', 'dt']:\n",
    "            if key in named_estimators and is_tree_model(named_estimators[key]):\n",
    "                model_to_explain = named_estimators[key]\n",
    "                base_estimator_key = key\n",
    "                print(f\"Selected base estimator '{key}' from Voting/Stacking ensemble.\")\n",
    "                break\n",
    "        if base_estimator_key is None:\n",
    "            print(\"Warning: No compatible tree model found in the ensemble; SHAP will use the full ensemble.\")\n",
    "\n",
    "    print(\"Model to explain:\", type(model_to_explain))\n",
    "\n",
    "    # Build the SHAP TreeExplainer\n",
    "    explainer = shap.TreeExplainer(model_to_explain)\n",
    "    shap_values = explainer.shap_values(X_holdout)\n",
    "\n",
    "    # SHAP summary plot (for multiclass)\n",
    "    # shap.summary_plot(shap_values, X_holdout)\n",
    "\n",
    "    # Get SHAP values as DataFrame (one per class)\n",
    "    shap_dfs = {}\n",
    "    \n",
    "    if isinstance(shap_values, list):\n",
    "        # Standard SHAP output for multiclass: list of [n_samples, n_features] arrays (one per class)\n",
    "        for i, class_shap in enumerate(shap_values):\n",
    "            shap_dfs[f\"class_{i}\"] = pd.DataFrame(class_shap, columns=X_holdout.columns, index=X_holdout.index)\n",
    "    elif isinstance(shap_values, np.ndarray) and shap_values.ndim == 3:\n",
    "        # SHAP returned shape: (n_samples, n_features, n_classes)\n",
    "        n_classes = shap_values.shape[2]\n",
    "        for i in range(n_classes):\n",
    "            shap_dfs[f\"class_{i}\"] = pd.DataFrame(shap_values[:,:,i], columns=X_holdout.columns, index=X_holdout.index)\n",
    "    else:\n",
    "        # Binary or regression: single 2D array\n",
    "        shap_dfs[\"shap_values\"] = pd.DataFrame(shap_values, columns=X_holdout.columns, index=X_holdout.index)\n",
    "\n",
    "    # display(shap_dfs[\"class_0\"].head())\n",
    "\n",
    "else:\n",
    "    print(f\"Best model ({best_model.__class__.__name__}) is NOT compatible with SHAP TreeExplainer.\")\n",
    "    print(\"Please select one of the following tree models for SHAP analysis: 'et', 'rf', 'gbc', 'lightgbm', 'dt'\")\n",
    "    print(\"Example:\")\n",
    "    print(\"rf_model = create_model('rf')\\nrf_model = finalize_model(rf_model)\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c1e9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 10  # Number of features to show\n",
    "\n",
    "for class_label in OUTPUT.plot_label2name.keys():\n",
    "    df = shap_dfs[class_label]\n",
    "    # Compute mean absolute SHAP value for each feature\n",
    "    feature_importance = df.abs().mean(axis=0).sort_values(ascending=False)\n",
    "    # Get top features\n",
    "    top_features = feature_importance.head(top_n)\n",
    "    \n",
    "    # Print as table\n",
    "    print(f\"\\nTop {top_n} features for {OUTPUT.plot_label2name[class_label]}:\")\n",
    "    print(top_features)\n",
    "    \n",
    "    # Bar plot\n",
    "    plt.figure(figsize=(6,4))\n",
    "    top_features[::-1].plot(kind='barh')\n",
    "    plt.title(f\"Top {top_n} Features by Mean(|SHAP|) for {OUTPUT.plot_label2name[class_label]}\")\n",
    "    plt.xlabel(\"Mean(|SHAP Value|)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752ea2c6",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b468b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a specific model (e.g., LightGBM)\n",
    "# model = create_model('lightgbm')\n",
    "\n",
    "# Tune the model hyperparameters\n",
    "# tuned_model = tune_model(model, optimize='Accuracy')\n",
    "\n",
    "# Ensemble models (optional)\n",
    "# blended_model = blend_models([tuned_model, best_model])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dhlab-panic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
