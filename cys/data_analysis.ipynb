{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72f4fd25",
   "metadata": {},
   "source": [
    "# Panic Project (DHLAB) - Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5634a08",
   "metadata": {},
   "source": [
    "author:  `@cyshin971`  \n",
    "\n",
    "date:    `2025-06-19`  \n",
    "\n",
    "version: `2.0`\n",
    "\n",
    "> version `1.1`: preprocessing separated to `data_preprocessing.ipynb` (version `1.0`)\n",
    "> version `2.0`:\n",
    ">  - Added `metadata_filled` generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76af6c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '2-0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42654e1",
   "metadata": {},
   "source": [
    "# ðŸ“š | Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9df09cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config as cfg\n",
    "import logging\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "\n",
    "from library.pandas_utils import move_column, remove_columns, aggregate_by_column, create_empty_df, read_csv\n",
    "from library.text_utils import save_as_csv\n",
    "from library.json_utils import save_dict_to_file, load_dict_from_file\n",
    "from library.path_utils import get_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa403ca",
   "metadata": {},
   "source": [
    "# ðŸ“ | Path Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8780ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./_data\"\n",
    "TMP_PATH = \"./cys/_tmp\"\n",
    "OUTPUT_PATH = \"./cys/_output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6024277b",
   "metadata": {},
   "source": [
    "# âš’ï¸ | Preprocessed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5b1f06",
   "metadata": {},
   "source": [
    "## Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5a6ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\tfeatures_dict = load_dict_from_file(OUTPUT_PATH, 'panic_features_dict')\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"File not found: {get_file_path(OUTPUT_PATH, 'panic_features_dict')}. Please run data_analysis.ipynb first.\")\n",
    "print(f\"Loaded features dict with {len(features_dict)} keys:\")\n",
    "scraped_data_filename = None\n",
    "for k, v in features_dict.items():\n",
    "    if k == 'scraped_data_filename':\n",
    "        print(f\"  {k}: {v}.csv\")\n",
    "        scraped_data_filename = v\n",
    "    elif k == 'preproc_version':\n",
    "        preproc_version = v\n",
    "    else:\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "if scraped_data_filename is None:\n",
    "\traise ValueError(\"scraped_data_filename not found in features_dict\")\n",
    "\n",
    "features_dict['analysis_version'] = version\n",
    "save_dict_to_file(features_dict, OUTPUT_PATH, 'panic_features_dict')\n",
    "\n",
    "pre_data = read_csv(get_file_path(OUTPUT_PATH, f'panic_pre_data_{preproc_version}({scraped_data_filename}).csv'))\n",
    "display(pre_data.head(5))\n",
    "metadata = read_csv(get_file_path(OUTPUT_PATH, f'panic_metadata_{preproc_version}({scraped_data_filename}).csv'))\n",
    "display(metadata.head(5))\n",
    "demography_data = read_csv(get_file_path(OUTPUT_PATH, f'panic_demography_data_{preproc_version}({scraped_data_filename}).csv'))\n",
    "display(demography_data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef5553a",
   "metadata": {},
   "source": [
    "# ðŸ” | Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920cd25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from library.matplotlib_utils import plot_histogram_of_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d403f88",
   "metadata": {},
   "source": [
    "## ðŸ¤¢ | Patient-level Analysis\n",
    "\n",
    "**Description**\n",
    "- `n_entries`: Number of entries per patient\n",
    "- `n_valid_3_entries`: Number of valid (3 prior consecutive days of data) entries per patient\n",
    "- `n_valid_2_entries`: Number of valid (2 prior consecutive days of data) entries per patient\n",
    "- `n_valid_1_entries`: Number of valid (1 prior consecutive days of data) entries per patient\n",
    "- `n_panic`: Number of panic events per patient\n",
    "- `max_severity`: Maximum panic severity experienced by patient\n",
    "- `min_severity`: Minimum panic severity experienced by patient\n",
    "- `mean_severity`: Average panic severity experienced by patient\n",
    "- `n_dailylog`: Number of daily log entries per patient\n",
    "- `n_lifelog`: Number of life log entries per patient\n",
    "- `n_questionnaire`: Number of questionnaire entries per patient\n",
    "- `sum_dtype`: Number of data (by group) per patient\n",
    "- `mean_dtype`: Average number of data types per entry per patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b24e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_matrix = [\n",
    "\t('n_entries', 'entry_id', 'count'),\n",
    "\t('n_valid_3_entries', 'valid_entry_3', 'sum'),\n",
    "\t('n_valid_2_entries', 'valid_entry_2', 'sum'),\n",
    "\t('n_valid_1_entries', 'valid_entry_1', 'sum'),\n",
    "\t('n_panic', 'panic_label', 'sum'),\n",
    "    ('max_severity', 'severity', 'max'),\n",
    "\t('min_severity', 'severity', 'min'),\n",
    "\t('mean_severity', 'severity', 'mean'),\n",
    "\t('n_dailylog', 'dailylog_data', 'sum'),\n",
    "\t('n_lifelog', 'lifelog_data', 'sum'),\n",
    "\t('n_questionnaire', 'questionnaire_data', 'sum'),\n",
    "\t('sum_dtype', 'dtype_n', 'sum'),\n",
    "\t('mean_dtype', 'dtype_n', 'mean'),\n",
    "    ('n_diary', 'diary_data', 'sum'),\n",
    "\t('coffee_mean', 'coffee', 'mean'),\n",
    "    ('coffee_n', 'coffee', 'count'),\n",
    "    ('smoking_mean', 'smoking', 'mean'),\n",
    "    ('total_sleep_mean', 'total_sleep', 'mean'),\n",
    "]\n",
    "patient_analysis_data = create_empty_df()\n",
    "patient_analysis_data = aggregate_by_column(metadata, 'ID', agg_matrix)\n",
    "\n",
    "display(patient_analysis_data.head(5))\n",
    "save_as_csv(patient_analysis_data, OUTPUT_PATH, f\"panic_patient_analysis_{version}({scraped_data_filename})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdce151",
   "metadata": {},
   "source": [
    "# Fill Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27d404d",
   "metadata": {},
   "source": [
    "## Daily Log\n",
    "\n",
    "- coffee: Fill with average coffee cups per patient for patients with entries, else fill with 0\n",
    "- smoking: Fill with average times of smoking per patient with history of smoking, else fill with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d609e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data_filled_dailylog = create_empty_df()\n",
    "pre_data_filled_dailylog = pre_data.copy()\n",
    "\n",
    "# Fill coffee data\n",
    "# make a dictionary of ID and coffee_mean from patient_analysis_data\n",
    "coffee_mean_dict = patient_analysis_data.set_index('ID')['coffee_mean'].to_dict()\n",
    "pre_data_filled_dailylog.loc[pre_data_filled_dailylog['coffee'].isnull(), 'coffee'] = pre_data_filled_dailylog.loc[pre_data_filled_dailylog['coffee'].isnull(), 'ID'].map(coffee_mean_dict)\n",
    "pre_data_filled_dailylog['coffee'] = pre_data_filled_dailylog['coffee'].fillna(0.0)\n",
    "\n",
    "# Fill smoking data\n",
    "smoking_mean_dict = patient_analysis_data.set_index('ID')['smoking_mean'].to_dict()\n",
    "smokingHx_dict = demography_data.set_index('ID')['smkHx'].to_dict()\n",
    "# get rid of keys in smokingHx_dict that are not in smoking_mean_dict\n",
    "smokingHx_dict = {k: v for k, v in smokingHx_dict.items() if k in smoking_mean_dict}\n",
    "# use smokingHx_dict to replace the smoking_mean_dict values such that if the smokingHx is 0, the smoking_mean_dict value is set to 0 else keep the smoking_mean_dict value\n",
    "smoking_mean_dict = {k: (0.0 if v == 0 else smoking_mean_dict[k]) for k, v in smokingHx_dict.items()}\n",
    "# fill the smoking column in pre_data_filled_smoking with the smoking_mean_dict values\n",
    "pre_data_filled_dailylog.loc[pre_data_filled_dailylog['smoking'].isnull(), 'smoking'] = pre_data_filled_dailylog.loc[pre_data_filled_dailylog['smoking'].isnull(), 'ID'].map(smoking_mean_dict)\n",
    "\n",
    "pre_data_filled_dailylog['smoking'] = pre_data_filled_dailylog['smoking'].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a336944",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pre_data_filled_dailylog.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac727db5",
   "metadata": {},
   "source": [
    "## Life Log\n",
    "\n",
    "- total_sleep: Fill with average sleep time per patient. if no sleep data exists fill with 8 Hour Sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2340612",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data_filled_lifelog = create_empty_df()\n",
    "pre_data_filled_lifelog = pre_data_filled_dailylog.copy()\n",
    "\n",
    "# Fill total_sleep data\n",
    "totsleep_mean_dict = patient_analysis_data.set_index('ID')['total_sleep_mean'].to_dict()\n",
    "pre_data_filled_lifelog.loc[pre_data_filled_lifelog['total_sleep'].isnull(), 'total_sleep'] = pre_data_filled_lifelog.loc[pre_data_filled_lifelog['total_sleep'].isnull(), 'ID'].map(totsleep_mean_dict)\n",
    "pre_data_filled_lifelog['total_sleep'] = pre_data_filled_lifelog['total_sleep'].fillna(8.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d955669",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pre_data_filled_dailylog.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0c8ada",
   "metadata": {},
   "source": [
    "## ðŸ’¾ | Save Filled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c34026",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data_filled = create_empty_df()\n",
    "pre_data_filled = pre_data_filled_lifelog.copy()\n",
    "\n",
    "save_as_csv(pre_data_filled, OUTPUT_PATH, f\"panic_pre_data_filled_{version}({scraped_data_filename})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeb7bee",
   "metadata": {},
   "source": [
    "## Filled Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df884ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_filled = create_empty_df()\n",
    "metadata_filled = metadata.copy()\n",
    "if len(pre_data_filled) != len(metadata):\n",
    "    raise ValueError(f\"Length of pre_data_filled ({len(pre_data_filled)}) does not match length of metadata ({len(metadata)}). Please check the data consistency.\")\n",
    "remove_columns(metadata_filled, ['coffee', 'smoking', 'total_sleep'])\n",
    "none_columns = ['dailylog_data', 'lifelog_data', 'questionnaire_data', 'dtype_n']\n",
    "for col in none_columns:\n",
    "    metadata_filled[col] = None\n",
    "\n",
    "metadata_filled['dailylog_data'] = pre_data_filled[features_dict['dailylog']].notnull().any(axis=1).astype(int)\n",
    "metadata_filled['lifelog_data'] = pre_data_filled[features_dict['lifelog']].notnull().any(axis=1).astype(int)\n",
    "metadata_filled['questionnaire_data'] = pre_data_filled[features_dict['questionnaire']].notnull().any(axis=1).astype(int)\n",
    "\n",
    "# TODO: Diary data is not used in the current analysis, but can be useful for future reference\n",
    "metadata_filled['dtype_n'] = metadata_filled['dailylog_data'] + metadata_filled['lifelog_data'] + metadata_filled['questionnaire_data']\n",
    "\n",
    "save_as_csv(metadata_filled, OUTPUT_PATH, f\"panic_metadata_filled_{version}({scraped_data_filename})\")\n",
    "display(metadata_filled.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bdba2a",
   "metadata": {},
   "source": [
    "# ðŸ“’ | Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf66dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from library.matplotlib_utils import plot_histogram_of_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1b0af6",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f58181",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_filled_ids =  pre_data_filled['ID'].unique()\n",
    "print(f\"Total number of unique IDs in pre_data_filled: {len(unique_filled_ids)}\")\n",
    "print(f\"Total number of entries in pre_data_filled: {len(pre_data_filled)}\")\n",
    "panic_entries = pre_data_filled[pre_data_filled['panic_label'] == 1]\n",
    "print(f\"Total number of panic entries in pre_data_filled: {len(panic_entries)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9142c25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_entry_ids = pre_data_filled['entry_id'].unique()\n",
    "print(f\"Total number of daily log entries: {metadata_filled[metadata_filled['dailylog_data'] == 1].shape[0]} / {len(filled_entry_ids)} ({metadata_filled[metadata_filled['dailylog_data'] == 1].shape[0] / len(filled_entry_ids) * 100:.2f}%)\")\n",
    "print(f\"Total number of life log entries: {metadata_filled[metadata_filled['lifelog_data'] == 1].shape[0]} / {len(filled_entry_ids)} ({metadata_filled[metadata_filled['lifelog_data'] == 1].shape[0] / len(filled_entry_ids) * 100:.2f}%)\")\n",
    "print(f\"Total number of questionnaire entries: {metadata_filled[metadata_filled['questionnaire_data'] == 1].shape[0]} / {len(filled_entry_ids)} ({metadata_filled[metadata_filled['questionnaire_data'] == 1].shape[0] / len(filled_entry_ids) * 100:.2f}%)\")\n",
    "print(f\"Total number of panic diary entries: {metadata_filled[metadata_filled['diary_data'] == 1].shape[0]} / {len(filled_entry_ids)} ({metadata_filled[metadata_filled['diary_data'] == 1].shape[0] / len(filled_entry_ids) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befcc5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "panic_patients = metadata_filled[metadata_filled['panic_label'] == 1]['ID'].unique()\n",
    "print(f\"Total number of patients with panic events: {len(panic_patients)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb4ad05",
   "metadata": {},
   "source": [
    "## ðŸ—’ï¸ | Entry-level Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2b1ffa",
   "metadata": {},
   "source": [
    "### Data Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dba3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = metadata[metadata['dtype_n'] == 0].copy()\n",
    "# test_entries = test['entry_id'].unique()\n",
    "# if len(test_entries) > 0:\n",
    "#     print(f\"Total number of entries with dtype 0: {test.shape[0]} / {len(data_pre_entry_ids)} ({test.shape[0] / len(data_pre_entry_ids) * 100:.2f}%)\")\n",
    "#     test_pre_data = pre_data[pre_data['entry_id'].isin(test_entries)].copy()\n",
    "#     save_as_csv(test_pre_data, TMP_PATH, f\"panic_test_pre_data_{version}({scraped_data_filename})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cf24a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_of_counts(metadata['dtype_n'], title='Number of data types per entry', xlabel='Number of data types', ylabel='Number of entries', zero_start=False, bins_step=1)\n",
    "print(f\"Number of entries with 1 data type: {metadata[metadata['dtype_n'] == 1].shape[0]} ({metadata[metadata['dtype_n'] == 1].shape[0] / metadata.shape[0] * 100:.2f}%)\")\n",
    "print(f\"Number of entries with 2 data types: {metadata[metadata['dtype_n'] == 2].shape[0]} ({metadata[metadata['dtype_n'] == 2].shape[0] / metadata.shape[0] * 100:.2f}%)\")\n",
    "print(f\"Number of entries with 3 data types: {metadata[metadata['dtype_n'] == 3].shape[0]} ({metadata[metadata['dtype_n'] == 3].shape[0] / metadata.shape[0] * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33b01fb",
   "metadata": {},
   "source": [
    "### Valid Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8301b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of valid entries (3 days): {metadata['valid_entry_3'].sum()} ({metadata['valid_entry_3'].mean() * 100:.2f}%)\")\n",
    "print(f\"Total number of valid entries (2 days): {metadata['valid_entry_2'].sum()} ({metadata['valid_entry_2'].mean() * 100:.2f}%)\")\n",
    "print(f\"Total number of valid entries (1 day): {metadata['valid_entry_1'].sum()} ({metadata['valid_entry_1'].mean() * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654adf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "panic_n = pre_data[pre_data['dbp'] == 0].shape[0]\n",
    "print(f\"Total number of panic events (dbp=0): {panic_n}\")\n",
    "valid_panic_events_3 = metadata[(metadata['valid_entry_3'] == 1) & (metadata['dbp'] == 0)].shape[0]\n",
    "print(f\"Total number of valid panic events (n_prior_data >= 3 days): {valid_panic_events_3} ({valid_panic_events_3 / panic_n * 100:.2f}%)\")\n",
    "valid_panic_events_2 = metadata[(metadata['valid_entry_2'] == 1) & (metadata['dbp'] == 0)].shape[0]\n",
    "print(f\"Total number of valid panic events (n_prior_data >= 2 days): {valid_panic_events_2} ({valid_panic_events_2 / panic_n * 100:.2f}%)\")\n",
    "valid_panic_events_1 = metadata[(metadata['valid_entry_1'] == 1) & (metadata['dbp'] == 0)].shape[0]\n",
    "print(f\"Total number of valid panic events (n_prior_data >= 1 day): {valid_panic_events_1} ({valid_panic_events_1 / panic_n * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faecf9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_dbp = metadata[metadata['dbp'] == 1]\n",
    "print(f\"Total number of entries with dbp=1: {one_dbp.shape[0]} ({one_dbp.shape[0] / metadata.shape[0] * 100:.2f}%)\")\n",
    "two_dvp = metadata[metadata['dbp'] == 2]\n",
    "print(f\"Total number of entries with dbp=2: {two_dvp.shape[0]} ({two_dvp.shape[0] / metadata.shape[0] * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff574743",
   "metadata": {},
   "source": [
    "## ðŸ¤¢ | Patient-level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8105998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data_ids = pre_data['ID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f10e315",
   "metadata": {},
   "source": [
    "### Patient-level Valid Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48fdd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_of_counts(patient_analysis_data['n_entries'], title='Number of Entries per Patient',\n",
    "                         xlabel='Number of Entries', ylabel='Number of Patients', bins_step=20, exclude_zero=True)\n",
    "valid_patients = patient_analysis_data[patient_analysis_data['n_valid_1_entries'] > 0]\n",
    "n_valid_patients_1 = valid_patients.shape[0]\n",
    "print(f\"Number of valid patients (1 days): {valid_patients.shape[0]} / {len(pre_data_ids)}\")\n",
    "print(f\"{len(pre_data_ids) - valid_patients.shape[0]} patients do not have valid entries (i.e., no data for at least 1 days before panic event)\")\n",
    "plot_histogram_of_counts(patient_analysis_data['n_valid_1_entries'], title='Number of Valid Entries (1 days) per Patient',\n",
    "                         xlabel='Number of Valid Entries (1 days)', ylabel='Number of Patients', bins_step=20, exclude_zero=True)\n",
    "valid_patients = patient_analysis_data[patient_analysis_data['n_valid_2_entries'] > 0]\n",
    "n_valid_patients_2 = valid_patients.shape[0]\n",
    "print(f\"Number of valid patients (2 days): {valid_patients.shape[0]} / {len(pre_data_ids)}\")\n",
    "print(f\"{len(pre_data_ids) - valid_patients.shape[0]} patients do not have valid entries (i.e., no data for at least 2 days before panic event)\")\n",
    "plot_histogram_of_counts(patient_analysis_data['n_valid_2_entries'], title='Number of Valid Entries (2 days) per Patient',\n",
    "                         xlabel='Number of Valid Entries (2 days)', ylabel='Number of Patients', bins_step=20, exclude_zero=True)\n",
    "valid_patients = patient_analysis_data[patient_analysis_data['n_valid_3_entries'] > 0]\n",
    "n_valid_patients_3 = valid_patients.shape[0]\n",
    "print(f\"Number of valid patients (3 days): {valid_patients.shape[0]} / {len(pre_data_ids)}\")\n",
    "print(f\"{len(pre_data_ids) - valid_patients.shape[0]} patients do not have valid entries (i.e., no data for at least 3 days before panic event)\")\n",
    "plot_histogram_of_counts(patient_analysis_data['n_valid_3_entries'], title='Number of Valid Entries (3 days) per Patient',\n",
    "                         xlabel='Number of Valid Entries (3 days)', ylabel='Number of Patients', bins_step=20, exclude_zero=True)\n",
    "del valid_patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1ed563",
   "metadata": {},
   "source": [
    "### Patient-level Panic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0145840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_of_counts(patient_analysis_data['n_panic'], title='Number of Panic Events per Patient', xlabel='Number of Panic Events', ylabel='Number of Patients', bins_step=5)\n",
    "print(f\"Number of patients with zero panic events: {patient_analysis_data[patient_analysis_data['n_panic'] == 0].shape[0]} / {len(pre_data_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29839359",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "valid_panic_events_patients = patient_analysis_data[(patient_analysis_data['n_panic'] > 0) & (patient_analysis_data['n_valid_3_entries'] > 0)]\n",
    "print(f\"Number of patients with valid panic events (3 days): {valid_panic_events_patients.shape[0]} / {n_valid_patients_3}\")\n",
    "valid_panic_events_patients = patient_analysis_data[(patient_analysis_data['n_panic'] > 0) & (patient_analysis_data['n_valid_2_entries'] > 0)]\n",
    "print(f\"Number of patients with valid panic events (2 days): {valid_panic_events_patients.shape[0]} / {n_valid_patients_2}\")\n",
    "valid_panic_events_patients = patient_analysis_data[(patient_analysis_data['n_panic'] > 0) & (patient_analysis_data['n_valid_1_entries'] > 0)]\n",
    "print(f\"Number of patients with valid panic events (1 days): {valid_panic_events_patients.shape[0]} / {n_valid_patients_1}\")\n",
    "del valid_panic_events_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b8cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_with_panic = patient_analysis_data[patient_analysis_data['n_panic'] > 0]\n",
    "print(f\"Number of patients with panic events: {patients_with_panic.shape[0]} / {len(pre_data_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aa2db7",
   "metadata": {},
   "source": [
    "### Patient-level Data Group Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bdc7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_of_counts(patient_analysis_data['n_dailylog'], title='Number of Daily Log Entries per Patient',\n",
    "\t\t\t\t\t\t xlabel='Number of Daily Log Entries', ylabel='Number of Patients', bins_step=20, exclude_zero=True)\n",
    "print(f\"Number of patients with no daily log entries: {patient_analysis_data[patient_analysis_data['n_dailylog'] == 0].shape[0]} / {len(pre_data_ids)}\")\n",
    "plot_histogram_of_counts(patient_analysis_data['n_lifelog'], title='Number of Life Log Entries per Patient',\n",
    "\t\t\t\t\t\t xlabel='Number of Life Log Entries', ylabel='Number of Patients', bins_step=20, exclude_zero=True)\n",
    "print(f\"Number of patients with no life log entries: {patient_analysis_data[patient_analysis_data['n_lifelog'] == 0].shape[0]} / {len(pre_data_ids)}\")\n",
    "plot_histogram_of_counts(patient_analysis_data['n_questionnaire'], title='Number of Questionnaire Entries per Patient',\n",
    "\t\t\t\t\t\t xlabel='Number of Questionnaire Entries', ylabel='Number of Patients', bins_step=20, exclude_zero=True)\n",
    "print(f\"Number of patients with no questionnaire entries: {patient_analysis_data[patient_analysis_data['n_questionnaire'] == 0].shape[0]} / {len(pre_data_ids)}\")\n",
    "plot_histogram_of_counts(patient_analysis_data['n_diary'], title='Number of Panic Diary Entries per Patient',\n",
    "\t\t\t\t\t\t xlabel='Number of Panic Diary Entries', ylabel='Number of Patients', bins_step=5, exclude_zero=True)\n",
    "print(f\"Number of patients with no panic diary entries: {patient_analysis_data[patient_analysis_data['n_diary'] == 0].shape[0]} / {len(pre_data_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb86ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_panic = metadata[metadata['panic_label'] == 1].copy()\n",
    "print(f\"Number of panic events in preprocessed data: {metadata_panic.shape[0]}\")\n",
    "agg_matrix = [\n",
    "\t('valid_entries_3', 'valid_entry_3', 'sum'),\n",
    "\t('valid_entries_2', 'valid_entry_2', 'sum'),\n",
    "\t('valid_entries_1', 'valid_entry_1', 'sum'),\n",
    "]\n",
    "agg_metadata_panic = aggregate_by_column(metadata_panic, 'ID', agg_matrix)\n",
    "\n",
    "print(f\"Number of valid panic entries (valid_entry_3): {agg_metadata_panic['valid_entries_3'].sum()}\")\n",
    "print(f\"Number of valid panic entries (valid_entry_2): {agg_metadata_panic['valid_entries_2'].sum()}\")\n",
    "print(f\"Number of valid panic entries (valid_entry_1): {agg_metadata_panic['valid_entries_1'].sum()}\")\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(f\"Number of patients with valid panic entries (valid_entry_3): {agg_metadata_panic[agg_metadata_panic['valid_entries_3'] > 0].shape[0]}\")\n",
    "print(f\"Number of patients with valid panic entries (valid_entry_2): {agg_metadata_panic[agg_metadata_panic['valid_entries_2'] > 0].shape[0]}\")\n",
    "print(f\"Number of patients with valid panic entries (valid_entry_1): {agg_metadata_panic[agg_metadata_panic['valid_entries_1'] > 0].shape[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dhlab-panic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
