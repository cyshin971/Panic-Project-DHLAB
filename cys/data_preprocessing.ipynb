{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72f4fd25",
   "metadata": {},
   "source": [
    "# Panic Project (DHLAB) - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5634a08",
   "metadata": {},
   "source": [
    "author:  `@cyshin971`  \n",
    "\n",
    "date:    `2025-06-18`  \n",
    "\n",
    "version: `1.3`\n",
    "\n",
    "> version `1.0`: Derived from `data_analysis.ipynb` version `1.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "534a5112",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"1-3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42654e1",
   "metadata": {},
   "source": [
    "# üìö | Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9df09cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config as cfg\n",
    "import logging\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "\n",
    "from library.pandas_utils import move_column, remove_columns, aggregate_by_column, create_empty_df, read_csv\n",
    "from library.text_utils import save_as_csv\n",
    "from library.json_utils import save_dict_to_file\n",
    "from library.path_utils import get_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa403ca",
   "metadata": {},
   "source": [
    "# üìÅ | Path Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd8780ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./_data\"\n",
    "TMP_PATH = \"./cys/_tmp\"\n",
    "OUTPUT_PATH = \"./cys/_output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bbe0e9",
   "metadata": {},
   "source": [
    "# ‚õèÔ∏è | Scraped Data\n",
    "\n",
    "load preprocessed data (by `junyeol_lee`)\n",
    "- Each entry are the datapoints for a patient (`ID`) on a specific date (`date`)\n",
    "- If there were multiple datapoints for a specific date (`date`) for a specific patient (`ID`), the values were processed (`sum`, `avg`, etc.) to a representation for the day\n",
    "- Questionnaire data was treated as a 'semi-trait' variable\n",
    "  - if a questionnaire was filled by the patient on a particular day all entries from that point forward will maintain the values of the questionnaire until the patient fills out the questionnaire again\n",
    "- Diary contents were added (20250613)\n",
    "\t- `mood`, `contents`\n",
    "- Certain columns were added back (20250613)\n",
    "  - demography: `suicide_need` (`boolean`)\n",
    "  - dailylog:\n",
    "    - `steps_maximum`\n",
    "\t- `steps_mean`\n",
    "\t- `step_hvar_mean`\n",
    "\t- `step_delta`\n",
    "\t- `step_max_delta`\n",
    "\t- `step_mean_delta`\n",
    "\t- `step_hvar_mean_delta`\n",
    "\t- `step_delta2`\n",
    "\t- `step_max_delta2`\n",
    "\t- `step_mean_delta2`\n",
    "\t- `step_hvar_mean_delta2`\n",
    "\t- `steps_variance`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dbe912",
   "metadata": {},
   "source": [
    "## Scraped Data Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aab7722c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables: 75\n",
      "   Demographic variables: 8\n",
      "   Daily log variables: 13\n",
      "   Life log variables: 37\n",
      "   Questionnaire variables: 17\n"
     ]
    }
   ],
   "source": [
    "scraped_data_filename = \"final_result_diary_20250617_03\"\n",
    "\n",
    "features_dict = {\n",
    "    \"scraped_data_filename\": scraped_data_filename,\n",
    "    \"preproc_version\": version,\n",
    "\t\"demography\": [\n",
    "\t\t'gender', 'age', 'marriage', 'job', 'smkHx', 'drinkHx', 'suicideHx', 'suicide_need'\n",
    "\t],\n",
    "\t\"dailylog\": [\n",
    "\t\t'panic', 'severity', 'exercise', 'alcohol', 'coffee', 'menstruation',\n",
    "\t\t'smoking', 'positive_feeling', 'negative_feeling', 'positive_E', 'negative_E',\n",
    "\t\t'anxiety', 'annoying'\n",
    "\t],\n",
    "\t\"lifelog\": [\n",
    "        'HR_var', 'HR_max', 'HR_mean', 'HR_hvar_mean', 'HR_acrophase', 'HR_amplitude', 'HR_mesor',\n",
    "        'HR_acrophase_difference', 'HR_acrophase_difference_2d', 'HR_amplitude_difference',\n",
    "        'HR_amplitude_difference_2d', 'HR_mesor_difference', 'HR_mesor_difference_2d',\n",
    "        'bandpower(0.001-0.0005Hz)', 'bandpower(0.0005-0.0001Hz)', 'bandpower(0.0001-0.00005Hz)', 'bandpower(0.00005-0.00001Hz)',\n",
    "        'steps', 'SLT1', 'SLT2', 'SLT3', 'SLT4', 'SLT5', 'SLT6', 'total_sleep',\n",
    "        'steps_maximum', 'steps_mean', 'step_hvar_mean', 'step_delta',\n",
    "        'step_max_delta', 'step_mean_delta', 'step_hvar_mean_delta',\n",
    "        'step_delta2', 'step_max_delta2', 'step_mean_delta2', 'step_hvar_mean_delta2', 'steps_variance'\n",
    "\t],\n",
    "\t\"questionnaire\": [\n",
    "\t\t'PHQ_9', 'STAI_X2', 'CSM', 'CTQ_1', 'CTQ_2', 'CTQ_3', 'CTQ_4', 'CTQ_5', 'KRQ', 'MDQ',\n",
    "\t\t'ACQ', 'APPQ_1', 'APPQ_2', 'APPQ_3', 'BSQ', 'GAD_7', 'BRIAN'\n",
    "\t],\n",
    "\t\"diary\":[\n",
    "        'mood', 'contents'\n",
    "\t],\n",
    "\t\"excluded\": [ # Dropped as variables were only in SYM dataset\n",
    "\t\t'SPAQ_1', 'SPAQ_2', 'BFNE', 'CES_D', 'KOSSSF', 'SADS', 'STAI_X1', 'medication_in_month',\n",
    "        'Unnamed: 0' # Placeholder column\n",
    "\t],\n",
    "    \"id\": [\n",
    "        'ID', 'date'\n",
    "    ],\n",
    "    \"label\": [\n",
    "        'panic', 'severity'\n",
    "    ],\n",
    "    \"metadata\": [\n",
    "        'coffee', 'smoking', 'total_sleep'\n",
    "    ],\n",
    "    \"metadata_calc\": [\n",
    "        'coffee', 'smoking', 'total_sleep'\n",
    "    ]\n",
    "}\n",
    "\n",
    "demo_vars = features_dict[\"demography\"]\n",
    "dailylog_vars = features_dict[\"dailylog\"]\n",
    "lifelog_vars = features_dict[\"lifelog\"]\n",
    "questionnaire_vars = features_dict[\"questionnaire\"]\n",
    "\n",
    "state_vars = demo_vars\n",
    "trait_vars = dailylog_vars + lifelog_vars + questionnaire_vars\n",
    "all_vars = state_vars + dailylog_vars + lifelog_vars + questionnaire_vars\n",
    "all_cols = features_dict[\"id\"] + all_vars + features_dict[\"diary\"]\n",
    "\n",
    "print(f'Number of variables: {len(all_vars)}')\n",
    "print(f'   Demographic variables: {len(state_vars)}')\n",
    "print(f'   Daily log variables: {len(dailylog_vars)}')\n",
    "print(f'   Life log variables: {len(lifelog_vars)}')\n",
    "print(f'   Questionnaire variables: {len(questionnaire_vars)}')\n",
    "\n",
    "# _ = save_dict_to_file(features_dict, TMP_PATH, \"scraped_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81218b4a",
   "metadata": {},
   "source": [
    "## Load Scraped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a279cfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (107577292.py) <module>: All expected columns are present in scraped_data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 28777\n",
      "Number of columns: 79\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>panic</th>\n",
       "      <th>gender</th>\n",
       "      <th>PHQ_9</th>\n",
       "      <th>STAI_X2</th>\n",
       "      <th>CSM</th>\n",
       "      <th>CTQ_1</th>\n",
       "      <th>CTQ_2</th>\n",
       "      <th>CTQ_3</th>\n",
       "      <th>...</th>\n",
       "      <th>SLT1</th>\n",
       "      <th>SLT2</th>\n",
       "      <th>SLT3</th>\n",
       "      <th>SLT4</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>severity</th>\n",
       "      <th>mood</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>15.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.07</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.68</td>\n",
       "      <td>7.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>6.19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID       date  panic  gender  PHQ_9  STAI_X2   CSM  CTQ_1  CTQ_2  \\\n",
       "0  PXPN_10006 2024-11-04    0.0       0    0.0     32.0  31.0   11.0   13.0   \n",
       "1  PXPN_10006 2024-11-05    0.0       0    0.0     32.0  31.0   11.0   13.0   \n",
       "2  PXPN_10006 2024-11-06    1.0       0    0.0     32.0  31.0   11.0   13.0   \n",
       "3  PXPN_10006 2024-11-07    2.0       0    0.0     32.0  31.0   11.0   13.0   \n",
       "4  PXPN_10006 2024-11-08    0.0       0    0.0     32.0  31.0   11.0   13.0   \n",
       "\n",
       "   CTQ_3  ...  SLT1  SLT2  SLT3  SLT4  SLT5  SLT6  total_sleep  severity  \\\n",
       "0   17.0  ...   NaN   NaN   NaN   NaN   NaN   NaN          NaN       NaN   \n",
       "1   17.0  ...   0.0  4.47  3.62  4.67  0.65  1.85        15.26       NaN   \n",
       "2   17.0  ...   0.0  0.00  0.20  4.07  1.43  1.68         7.38       NaN   \n",
       "3   17.0  ...   0.0  0.00  0.14  5.08  0.00  0.97         6.19       1.0   \n",
       "4   17.0  ...   NaN   NaN   NaN   NaN   NaN   NaN          NaN       NaN   \n",
       "\n",
       "   mood  contents  \n",
       "0   NaN       NaN  \n",
       "1   NaN       NaN  \n",
       "2   NaN       NaN  \n",
       "3   NaN       NaN  \n",
       "4   NaN       NaN  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scraped_data = read_csv(get_file_path(DATA_PATH, scraped_data_filename+'.csv'))\n",
    "\n",
    "# check if all columns are present\n",
    "missing_cols = [col for col in all_vars if col not in scraped_data.columns]\n",
    "if missing_cols:\n",
    "    logging.warning(f\"Missing columns in scraped_data: {missing_cols}\")\n",
    "else:\n",
    "\tlogging.info(\"All expected columns are present in scraped_data.\")\n",
    "extra_cols = [col for col in scraped_data.columns if col not in all_cols + features_dict[\"excluded\"]]\n",
    "if extra_cols:\n",
    "\tlogging.warning(f\"Extra columns in scraped_data: {extra_cols}\")\n",
    "\n",
    "# convert date column to datetime format\n",
    "scraped_data['date'] = pd.to_datetime(scraped_data['date'], format='%Y-%m-%d')\n",
    "remove_columns(scraped_data, ['Unnamed: 0'])\n",
    "\n",
    "# remove any of the columns in features_dict[\"excluded\"] if they exist\n",
    "for col in features_dict[\"excluded\"]:\n",
    "\tif col in scraped_data.columns:\n",
    "\t\tscraped_data.drop(columns=[col], inplace=True)\n",
    "\n",
    "print(f\"Number of rows: {scraped_data.shape[0]}\")\n",
    "print(f\"Number of columns: {scraped_data.shape[1]}\")\n",
    "display(scraped_data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6024277b",
   "metadata": {},
   "source": [
    "# ‚öíÔ∏è | Data Preprocessing\n",
    "\n",
    "Changes from scraped data:\n",
    "- add `entry_id` to identify each entry: `'ID'_'date'`\n",
    "- add `dataset` to identify source: `SYM1`, `SYM2`, `PXPN`\n",
    "- convert `panic` (`0`, `1`, `2` = panic) to days befor panic (`dbp`) (panic = `0`, `1`, `2`)\n",
    "- keep `panic` column instead of removing it (`20250617`)\n",
    "- add `panic_label` : whether a panic occurred in the entry (`boolean`)\n",
    "- demographic features were removed from preprocessed data (`data_pre`)\n",
    "- the data was filtered to remove entries with only demgraphic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5b1f06",
   "metadata": {},
   "source": [
    "## Initialize Preprocessed Data\n",
    "\n",
    "- add `entry_id` to identify each entry: `'ID'_'date'`\n",
    "- add `dataset` to identify source: `SYM1`, `SYM2`, `PXPN`\n",
    "- convert `panic` (`0`, `1`, `2` = panic) to days befor panic (`dbp`) (panic = `0`, `1`, `2`)\n",
    "- add `panic_label` (boolean)\n",
    "- keep `panic` column instead of removing it (`20250617`)\n",
    "> If using `panic` column as a label this must be removed as a feature from final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d5a6ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique entry IDs: 28777\n",
      "Scraped data shape: (28777, 79)\n",
      "Initialized preprocessed data shape: (28777, 83)\n"
     ]
    }
   ],
   "source": [
    "data_pre_init = create_empty_df()\n",
    "data_pre_init = scraped_data.copy()\n",
    "\n",
    "# Add 'entry_id' column: unique identifier for each row\n",
    "data_pre_init['entry_id'] = data_pre_init['ID'] + '_' + data_pre_init['date'].astype(str)\n",
    "instance_id_unique = data_pre_init['entry_id'].unique()\n",
    "move_column(data_pre_init, 'entry_id', 0)\n",
    "print(\"Number of unique entry IDs:\", len(instance_id_unique))\n",
    "# Check if 'entry_id' is unique\n",
    "if data_pre_init['entry_id'].duplicated().any():\n",
    "\t# return the rows with duplicate 'entry_id'\n",
    "\tduplicates = data_pre_init[data_pre_init['entry_id'].duplicated(keep=False)]\n",
    "\tdisplay(duplicates.head(5))\n",
    "\tsave_as_csv(duplicates, TMP_PATH, f\"duplicates_{scraped_data_filename}\")\n",
    "\traise ValueError(\"Duplicate 'entry_id' found in the data. Please resolve this issue before proceeding.\")\n",
    "\n",
    "# Add 'dataset' column: source of data\n",
    "data_pre_init['dataset'] = data_pre_init['ID'].str.split('_').str[0]\n",
    "data_pre_init['dataset'] = data_pre_init['dataset'].str.split('-').str[0]\n",
    "move_column(data_pre_init, 'dataset', 1)\n",
    "\n",
    "# Convert 'panic' column to Days Before Panic (dbp)\n",
    "data_pre_init['dbp'] = data_pre_init.apply(\n",
    "\tlambda row: np.nan if row['panic'] == 0\n",
    " \t\t\t\telse 0 if row['panic'] == 2 else row['panic'],\n",
    "\taxis=1\n",
    ")\n",
    "# TODO: keep 'panic' column\n",
    "# NOTE: Rember to remove 'panic' column on final training/dev/test set as this is a label and not a feature\n",
    "# remove_columns(data_pre_init, ['panic'])\n",
    "\n",
    "# TODO: Temporarily remove 'diary' columns\n",
    "# remove_columns(data_pre_init, features_dict['diary'])\n",
    "\n",
    "# Add panic_label column\n",
    "data_pre_init['panic_label'] = data_pre_init['panic'].apply(lambda x: 1 if x == 2 else 0)\n",
    "\n",
    "# Update the features_dict\n",
    "if 'entry_id' not in features_dict['id']:\n",
    "\tfeatures_dict['id'].insert(0, 'entry_id')\n",
    "if 'dataset' not in features_dict['id']:\n",
    "\tfeatures_dict['id'].append('dataset')\n",
    "if 'dbp' not in features_dict['dailylog']:\n",
    "\tfeatures_dict['label'].insert(0, 'dbp')\n",
    "if 'panic_label' not in features_dict['label']:\n",
    "\tfeatures_dict['label'].append('panic_label')\n",
    " \n",
    "# TODO: keep 'panic' column\n",
    "# NOTE: Rember to remove 'panic' column on final training/dev/test set as this is a label and not a feature\n",
    "# if 'panic' in features_dict['dailylog']:\n",
    "# \tfeatures_dict['dailylog'].remove('panic')\n",
    "\n",
    "# print scraped_data shape\n",
    "print(f\"Scraped data shape: {scraped_data.shape}\")\n",
    "print(f\"Initialized preprocessed data shape: {data_pre_init.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "276b12c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>panic</th>\n",
       "      <th>gender</th>\n",
       "      <th>PHQ_9</th>\n",
       "      <th>STAI_X2</th>\n",
       "      <th>CSM</th>\n",
       "      <th>CTQ_1</th>\n",
       "      <th>...</th>\n",
       "      <th>SLT3</th>\n",
       "      <th>SLT4</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>severity</th>\n",
       "      <th>mood</th>\n",
       "      <th>contents</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006_2024-11-04</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10006_2024-11-05</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>15.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PXPN_10006_2024-11-06</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.07</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.68</td>\n",
       "      <td>7.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PXPN_10006_2024-11-07</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>6.19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PXPN_10006_2024-11-08</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                entry_id dataset          ID       date  panic  gender  PHQ_9  \\\n",
       "0  PXPN_10006_2024-11-04    PXPN  PXPN_10006 2024-11-04    0.0       0    0.0   \n",
       "1  PXPN_10006_2024-11-05    PXPN  PXPN_10006 2024-11-05    0.0       0    0.0   \n",
       "2  PXPN_10006_2024-11-06    PXPN  PXPN_10006 2024-11-06    1.0       0    0.0   \n",
       "3  PXPN_10006_2024-11-07    PXPN  PXPN_10006 2024-11-07    2.0       0    0.0   \n",
       "4  PXPN_10006_2024-11-08    PXPN  PXPN_10006 2024-11-08    0.0       0    0.0   \n",
       "\n",
       "   STAI_X2   CSM  CTQ_1  ...  SLT3  SLT4  SLT5  SLT6  total_sleep  severity  \\\n",
       "0     32.0  31.0   11.0  ...   NaN   NaN   NaN   NaN          NaN       NaN   \n",
       "1     32.0  31.0   11.0  ...  3.62  4.67  0.65  1.85        15.26       NaN   \n",
       "2     32.0  31.0   11.0  ...  0.20  4.07  1.43  1.68         7.38       NaN   \n",
       "3     32.0  31.0   11.0  ...  0.14  5.08  0.00  0.97         6.19       1.0   \n",
       "4     32.0  31.0   11.0  ...   NaN   NaN   NaN   NaN          NaN       NaN   \n",
       "\n",
       "   mood  contents  dbp  panic_label  \n",
       "0   NaN       NaN  NaN            0  \n",
       "1   NaN       NaN  NaN            0  \n",
       "2   NaN       NaN  1.0            0  \n",
       "3   NaN       NaN  0.0            1  \n",
       "4   NaN       NaN  NaN            0  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique sources in metadata_ljy:  ['PXPN' 'SYM1' 'SYM2']\n",
      "Number of entries in metadata_ljy: 28777\n",
      "    SYM entries: 27938\n",
      "    PXPN entries: 839\n",
      "Number of unique IDs in metadata_ljy: 429\n",
      "    SYM IDs:  400\n",
      "    PXPN IDs:  29\n",
      "Number of panic events (dbp=0): 811\n"
     ]
    }
   ],
   "source": [
    "display(data_pre_init.head(5))\n",
    "print(\"Unique sources in metadata_ljy: \", data_pre_init['dataset'].unique())\n",
    "print(\"Number of entries in metadata_ljy:\", data_pre_init.shape[0])\n",
    "sym1_n = data_pre_init[data_pre_init['dataset'] == 'SYM1'].shape[0]\n",
    "sym2_n = data_pre_init[data_pre_init['dataset'] == 'SYM2'].shape[0]\n",
    "print(\"    SYM entries:\", sym1_n+sym2_n)\n",
    "print(\"    PXPN entries:\", data_pre_init[data_pre_init['dataset'] == 'PXPN'].shape[0])\n",
    "print(\"Number of unique IDs in metadata_ljy:\", len(data_pre_init['ID'].unique()))\n",
    "# find the unique IDs for SYM1 and SYM2\n",
    "sym1_ids = data_pre_init[data_pre_init['dataset'] == 'SYM1']['ID'].unique()\n",
    "sym2_ids = data_pre_init[data_pre_init['dataset'] == 'SYM2']['ID'].unique()\n",
    "print(\"    SYM IDs: \", len(sym1_ids)+len(sym2_ids))\n",
    "print(\"    PXPN IDs: \", len(data_pre_init[data_pre_init['dataset'] == 'PXPN']['ID'].unique()))\n",
    "print(\"Number of panic events (dbp=0):\", data_pre_init[data_pre_init['dbp'] == 0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7cac54",
   "metadata": {},
   "source": [
    "## Initialize Metadata\n",
    "\n",
    "initialize `metadata` by adding\n",
    "- `demography_data` : whether demography data exists in the entry (`boolean`)\n",
    "- `dailylog_data`, `lifelog_data`, `questionnaire_data` : whether each data group exists in the entry (`boolean`)\n",
    "- `dtype_n` : how many of the 3 `state` groups exists in the entry (`int`)\n",
    "- `diary_data`: whether panic diary data group exists in the entry (`boolean`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ed181f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>panic</th>\n",
       "      <th>gender</th>\n",
       "      <th>PHQ_9</th>\n",
       "      <th>STAI_X2</th>\n",
       "      <th>dtype_n</th>\n",
       "      <th>CSM</th>\n",
       "      <th>...</th>\n",
       "      <th>severity</th>\n",
       "      <th>mood</th>\n",
       "      <th>contents</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic_label</th>\n",
       "      <th>demography_data</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "      <th>diary_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006_2024-11-04</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10006_2024-11-05</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PXPN_10006_2024-11-06</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PXPN_10006_2024-11-07</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PXPN_10006_2024-11-08</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                entry_id dataset          ID       date  panic  gender  PHQ_9  \\\n",
       "0  PXPN_10006_2024-11-04    PXPN  PXPN_10006 2024-11-04    0.0       0    0.0   \n",
       "1  PXPN_10006_2024-11-05    PXPN  PXPN_10006 2024-11-05    0.0       0    0.0   \n",
       "2  PXPN_10006_2024-11-06    PXPN  PXPN_10006 2024-11-06    1.0       0    0.0   \n",
       "3  PXPN_10006_2024-11-07    PXPN  PXPN_10006 2024-11-07    2.0       0    0.0   \n",
       "4  PXPN_10006_2024-11-08    PXPN  PXPN_10006 2024-11-08    0.0       0    0.0   \n",
       "\n",
       "   STAI_X2  dtype_n   CSM  ...  severity  mood  contents  dbp  panic_label  \\\n",
       "0     32.0        3  31.0  ...       NaN   NaN       NaN  NaN            0   \n",
       "1     32.0        3  31.0  ...       NaN   NaN       NaN  NaN            0   \n",
       "2     32.0        3  31.0  ...       NaN   NaN       NaN  1.0            0   \n",
       "3     32.0        3  31.0  ...       1.0   NaN       NaN  0.0            1   \n",
       "4     32.0        3  31.0  ...       NaN   NaN       NaN  NaN            0   \n",
       "\n",
       "   demography_data  dailylog_data  lifelog_data  questionnaire_data  \\\n",
       "0                1              1             1                   1   \n",
       "1                1              1             1                   1   \n",
       "2                1              1             1                   1   \n",
       "3                1              1             1                   1   \n",
       "4                1              1             1                   1   \n",
       "\n",
       "   diary_data  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata_init = create_empty_df()\n",
    "metadata_init = data_pre_init.copy()\n",
    "\n",
    "metadata_init['demography_data'] = metadata_init[features_dict['demography']].notnull().any(axis=1).astype(int)\n",
    "metadata_init['dailylog_data'] = metadata_init[features_dict['dailylog']].notnull().any(axis=1).astype(int)\n",
    "metadata_init['lifelog_data'] = metadata_init[features_dict['lifelog']].notnull().any(axis=1).astype(int)\n",
    "metadata_init['questionnaire_data'] = metadata_init[features_dict['questionnaire']].notnull().any(axis=1).astype(int)\n",
    "metadata_init['diary_data'] = metadata_init[features_dict['diary']].notnull().any(axis=1).astype(int)\n",
    "\n",
    "# TODO: Diary data is not used in the current analysis, but can be useful for future reference\n",
    "metadata_init['dtype_n'] = metadata_init['dailylog_data'] + metadata_init['lifelog_data'] + metadata_init['questionnaire_data']\n",
    "move_column(metadata_init, 'dtype_n', 8)\n",
    "\n",
    "add_list = ['dailylog_data', 'lifelog_data', 'questionnaire_data', 'dtype_n', 'diary_data']\n",
    "for item in add_list:\n",
    "\tif item not in features_dict['metadata']:\n",
    "\t\tfeatures_dict['metadata'].append(item)\n",
    "del add_list\n",
    "\n",
    "check_metadata = False\n",
    "if check_metadata:\n",
    "    check_type = 'questionnaire' # demography, dailylog, lifelog, questionnaire\n",
    "    check_for = 0\n",
    "    test = metadata_init[metadata_init[check_type+'_data'] == check_for].copy()\n",
    "    test = test[features_dict['id']+features_dict['metadata']+features_dict[check_type]]\n",
    "    print(f\"--------- TEST {test.shape[0]} ENTRIES WITH {check_type} = {check_for} ---------\")\n",
    "    display(test.head(10))\n",
    "    save_as_csv(test, TMP_PATH, f\"metadata_{check_type}_{check_for}\")\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    del test, check_type, check_for\n",
    "\n",
    "display(metadata_init.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dccf3dc",
   "metadata": {},
   "source": [
    "## Extract Demography Data\n",
    "\n",
    "- All patients within the scraped data were confirmed to have demographic data (`demography_data` = `True`)\n",
    "- as such demography_data will not be included in the `metadata`\n",
    "- Demography data was extracted and saved as `demography.csv` to the `output` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efc9a7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All demographic columns are unique for each ID in demo_data.\n",
      "Number of rows in demo_data: 429\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>marriage</th>\n",
       "      <th>job</th>\n",
       "      <th>smkHx</th>\n",
       "      <th>drinkHx</th>\n",
       "      <th>suicideHx</th>\n",
       "      <th>suicide_need</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10007</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PXPN_10008</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PXPN_10009</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PXPN_10010</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  gender   age  marriage  job  smkHx  drinkHx  suicideHx  \\\n",
       "0  PXPN_10006       0  32.0       0.0  1.0    1.0      1.0        0.0   \n",
       "1  PXPN_10007       1  38.0       1.0  1.0    0.0      0.0        0.0   \n",
       "2  PXPN_10008       0  38.0       1.0  0.0    0.0      1.0        0.0   \n",
       "3  PXPN_10009       1  28.0       0.0  0.0    1.0      0.0        1.0   \n",
       "4  PXPN_10010       1  21.0       0.0  0.0    1.0      1.0        0.0   \n",
       "\n",
       "   suicide_need  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - (path_utils.py) make_dir: Created directory: C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\cys\\_output\n",
      "DEBUG - (text_utils.py) save_as_csv: Saved panic_demography_data_1-3(final_result_diary_20250617_03).csv to C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\cys\\_output\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/cyshi/OneDrive/Documents/GitHub/Panic-Project-CYS/cys/_output/panic_demography_data_1-3(final_result_diary_20250617_03).csv')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_matrix = [\n",
    "\t('gender_n', 'gender', 'nunique'),\n",
    "\t('age_n', 'age', 'nunique'),\n",
    "\t('marriage_n', 'marriage', 'nunique'),\n",
    "\t('job_n', 'job', 'nunique'),\n",
    "\t('smkHx_n', 'smkHx', 'nunique'),\n",
    "\t('drinkHx_n', 'drinkHx', 'nunique'),\n",
    "\t('suicideHx_n', 'suicideHx', 'nunique'),\n",
    "\t('suicide_need_n', 'suicide_need', 'nunique'),\n",
    "    ('gender', 'gender', 'first'),\n",
    "\t('age', 'age', 'first'),\n",
    "\t('marriage', 'marriage', 'first'),\n",
    "\t('job', 'job', 'first'),\n",
    "\t('smkHx', 'smkHx', 'first'),\n",
    "\t('drinkHx', 'drinkHx', 'first'),\n",
    "\t('suicideHx', 'suicideHx', 'first'),\n",
    "\t('suicide_need', 'suicide_need', 'first'),\n",
    "]\n",
    "demo_data = create_empty_df()\n",
    "demo_data = aggregate_by_column(metadata_init, 'ID', agg_matrix)\n",
    "# check if the length of each unique value is 1\n",
    "non_unique_cols = []\n",
    "for col in features_dict['demography']:\n",
    "\tif demo_data[col+'_n'].apply(lambda x: x > 1).any():\n",
    "\t\tnon_unique_cols.append(col)\n",
    "if non_unique_cols:\n",
    "\traise ValueError(f\"Demographic columns {non_unique_cols} are not unique for each ID in demo_data.\")\n",
    "else:\n",
    "\tprint(\"All demographic columns are unique for each ID in demo_data.\")\n",
    "\n",
    "for col in features_dict['demography']:\n",
    "\tremove_columns(demo_data, [col+'_n'])\n",
    "print(f\"Number of rows in demo_data: {demo_data.shape[0]}\")\n",
    "display(demo_data.head(5))\n",
    "\n",
    "save_as_csv(demo_data, OUTPUT_PATH, f\"panic_demography_data_{version}({scraped_data_filename})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e384fd55",
   "metadata": {},
   "source": [
    "## Extract Panic Diary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26c08088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in panic_diary_data: 775\n",
      "Number of unique patients in panic_diary_data: 65\n",
      "Unique datasets in panic_diary_data: ['SYM1' 'SYM2']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset</th>\n",
       "      <th>mood</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>SYM1-1-100_2021-03-03</td>\n",
       "      <td>SYM1-1-100</td>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>ÏÑ§Î†ò</td>\n",
       "      <td>ÏπúÌïú ÏπúÍµ¨ÏôÄ Ïò§ÎûúÎßåÏóê ÎßåÎÇ®</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>SYM1-1-103_2021-03-03</td>\n",
       "      <td>SYM1-1-103</td>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>Í∏∞ÏÅ®</td>\n",
       "      <td>„Öé„Öé„Öé„Öé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718</th>\n",
       "      <td>SYM1-1-133_2021-04-27</td>\n",
       "      <td>SYM1-1-133</td>\n",
       "      <td>2021-04-27</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>ÌñâÎ≥µ</td>\n",
       "      <td>ÌñâÎ≥µÌïòÏûê ÏïÑÌîÑÏßÄÎßêÍ≥†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>SYM1-1-133_2021-05-02</td>\n",
       "      <td>SYM1-1-133</td>\n",
       "      <td>2021-05-02</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>ÌñâÎ≥µ</td>\n",
       "      <td>Ïò§ÎûúÎßåÏóê Í∞ÄÏ°±Îì§Í≥º Ìï®Íªò ÏãúÍ∞ÑÏùÑ Î≥¥ÎÉàÎã§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>SYM1-1-133_2021-06-17</td>\n",
       "      <td>SYM1-1-133</td>\n",
       "      <td>2021-06-17</td>\n",
       "      <td>SYM1</td>\n",
       "      <td>ÌñâÎ≥µ</td>\n",
       "      <td>Í∏àÏöîÏùºÏù¥Îùº ÌñâÎ≥µÌï¥Ïöî</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   entry_id          ID       date dataset mood  \\\n",
       "840   SYM1-1-100_2021-03-03  SYM1-1-100 2021-03-03    SYM1   ÏÑ§Î†ò   \n",
       "1018  SYM1-1-103_2021-03-03  SYM1-1-103 2021-03-03    SYM1   Í∏∞ÏÅ®   \n",
       "1718  SYM1-1-133_2021-04-27  SYM1-1-133 2021-04-27    SYM1   ÌñâÎ≥µ   \n",
       "1723  SYM1-1-133_2021-05-02  SYM1-1-133 2021-05-02    SYM1   ÌñâÎ≥µ   \n",
       "1769  SYM1-1-133_2021-06-17  SYM1-1-133 2021-06-17    SYM1   ÌñâÎ≥µ   \n",
       "\n",
       "                  contents  \n",
       "840         ÏπúÌïú ÏπúÍµ¨ÏôÄ Ïò§ÎûúÎßåÏóê ÎßåÎÇ®  \n",
       "1018                  „Öé„Öé„Öé„Öé  \n",
       "1718            ÌñâÎ≥µÌïòÏûê ÏïÑÌîÑÏßÄÎßêÍ≥†  \n",
       "1723  Ïò§ÎûúÎßåÏóê Í∞ÄÏ°±Îì§Í≥º Ìï®Íªò ÏãúÍ∞ÑÏùÑ Î≥¥ÎÉàÎã§  \n",
       "1769            Í∏àÏöîÏùºÏù¥Îùº ÌñâÎ≥µÌï¥Ïöî  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - (text_utils.py) save_as_csv: Saved panic_diary_data_1-3(final_result_diary_20250617_03).csv to C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\cys\\_output\n"
     ]
    }
   ],
   "source": [
    "if all(col in data_pre_init.columns for col in features_dict['diary']):\n",
    "\tpanic_diary_data = create_empty_df()\n",
    "\tpanic_diary_data = data_pre_init[features_dict['id'] + features_dict['diary']].copy()\n",
    "\n",
    "\tpanic_diary_entries = metadata_init[metadata_init['diary_data'] == 1]['entry_id'].unique()\n",
    "\t# Filter panic_diary_data to only include entries with diary data\n",
    "\tpanic_diary_data = panic_diary_data[panic_diary_data['entry_id'].isin(panic_diary_entries)]\n",
    "\n",
    "\tprint(f\"Number of rows in panic_diary_data: {panic_diary_data.shape[0]}\")\n",
    "\tprint(f\"Number of unique patients in panic_diary_data: {panic_diary_data['ID'].nunique()}\")\n",
    "\tprint(f\"Unique datasets in panic_diary_data: {panic_diary_data['dataset'].unique()}\")\n",
    "\tdisplay(panic_diary_data.head(5))\n",
    "\n",
    "\tsave_as_csv(panic_diary_data, OUTPUT_PATH, f\"panic_diary_data_{version}({scraped_data_filename})\")\n",
    "\tremove_columns(data_pre_init, features_dict['diary'])  # Remove diary columns from data_pre_init\n",
    "else:\n",
    "\tprint(\"No diary data found in the scraped data. Skipping panic_diary_data creation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd52f179",
   "metadata": {},
   "source": [
    "## Construct Intermediate Metadata\n",
    "- the current `metadata` (`metadata_init`) was filtered to include only columns for identification, added columns for metadata, and labels\n",
    "- the `metadata` was also filtered to get rid of all entries that only have demography data (`dtype_n` = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95b509aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset</th>\n",
       "      <th>coffee</th>\n",
       "      <th>smoking</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "      <th>dtype_n</th>\n",
       "      <th>diary_data</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic</th>\n",
       "      <th>severity</th>\n",
       "      <th>panic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006_2024-11-04</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10006_2024-11-05</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PXPN_10006_2024-11-06</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PXPN_10006_2024-11-07</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PXPN_10006_2024-11-08</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                entry_id          ID       date dataset  coffee  smoking  \\\n",
       "0  PXPN_10006_2024-11-04  PXPN_10006 2024-11-04    PXPN     NaN      NaN   \n",
       "1  PXPN_10006_2024-11-05  PXPN_10006 2024-11-05    PXPN     NaN      NaN   \n",
       "2  PXPN_10006_2024-11-06  PXPN_10006 2024-11-06    PXPN     NaN      NaN   \n",
       "3  PXPN_10006_2024-11-07  PXPN_10006 2024-11-07    PXPN     NaN      NaN   \n",
       "4  PXPN_10006_2024-11-08  PXPN_10006 2024-11-08    PXPN     NaN      NaN   \n",
       "\n",
       "   total_sleep  dailylog_data  lifelog_data  questionnaire_data  dtype_n  \\\n",
       "0          NaN              1             1                   1        3   \n",
       "1        15.26              1             1                   1        3   \n",
       "2         7.38              1             1                   1        3   \n",
       "3         6.19              1             1                   1        3   \n",
       "4          NaN              1             1                   1        3   \n",
       "\n",
       "   diary_data  dbp  panic  severity  panic_label  \n",
       "0           0  NaN    0.0       NaN            0  \n",
       "1           0  NaN    0.0       NaN            0  \n",
       "2           0  1.0    1.0       NaN            0  \n",
       "3           0  0.0    2.0       1.0            1  \n",
       "4           0  NaN    0.0       NaN            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata_int = create_empty_df()\n",
    "metadata_int = metadata_init.copy()\n",
    "\n",
    "metadata_int = metadata_int[features_dict['id'] + features_dict['metadata'] + features_dict['label']]\n",
    "move_column(metadata_int, 'severity', -1)\n",
    "move_column(metadata_int, 'panic_label', -1)\n",
    "# metadata_int = metadata_int[metadata_int['dtype_n'] > 0]\n",
    "metadata_int = metadata_int[metadata_int['date'].notnull()]\n",
    "display(metadata_int.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c967c9",
   "metadata": {},
   "source": [
    "## Filter Preprocessed Data\n",
    "\n",
    "- demographic features were removed from preprocessed data (`data_pre`)\n",
    "- the data was filtered to remove entries with only demgraphic data\n",
    "- the removed IDs were checked to see if no relevant entries were discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e29ca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre = create_empty_df()\n",
    "data_pre = data_pre_init.copy()\n",
    "# Remove demographic features from data_proc\n",
    "remove_columns(data_pre, features_dict['demography'])\n",
    "# Filter data_proc to keep only rows with entry IDs present in metadata_int\n",
    "metadata_int_unique_ids = metadata_int['entry_id'].unique()\n",
    "data_pre = data_pre[data_pre['entry_id'].isin(metadata_int_unique_ids)]\n",
    "\n",
    "# remove rows with null dates\n",
    "data_pre = data_pre[data_pre['date'].notnull()]\n",
    "\n",
    "# Find IDs present in unfiltered_data but missing in filtered_data (i.e., lost after filtering)\n",
    "check_missing_ids = False\n",
    "if check_missing_ids:\n",
    "\tmissing_ids = np.setdiff1d(data_pre_init['ID'].unique(), data_pre['ID'].unique())\n",
    "\tmissing_data = data_pre_init[data_pre_init['ID'].isin(missing_ids)]\n",
    "\tprint(f\"Number of IDs lost after filtering: {len(missing_ids)}\")\n",
    "\t_ = save_as_csv(missing_data, TMP_PATH, f\"missing_{scraped_data_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cc84e1",
   "metadata": {},
   "source": [
    "## üíæ | Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2daa5322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - (text_utils.py) save_as_csv: Saved panic_pre_data_1-3(final_result_diary_20250617_03).csv to C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\cys\\_output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>panic</th>\n",
       "      <th>PHQ_9</th>\n",
       "      <th>STAI_X2</th>\n",
       "      <th>CSM</th>\n",
       "      <th>CTQ_1</th>\n",
       "      <th>CTQ_2</th>\n",
       "      <th>...</th>\n",
       "      <th>SLT1</th>\n",
       "      <th>SLT2</th>\n",
       "      <th>SLT3</th>\n",
       "      <th>SLT4</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>severity</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006_2024-11-04</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10006_2024-11-05</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>15.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PXPN_10006_2024-11-06</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.07</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.68</td>\n",
       "      <td>7.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                entry_id dataset          ID       date  panic  PHQ_9  \\\n",
       "0  PXPN_10006_2024-11-04    PXPN  PXPN_10006 2024-11-04    0.0    0.0   \n",
       "1  PXPN_10006_2024-11-05    PXPN  PXPN_10006 2024-11-05    0.0    0.0   \n",
       "2  PXPN_10006_2024-11-06    PXPN  PXPN_10006 2024-11-06    1.0    0.0   \n",
       "\n",
       "   STAI_X2   CSM  CTQ_1  CTQ_2  ...  SLT1  SLT2  SLT3  SLT4  SLT5  SLT6  \\\n",
       "0     32.0  31.0   11.0   13.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1     32.0  31.0   11.0   13.0  ...   0.0  4.47  3.62  4.67  0.65  1.85   \n",
       "2     32.0  31.0   11.0   13.0  ...   0.0  0.00  0.20  4.07  1.43  1.68   \n",
       "\n",
       "   total_sleep  severity  dbp  panic_label  \n",
       "0          NaN       NaN  NaN            0  \n",
       "1        15.26       NaN  NaN            0  \n",
       "2         7.38       NaN  1.0            0  \n",
       "\n",
       "[3 rows x 73 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Total entries in original:  28777\n",
      "    SYM entries: 27938\n",
      "    PXPN entries: 839\n",
      "Number of unique IDs in original: 429\n",
      "    SYM IDs:  400\n",
      "    PXPN IDs:  29\n",
      "Number of panic events (dbp=0): 811\n",
      "--------------------------------------------------------\n",
      "Total entries in filtered:  28625\n",
      "    SYM entries: 27786\n",
      "    PXPN entries: 839\n",
      "Number of unique IDs in filtered: 277\n",
      "    SYM IDs:  248\n",
      "    PXPN IDs:  29\n",
      "Number of panic events (dbp=0): 811\n"
     ]
    }
   ],
   "source": [
    "# save data_pre to CSV\n",
    "save_as_csv(data_pre, OUTPUT_PATH, f\"panic_pre_data_{version}({scraped_data_filename})\")\n",
    "\n",
    "display(data_pre.head(3))\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"Total entries in original: \", data_pre_init.shape[0])\n",
    "sym1_n = data_pre_init[data_pre_init['dataset'] == 'SYM1'].shape[0]\n",
    "sym2_n = data_pre_init[data_pre_init['dataset'] == 'SYM2'].shape[0]\n",
    "print(\"    SYM entries:\", sym1_n+sym2_n)\n",
    "print(\"    PXPN entries:\", data_pre_init[data_pre_init['dataset'] == 'PXPN'].shape[0])\n",
    "print(\"Number of unique IDs in original:\", len(data_pre_init['ID'].unique()))\n",
    "# find the unique IDs for SYM1 and SYM2\n",
    "sym1_ids = data_pre_init[data_pre_init['dataset'] == 'SYM1']['ID'].unique()\n",
    "sym2_ids = data_pre_init[data_pre_init['dataset'] == 'SYM2']['ID'].unique()\n",
    "print(\"    SYM IDs: \", len(sym1_ids)+len(sym2_ids))\n",
    "print(\"    PXPN IDs: \", len(data_pre_init[data_pre_init['dataset'] == 'PXPN']['ID'].unique()))\n",
    "print(\"Number of panic events (dbp=0):\", data_pre_init[data_pre_init['dbp'] == 0].shape[0])\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"Total entries in filtered: \", data_pre.shape[0])\n",
    "sym1_n = data_pre[data_pre['dataset'] == 'SYM1'].shape[0]\n",
    "sym2_n = data_pre[data_pre['dataset'] == 'SYM2'].shape[0]\n",
    "print(\"    SYM entries:\", sym1_n+sym2_n)\n",
    "print(\"    PXPN entries:\", data_pre[data_pre['dataset'] == 'PXPN'].shape[0])\n",
    "print(\"Number of unique IDs in filtered:\", len(data_pre['ID'].unique()))\n",
    "# find the unique IDs for SYM1 and SYM2\n",
    "sym1_ids = data_pre[data_pre['dataset'] == 'SYM1']['ID'].unique()\n",
    "sym2_ids = data_pre[data_pre['dataset'] == 'SYM2']['ID'].unique()\n",
    "print(\"    SYM IDs: \", len(sym1_ids)+len(sym2_ids))\n",
    "print(\"    PXPN IDs: \", len(data_pre[data_pre['dataset'] == 'PXPN']['ID'].unique()))\n",
    "print(\"Number of panic events (dbp=0):\", data_pre[data_pre['dbp'] == 0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7e6270",
   "metadata": {},
   "source": [
    "# üìñ | Metadata\n",
    "\n",
    "**Description**\n",
    "- `entry_id`: ID for each entry `'ID'_'date'`\n",
    "- `ID`: ID for each patient\n",
    "- `date`: logging date of each entry\n",
    "- `dataset`: source of entry (`SYM1`, `SYM2`, `PXPN`)\n",
    "- `dailylog_data`: whether daily log data exists in the entry (`boolean`)\n",
    "- `lifelog_data`: whether life log data exists in the entry (`boolean`)\n",
    "- `questionnaire_data`: whether questionnaire data exists in the entry (`boolean`)\n",
    "- `dtype_n`: how many of the 3 `state` groups exists in the entry (`int`)\n",
    "- `diary_data`: whether panic diary data exists in the entry (`boolean`)\n",
    "- `dbp`: number of consecutive days prior to panic. i.e. panic day = 0; 1 day prior = 1; etc. (up to 3)\n",
    "- `n_prior_data`: number of existing consecutive prior (days) entries\n",
    "- `ref_event_id`: the `entry_id` to which days before panic (`dbp`) is referencing\n",
    "- `valid_entry_3`: whether the entry has 3 consecutive days of prior data (`n_prior_data`)\n",
    "- `valid_entry_2`: whether the entry has 2 consecutive days of prior data (`n_prior_data`)\n",
    "- `valid_entry_1`: whether the entry has 1 consecutive days of prior data (`n_prior_data`)\n",
    "- `panic_label`: whether a panic occured in the entry (`boolean`)\n",
    "- `severity`: severity of the panic (1 ~ 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277e7f97",
   "metadata": {},
   "source": [
    "## Calculate Days Before Panic (``dbp``) and Prior Consecutive Days (``n_prior_data``)\n",
    "\n",
    "- calculate the consecutive 'days before panic' (`dbp`):\n",
    "  - day when panic occured -> `dbp` = 0\n",
    "  - 1 day before panic -> `dbp` = 1\n",
    "  - 2 day before panic -> `dbp` = 2\n",
    "  - 3 day before panic -> `dbp` = 3 (etc)\n",
    "  - stop calculating at a set limit (`delta_days`) or if a panic occurred within the limit\n",
    "- calculate the number of existing prior consecutive (days) entries (`n_prior_data`) (Default: 3)\n",
    "  - stop calculating at a certain limit (`lookback_limit`) (Default: 7)\n",
    "\n",
    "> May take ~ 1 to 2 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f133fed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 100.00% complete\r"
     ]
    }
   ],
   "source": [
    "metadata_calc = create_empty_df()\n",
    "metadata_calc = metadata_int.copy()\n",
    "\n",
    "metadata_calc['n_prior_data']    = None\n",
    "metadata_calc['ref_event_id']    = None\n",
    "move_column(metadata_calc, 'panic_label', -1)\n",
    "move_column(metadata_calc, 'severity', -1)\n",
    "metadata_calc.sort_values(by=['ID', 'date'], ascending=False, inplace=True)\n",
    "\n",
    "d_days = 3\n",
    "l_back_lim = 7\n",
    "\n",
    "def calculate_days_before_panic(df, patient_id, delta_days=3, lookback_limit=7):\n",
    "    patient_data = df[df['ID'] == patient_id]\n",
    "    entry_dates_series = patient_data['date']\n",
    "    if len(set(entry_dates_series)) != len(entry_dates_series):\n",
    "        raise ValueError(f\"Duplicate dates found for patient {patient_id}. Please check the data.\")\n",
    "    panic_dates_series = patient_data[patient_data['dbp'] == 0]['date']\n",
    "    if len(set(panic_dates_series)) != len(panic_dates_series):\n",
    "        raise ValueError(f\"Duplicate panic dates found for patient {patient_id}. Please check the data.\")\n",
    "    \n",
    "    entry_dates = set(entry_dates_series)\n",
    "    panic_dates = set(panic_dates_series)\n",
    "\n",
    "    for panic_date in sorted(panic_dates, reverse=True): # Sort from latest to earliest\n",
    "        index = patient_data[patient_data['date'] == panic_date].index[0]\n",
    "        event_id = patient_data.loc[index, 'entry_id']\n",
    "        df.loc[index, 'dbp'] = 0\n",
    "        for j in range(1, delta_days + 1):\n",
    "            prior_date = panic_date - pd.Timedelta(days=j)\n",
    "            if prior_date in entry_dates:\n",
    "                index = patient_data[patient_data['date'] == prior_date].index[0]\n",
    "                df.loc[index, 'dbp'] = j\n",
    "                df.loc[index, 'ref_event_id'] = event_id\n",
    "    \n",
    "    for entry_date in sorted(entry_dates, reverse=True):\n",
    "        for j in range(1, lookback_limit + 1):\n",
    "            if j == lookback_limit+1:\n",
    "                df.loc[index, 'n_prior_data'] = j\n",
    "                break\n",
    "            prior_date = entry_date - pd.Timedelta(days=j)\n",
    "            if prior_date not in entry_dates:\n",
    "                break\n",
    "            index = patient_data[patient_data['date'] == prior_date].index[0]\n",
    "            if df.loc[index, 'panic_label'] == 1:\n",
    "                break\n",
    "            index = patient_data[patient_data['date'] == entry_date].index[0]\n",
    "            df.loc[index, 'n_prior_data'] = j\n",
    "\n",
    "def process_calculate_days_before_panic(df, delta_days=3, lookback_limit=7):\n",
    "    patient_ids = df['ID'].unique()\n",
    "    for patient_id in patient_ids:\n",
    "        calculate_days_before_panic(df, patient_id, delta_days, lookback_limit)\n",
    "        progress = (np.where(patient_ids == patient_id)[0][0] + 1) / len(patient_ids) * 100\n",
    "        print(f\"Processing: {progress:.2f}% complete\", end='\\r')\n",
    "    # replace None values in 'n_prior_data' with 0\n",
    "    df['n_prior_data'] = df['n_prior_data'].fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "metadata_int = process_calculate_days_before_panic(metadata_calc, delta_days=d_days, lookback_limit=l_back_lim)\n",
    "\n",
    "# update features_dict with metadata columns\n",
    "if 'ref_event_id' not in features_dict['metadata']:\n",
    "\tfeatures_dict['metadata'].append('ref_event_id')\n",
    "if 'n_prior_data' not in features_dict['metadata']:\n",
    "\tfeatures_dict['metadata'].append('n_prior_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6da162d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset</th>\n",
       "      <th>coffee</th>\n",
       "      <th>smoking</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "      <th>dtype_n</th>\n",
       "      <th>diary_data</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic</th>\n",
       "      <th>n_prior_data</th>\n",
       "      <th>ref_event_id</th>\n",
       "      <th>panic_label</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26972</th>\n",
       "      <td>SYM2-1-422_2022-05-24</td>\n",
       "      <td>SYM2-1-422</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26971</th>\n",
       "      <td>SYM2-1-422_2022-05-23</td>\n",
       "      <td>SYM2-1-422</td>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26970</th>\n",
       "      <td>SYM2-1-422_2022-05-22</td>\n",
       "      <td>SYM2-1-422</td>\n",
       "      <td>2022-05-22</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26969</th>\n",
       "      <td>SYM2-1-422_2022-05-21</td>\n",
       "      <td>SYM2-1-422</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26968</th>\n",
       "      <td>SYM2-1-422_2022-05-20</td>\n",
       "      <td>SYM2-1-422</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26967</th>\n",
       "      <td>SYM2-1-422_2022-05-19</td>\n",
       "      <td>SYM2-1-422</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26966</th>\n",
       "      <td>SYM2-1-422_2022-05-18</td>\n",
       "      <td>SYM2-1-422</td>\n",
       "      <td>2022-05-18</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>SYM2-1-422_2022-05-19</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26965</th>\n",
       "      <td>SYM2-1-422_2022-05-17</td>\n",
       "      <td>SYM2-1-422</td>\n",
       "      <td>2022-05-17</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>SYM2-1-422_2022-05-18</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26964</th>\n",
       "      <td>SYM2-1-422_2022-05-16</td>\n",
       "      <td>SYM2-1-422</td>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.73</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>SYM2-1-422_2022-05-17</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26963</th>\n",
       "      <td>SYM2-1-422_2022-05-15</td>\n",
       "      <td>SYM2-1-422</td>\n",
       "      <td>2022-05-15</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>SYM2-1-422_2022-05-17</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    entry_id          ID       date dataset  coffee  smoking  \\\n",
       "26972  SYM2-1-422_2022-05-24  SYM2-1-422 2022-05-24    SYM2     NaN      NaN   \n",
       "26971  SYM2-1-422_2022-05-23  SYM2-1-422 2022-05-23    SYM2     NaN      NaN   \n",
       "26970  SYM2-1-422_2022-05-22  SYM2-1-422 2022-05-22    SYM2     NaN      NaN   \n",
       "26969  SYM2-1-422_2022-05-21  SYM2-1-422 2022-05-21    SYM2     NaN      NaN   \n",
       "26968  SYM2-1-422_2022-05-20  SYM2-1-422 2022-05-20    SYM2     NaN      NaN   \n",
       "26967  SYM2-1-422_2022-05-19  SYM2-1-422 2022-05-19    SYM2     NaN      NaN   \n",
       "26966  SYM2-1-422_2022-05-18  SYM2-1-422 2022-05-18    SYM2     NaN      NaN   \n",
       "26965  SYM2-1-422_2022-05-17  SYM2-1-422 2022-05-17    SYM2     NaN      NaN   \n",
       "26964  SYM2-1-422_2022-05-16  SYM2-1-422 2022-05-16    SYM2     NaN      NaN   \n",
       "26963  SYM2-1-422_2022-05-15  SYM2-1-422 2022-05-15    SYM2     NaN      NaN   \n",
       "\n",
       "       total_sleep  dailylog_data  lifelog_data  questionnaire_data  dtype_n  \\\n",
       "26972         9.30              1             1                   1        3   \n",
       "26971         8.90              1             1                   1        3   \n",
       "26970         9.37              1             1                   1        3   \n",
       "26969         8.18              1             1                   1        3   \n",
       "26968         8.28              1             1                   1        3   \n",
       "26967         6.85              1             1                   1        3   \n",
       "26966         7.27              1             1                   1        3   \n",
       "26965        10.30              1             1                   1        3   \n",
       "26964         7.73              1             1                   1        3   \n",
       "26963         8.16              1             1                   1        3   \n",
       "\n",
       "       diary_data  dbp  panic  n_prior_data           ref_event_id  \\\n",
       "26972           0  NaN    0.0             4                   None   \n",
       "26971           0  NaN    0.0             3                   None   \n",
       "26970           0  NaN    0.0             2                   None   \n",
       "26969           0  NaN    0.0             1                   None   \n",
       "26968           0  NaN    0.0             0                   None   \n",
       "26967           0  0.0    2.0             0                   None   \n",
       "26966           0  0.0    2.0             0  SYM2-1-422_2022-05-19   \n",
       "26965           0  0.0    2.0             1  SYM2-1-422_2022-05-18   \n",
       "26964           0  1.0    1.0             0  SYM2-1-422_2022-05-17   \n",
       "26963           0  0.0    2.0             2  SYM2-1-422_2022-05-17   \n",
       "\n",
       "       panic_label  severity  \n",
       "26972            0       NaN  \n",
       "26971            0       NaN  \n",
       "26970            0       NaN  \n",
       "26969            0       NaN  \n",
       "26968            0       NaN  \n",
       "26967            1       3.0  \n",
       "26966            1       3.0  \n",
       "26965            1       4.0  \n",
       "26964            0       NaN  \n",
       "26963            1       4.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_id = 'SYM2-1-422'\n",
    "disp_df = metadata_int[metadata_int['ID'] == p_id]\n",
    "display(disp_df.head(10))\n",
    "del disp_df, p_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded18a26",
   "metadata": {},
   "source": [
    "## Find Valid Entries\n",
    "- add `valid_entry_3`: whether the entry has 3 consecutive days of prior data (`n_prior_data`)\n",
    "- add `valid_entry_2`: whether the entry has 2 consecutive days of prior data (`n_prior_data`)\n",
    "- add `valid_entry_1`: whether the entry has 1 consecutive days of prior data (`n_prior_data`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3cb3f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset</th>\n",
       "      <th>coffee</th>\n",
       "      <th>smoking</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "      <th>...</th>\n",
       "      <th>diary_data</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic</th>\n",
       "      <th>n_prior_data</th>\n",
       "      <th>valid_entry_3</th>\n",
       "      <th>valid_entry_2</th>\n",
       "      <th>valid_entry_1</th>\n",
       "      <th>ref_event_id</th>\n",
       "      <th>panic_label</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28776</th>\n",
       "      <td>SYM2-1-96_2021-08-04</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28775</th>\n",
       "      <td>SYM2-1-96_2021-08-03</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28774</th>\n",
       "      <td>SYM2-1-96_2021-08-02</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-02</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28773</th>\n",
       "      <td>SYM2-1-96_2021-08-01</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28772</th>\n",
       "      <td>SYM2-1-96_2021-07-31</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   entry_id         ID       date dataset  coffee  smoking  \\\n",
       "28776  SYM2-1-96_2021-08-04  SYM2-1-96 2021-08-04    SYM2     NaN      NaN   \n",
       "28775  SYM2-1-96_2021-08-03  SYM2-1-96 2021-08-03    SYM2     NaN      NaN   \n",
       "28774  SYM2-1-96_2021-08-02  SYM2-1-96 2021-08-02    SYM2     NaN      NaN   \n",
       "28773  SYM2-1-96_2021-08-01  SYM2-1-96 2021-08-01    SYM2     NaN      NaN   \n",
       "28772  SYM2-1-96_2021-07-31  SYM2-1-96 2021-07-31    SYM2     NaN      NaN   \n",
       "\n",
       "       total_sleep  dailylog_data  lifelog_data  questionnaire_data  ...  \\\n",
       "28776          NaN              1             1                   1  ...   \n",
       "28775          NaN              1             1                   1  ...   \n",
       "28774          NaN              1             1                   1  ...   \n",
       "28773          NaN              1             0                   1  ...   \n",
       "28772          NaN              1             0                   1  ...   \n",
       "\n",
       "       diary_data  dbp  panic  n_prior_data  valid_entry_3  valid_entry_2  \\\n",
       "28776           0  NaN    0.0             7              1              1   \n",
       "28775           0  NaN    0.0             7              1              1   \n",
       "28774           0  NaN    0.0             7              1              1   \n",
       "28773           0  NaN    0.0             7              1              1   \n",
       "28772           0  NaN    0.0             7              1              1   \n",
       "\n",
       "       valid_entry_1  ref_event_id panic_label  severity  \n",
       "28776              1          None           0       NaN  \n",
       "28775              1          None           0       NaN  \n",
       "28774              1          None           0       NaN  \n",
       "28773              1          None           0       NaN  \n",
       "28772              1          None           0       NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata_int['valid_entry_3'] = metadata_int.apply(\n",
    "\tlambda row: 1 if row['n_prior_data'] >= 3 else 0,\n",
    "\taxis=1\n",
    ")\n",
    "metadata_int['valid_entry_2'] = metadata_int.apply(\n",
    "\tlambda row: 1 if row['n_prior_data'] >= 2 else 0,\n",
    "\taxis=1\n",
    ")\n",
    "metadata_int['valid_entry_1'] = metadata_int.apply(\n",
    "\tlambda row: 1 if row['n_prior_data'] >= 1 else 0,\n",
    "\taxis=1\n",
    ")\n",
    "move_column(metadata_int, 'ref_event_id', -1)\n",
    "move_column(metadata_int, 'panic_label', -1)\n",
    "move_column(metadata_int, 'severity', -1)\n",
    "display(metadata_int.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "262ff9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_panic_dbpnot0 = metadata_int[(metadata_int['panic'] == 2) & (metadata_int['dbp'] != 0)]['entry_id'].unique()\n",
    "test_panic_dbp1 = metadata_int[(metadata_int['panic'] == 1) & (metadata_int['dbp'] != 1)]['entry_id'].unique()\n",
    "if len(test_panic_dbpnot0) != 0:\n",
    "\traise ValueError(\"Entries found with dbp != 0 for panic events. Please check the data.\")\n",
    "if len(test_panic_dbp1) != 0:\n",
    "\traise ValueError(\"Entries found with dbp != 1 for panic = 1. Please check the data.\")\n",
    "del test_panic_dbpnot0, test_panic_dbp1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dea337",
   "metadata": {},
   "source": [
    "## üíæ | Save Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f69eeb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - (text_utils.py) save_as_csv: Saved panic_metadata_1-3(final_result_diary_20250617_03).csv to C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\cys\\_output\n",
      "DEBUG - (json_utils.py) save_dict_to_file: Dictionary saved successfully to C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\cys\\_output\\panic_features_dict.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset</th>\n",
       "      <th>coffee</th>\n",
       "      <th>smoking</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "      <th>...</th>\n",
       "      <th>diary_data</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic</th>\n",
       "      <th>n_prior_data</th>\n",
       "      <th>valid_entry_3</th>\n",
       "      <th>valid_entry_2</th>\n",
       "      <th>valid_entry_1</th>\n",
       "      <th>ref_event_id</th>\n",
       "      <th>panic_label</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28776</th>\n",
       "      <td>SYM2-1-96_2021-08-04</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28775</th>\n",
       "      <td>SYM2-1-96_2021-08-03</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28774</th>\n",
       "      <td>SYM2-1-96_2021-08-02</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-02</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28773</th>\n",
       "      <td>SYM2-1-96_2021-08-01</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28772</th>\n",
       "      <td>SYM2-1-96_2021-07-31</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28771</th>\n",
       "      <td>SYM2-1-96_2021-07-30</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-30</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28770</th>\n",
       "      <td>SYM2-1-96_2021-07-29</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-29</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28769</th>\n",
       "      <td>SYM2-1-96_2021-07-28</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-28</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28768</th>\n",
       "      <td>SYM2-1-96_2021-07-27</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28767</th>\n",
       "      <td>SYM2-1-96_2021-07-26</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-26</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   entry_id         ID       date dataset  coffee  smoking  \\\n",
       "28776  SYM2-1-96_2021-08-04  SYM2-1-96 2021-08-04    SYM2     NaN      NaN   \n",
       "28775  SYM2-1-96_2021-08-03  SYM2-1-96 2021-08-03    SYM2     NaN      NaN   \n",
       "28774  SYM2-1-96_2021-08-02  SYM2-1-96 2021-08-02    SYM2     NaN      NaN   \n",
       "28773  SYM2-1-96_2021-08-01  SYM2-1-96 2021-08-01    SYM2     NaN      NaN   \n",
       "28772  SYM2-1-96_2021-07-31  SYM2-1-96 2021-07-31    SYM2     NaN      NaN   \n",
       "28771  SYM2-1-96_2021-07-30  SYM2-1-96 2021-07-30    SYM2     NaN      NaN   \n",
       "28770  SYM2-1-96_2021-07-29  SYM2-1-96 2021-07-29    SYM2     NaN      NaN   \n",
       "28769  SYM2-1-96_2021-07-28  SYM2-1-96 2021-07-28    SYM2     NaN      NaN   \n",
       "28768  SYM2-1-96_2021-07-27  SYM2-1-96 2021-07-27    SYM2     NaN      NaN   \n",
       "28767  SYM2-1-96_2021-07-26  SYM2-1-96 2021-07-26    SYM2     NaN      NaN   \n",
       "\n",
       "       total_sleep  dailylog_data  lifelog_data  questionnaire_data  ...  \\\n",
       "28776          NaN              1             1                   1  ...   \n",
       "28775          NaN              1             1                   1  ...   \n",
       "28774          NaN              1             1                   1  ...   \n",
       "28773          NaN              1             0                   1  ...   \n",
       "28772          NaN              1             0                   1  ...   \n",
       "28771          NaN              1             1                   1  ...   \n",
       "28770          NaN              1             1                   1  ...   \n",
       "28769          NaN              1             1                   1  ...   \n",
       "28768          NaN              1             0                   1  ...   \n",
       "28767          NaN              1             0                   1  ...   \n",
       "\n",
       "       diary_data  dbp  panic  n_prior_data  valid_entry_3  valid_entry_2  \\\n",
       "28776           0  NaN    0.0             7              1              1   \n",
       "28775           0  NaN    0.0             7              1              1   \n",
       "28774           0  NaN    0.0             7              1              1   \n",
       "28773           0  NaN    0.0             7              1              1   \n",
       "28772           0  NaN    0.0             7              1              1   \n",
       "28771           0  NaN    0.0             7              1              1   \n",
       "28770           0  NaN    0.0             7              1              1   \n",
       "28769           0  NaN    0.0             7              1              1   \n",
       "28768           0  NaN    0.0             7              1              1   \n",
       "28767           0  NaN    0.0             7              1              1   \n",
       "\n",
       "       valid_entry_1  ref_event_id panic_label  severity  \n",
       "28776              1          None           0       NaN  \n",
       "28775              1          None           0       NaN  \n",
       "28774              1          None           0       NaN  \n",
       "28773              1          None           0       NaN  \n",
       "28772              1          None           0       NaN  \n",
       "28771              1          None           0       NaN  \n",
       "28770              1          None           0       NaN  \n",
       "28769              1          None           0       NaN  \n",
       "28768              1          None           0       NaN  \n",
       "28767              1          None           0       NaN  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata = create_empty_df()\n",
    "metadata = metadata_int.copy()\n",
    "save_as_csv(metadata, OUTPUT_PATH, f\"panic_metadata_{version}({scraped_data_filename})\")\n",
    "save_dict_to_file(features_dict, OUTPUT_PATH, \"panic_features_dict\")\n",
    "\n",
    "display(metadata.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef5553a",
   "metadata": {},
   "source": [
    "# üîç | Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf6ff081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped data shape: (28777, 79)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>panic</th>\n",
       "      <th>gender</th>\n",
       "      <th>PHQ_9</th>\n",
       "      <th>STAI_X2</th>\n",
       "      <th>CSM</th>\n",
       "      <th>CTQ_1</th>\n",
       "      <th>CTQ_2</th>\n",
       "      <th>CTQ_3</th>\n",
       "      <th>...</th>\n",
       "      <th>SLT1</th>\n",
       "      <th>SLT2</th>\n",
       "      <th>SLT3</th>\n",
       "      <th>SLT4</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>severity</th>\n",
       "      <th>mood</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>15.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID       date  panic  gender  PHQ_9  STAI_X2   CSM  CTQ_1  CTQ_2  \\\n",
       "0  PXPN_10006 2024-11-04    0.0       0    0.0     32.0  31.0   11.0   13.0   \n",
       "1  PXPN_10006 2024-11-05    0.0       0    0.0     32.0  31.0   11.0   13.0   \n",
       "\n",
       "   CTQ_3  ...  SLT1  SLT2  SLT3  SLT4  SLT5  SLT6  total_sleep  severity  \\\n",
       "0   17.0  ...   NaN   NaN   NaN   NaN   NaN   NaN          NaN       NaN   \n",
       "1   17.0  ...   0.0  4.47  3.62  4.67  0.65  1.85        15.26       NaN   \n",
       "\n",
       "   mood  contents  \n",
       "0   NaN       NaN  \n",
       "1   NaN       NaN  \n",
       "\n",
       "[2 rows x 79 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessed shape: (28625, 73)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>panic</th>\n",
       "      <th>PHQ_9</th>\n",
       "      <th>STAI_X2</th>\n",
       "      <th>CSM</th>\n",
       "      <th>CTQ_1</th>\n",
       "      <th>CTQ_2</th>\n",
       "      <th>...</th>\n",
       "      <th>SLT1</th>\n",
       "      <th>SLT2</th>\n",
       "      <th>SLT3</th>\n",
       "      <th>SLT4</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>severity</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006_2024-11-04</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10006_2024-11-05</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>15.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                entry_id dataset          ID       date  panic  PHQ_9  \\\n",
       "0  PXPN_10006_2024-11-04    PXPN  PXPN_10006 2024-11-04    0.0    0.0   \n",
       "1  PXPN_10006_2024-11-05    PXPN  PXPN_10006 2024-11-05    0.0    0.0   \n",
       "\n",
       "   STAI_X2   CSM  CTQ_1  CTQ_2  ...  SLT1  SLT2  SLT3  SLT4  SLT5  SLT6  \\\n",
       "0     32.0  31.0   11.0   13.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1     32.0  31.0   11.0   13.0  ...   0.0  4.47  3.62  4.67  0.65  1.85   \n",
       "\n",
       "   total_sleep  severity  dbp  panic_label  \n",
       "0          NaN       NaN  NaN            0  \n",
       "1        15.26       NaN  NaN            0  \n",
       "\n",
       "[2 rows x 73 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata shape: (28625, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset</th>\n",
       "      <th>coffee</th>\n",
       "      <th>smoking</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "      <th>...</th>\n",
       "      <th>diary_data</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic</th>\n",
       "      <th>n_prior_data</th>\n",
       "      <th>valid_entry_3</th>\n",
       "      <th>valid_entry_2</th>\n",
       "      <th>valid_entry_1</th>\n",
       "      <th>ref_event_id</th>\n",
       "      <th>panic_label</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28776</th>\n",
       "      <td>SYM2-1-96_2021-08-04</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28775</th>\n",
       "      <td>SYM2-1-96_2021-08-03</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   entry_id         ID       date dataset  coffee  smoking  \\\n",
       "28776  SYM2-1-96_2021-08-04  SYM2-1-96 2021-08-04    SYM2     NaN      NaN   \n",
       "28775  SYM2-1-96_2021-08-03  SYM2-1-96 2021-08-03    SYM2     NaN      NaN   \n",
       "\n",
       "       total_sleep  dailylog_data  lifelog_data  questionnaire_data  ...  \\\n",
       "28776          NaN              1             1                   1  ...   \n",
       "28775          NaN              1             1                   1  ...   \n",
       "\n",
       "       diary_data  dbp  panic  n_prior_data  valid_entry_3  valid_entry_2  \\\n",
       "28776           0  NaN    0.0             7              1              1   \n",
       "28775           0  NaN    0.0             7              1              1   \n",
       "\n",
       "       valid_entry_1  ref_event_id panic_label  severity  \n",
       "28776              1          None           0       NaN  \n",
       "28775              1          None           0       NaN  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Scraped data shape:\", scraped_data.shape)\n",
    "display(scraped_data.head(2))\n",
    "print(\"Data preprocessed shape:\", data_pre.shape)\n",
    "display(data_pre.head(2))\n",
    "print(\"Metadata shape:\", metadata.shape)\n",
    "display(metadata.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40357bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped Entries: 28777 -> 28625 after preprocessing. discarded 152 entries.\n"
     ]
    }
   ],
   "source": [
    "scraped_data_n = len(scraped_data)\n",
    "data_pre_entry_ids = data_pre['entry_id'].unique()\n",
    "print(f\"Scraped Entries: {scraped_data_n} -> {len(data_pre_entry_ids)} after preprocessing. discarded {scraped_data_n - len(data_pre_entry_ids)} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01ea0faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped Data (n): 429 -> Preprocessed Data (n): 277\n",
      "152 patient data were discarded during preprocessing due to entries having only demographic data\n"
     ]
    }
   ],
   "source": [
    "scraped_data_ids = scraped_data['ID'].unique()\n",
    "data_pre_ids = data_pre['ID'].unique()\n",
    "print(f\"Scraped Data (n): {len(scraped_data_ids)} -> Preprocessed Data (n): {len(data_pre_ids)}\")\n",
    "print(f\"{len(scraped_data_ids) - len(data_pre_ids)} patient data were discarded during preprocessing due to entries having only demographic data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dhlab-panic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
