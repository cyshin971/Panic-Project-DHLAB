{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72f4fd25",
   "metadata": {},
   "source": [
    "# Panic Project (DHLAB) - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5634a08",
   "metadata": {},
   "source": [
    "author:  `@cyshin971`  \n",
    "\n",
    "date:    `2025-06-16`  \n",
    "\n",
    "version: `1.0`\n",
    "\n",
    "> version `1.0`: Derived from `data_analysis.ipynb` version `1.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42654e1",
   "metadata": {},
   "source": [
    "# üìö | Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9df09cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config as cfg\n",
    "import logging\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "\n",
    "from library.pandas_utils import move_column, remove_columns, aggregate_by_column, create_empty_df\n",
    "from library.text_utils import save_as_csv\n",
    "from library.json_utils import save_dict_to_file\n",
    "from library.path_utils import get_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa403ca",
   "metadata": {},
   "source": [
    "# üìÅ | Path Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd8780ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../_data\"\n",
    "TMP_PATH = \"./cys/_tmp\"\n",
    "OUTPUT_PATH = \"./cys/_output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bbe0e9",
   "metadata": {},
   "source": [
    "# ‚õèÔ∏è | Scraped Data\n",
    "\n",
    "load preprocessed data (by `junyeol_lee`)\n",
    "- Each entry are the datapoints for a patient (`ID`) on a specific date (`date`)\n",
    "- If there were multiple datapoints for a specific date (`date`) for a specific patient (`ID`), the values were processed (`sum`, `avg`, etc.) to a representation for the day\n",
    "- Questionnaire data was treated as a 'semi-trait' variable\n",
    "  - if a questionnaire was filled by the patient on a particular day all entries from that point forward will maintain the values of the questionnaire until the patient fills out the questionnaire again\n",
    "- Diary contents were added (20250613)\n",
    "\t- `mood`, `contents`\n",
    "- Certain columns were added back (20250613)\n",
    "  - demography: `suicide_need` (`boolean`)\n",
    "  - dailylog:\n",
    "    - `steps_maximum`\n",
    "\t- `steps_mean`\n",
    "\t- `step_hvar_mean`\n",
    "\t- `step_delta`\n",
    "\t- `step_max_delta`\n",
    "\t- `step_mean_delta`\n",
    "\t- `step_hvar_mean_delta`\n",
    "\t- `step_delta2`\n",
    "\t- `step_max_delta2`\n",
    "\t- `step_mean_delta2`\n",
    "\t- `step_hvar_mean_delta2`\n",
    "\t- `steps_variance`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dbe912",
   "metadata": {},
   "source": [
    "## Scraped Data Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aab7722c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables: 75\n",
      "   Demographic variables: 8\n",
      "   Daily log variables: 13\n",
      "   Life log variables: 37\n",
      "   Questionnaire variables: 17\n"
     ]
    }
   ],
   "source": [
    "scraped_data_filename = \"final_result_diary_20250616\"\n",
    "\n",
    "features_dict = {\n",
    "    \"scraped_data_filename\": scraped_data_filename,\n",
    "\t\"demography\": [\n",
    "\t\t'gender', 'age', 'marriage', 'job', 'smkHx', 'drinkHx', 'suicideHx', 'suicide_need'\n",
    "\t],\n",
    "\t\"dailylog\": [\n",
    "\t\t'panic', 'severity', 'exercise', 'alcohol', 'coffee', 'menstruation',\n",
    "\t\t'smoking', 'positive_feeling', 'negative_feeling', 'positive_E', 'negative_E',\n",
    "\t\t'anxiety', 'annoying'\n",
    "\t],\n",
    "\t\"lifelog\": [\n",
    "        'HR_var', 'HR_max', 'HR_mean', 'HR_hvar_mean', 'HR_acrophase', 'HR_amplitude', 'HR_mesor',\n",
    "        'HR_acrophase_difference', 'HR_acrophase_difference_2d', 'HR_amplitude_difference',\n",
    "        'HR_amplitude_difference_2d', 'HR_mesor_difference', 'HR_mesor_difference_2d',\n",
    "        'bandpower(0.001-0.0005Hz)', 'bandpower(0.0005-0.0001Hz)', 'bandpower(0.0001-0.00005Hz)', 'bandpower(0.00005-0.00001Hz)',\n",
    "        'steps', 'SLT1', 'SLT2', 'SLT3', 'SLT4', 'SLT5', 'SLT6', 'total_sleep',\n",
    "        'steps_maximum', 'steps_mean', 'step_hvar_mean', 'step_delta',\n",
    "        'step_max_delta', 'step_mean_delta', 'step_hvar_mean_delta',\n",
    "        'step_delta2', 'step_max_delta2', 'step_mean_delta2', 'step_hvar_mean_delta2', 'steps_variance'\n",
    "\t],\n",
    "\t\"questionnaire\": [\n",
    "\t\t'PHQ_9', 'STAI_X2', 'CSM', 'CTQ_1', 'CTQ_2', 'CTQ_3', 'CTQ_4', 'CTQ_5', 'KRQ', 'MDQ',\n",
    "\t\t'ACQ', 'APPQ_1', 'APPQ_2', 'APPQ_3', 'BSQ', 'GAD_7', 'BRIAN'\n",
    "\t],\n",
    "\t\"diary\":[\n",
    "        'mood', 'contents'\n",
    "\t],\n",
    "\t\"excluded\": [ # Dropped as variables were only in SYM dataset\n",
    "\t\t'SPAQ_1', 'SPAQ_2', 'BFNE', 'CES_D', 'KOSSSF', 'SADS', 'STAI_X1', 'medication_in_month',\n",
    "        'Unnamed: 0' # Placeholder column\n",
    "\t],\n",
    "    \"id\": [\n",
    "        'ID', 'date'\n",
    "    ],\n",
    "    \"label\": [\n",
    "        'severity'\n",
    "    ],\n",
    "    \"metadata\": ['coffee', 'smoking', 'total_sleep']\n",
    "}\n",
    "\n",
    "demo_vars = features_dict[\"demography\"]\n",
    "dailylog_vars = features_dict[\"dailylog\"]\n",
    "lifelog_vars = features_dict[\"lifelog\"]\n",
    "questionnaire_vars = features_dict[\"questionnaire\"]\n",
    "\n",
    "state_vars = demo_vars\n",
    "trait_vars = dailylog_vars + lifelog_vars + questionnaire_vars\n",
    "all_vars = state_vars + dailylog_vars + lifelog_vars + questionnaire_vars\n",
    "all_cols = features_dict[\"id\"] + all_vars + features_dict[\"diary\"]\n",
    "\n",
    "print(f'Number of variables: {len(all_vars)}')\n",
    "print(f'   Demographic variables: {len(state_vars)}')\n",
    "print(f'   Daily log variables: {len(dailylog_vars)}')\n",
    "print(f'   Life log variables: {len(lifelog_vars)}')\n",
    "print(f'   Questionnaire variables: {len(questionnaire_vars)}')\n",
    "\n",
    "# _ = save_dict_to_file(features_dict, TMP_PATH, \"scraped_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81218b4a",
   "metadata": {},
   "source": [
    "## Load Scraped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a279cfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (3580894465.py) <module>: All expected columns are present in scraped_data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 24386\n",
      "Number of columns: 79\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>panic</th>\n",
       "      <th>gender</th>\n",
       "      <th>PHQ_9</th>\n",
       "      <th>STAI_X2</th>\n",
       "      <th>CSM</th>\n",
       "      <th>CTQ_1</th>\n",
       "      <th>CTQ_2</th>\n",
       "      <th>CTQ_3</th>\n",
       "      <th>...</th>\n",
       "      <th>SLT1</th>\n",
       "      <th>SLT2</th>\n",
       "      <th>SLT3</th>\n",
       "      <th>SLT4</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>severity</th>\n",
       "      <th>mood</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>15.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.07</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.68</td>\n",
       "      <td>7.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>6.19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID       date  panic  gender  PHQ_9  STAI_X2   CSM  CTQ_1  CTQ_2  \\\n",
       "0  PXPN_10006 2024-11-04    0.0       0    0.0     32.0  31.0   11.0   13.0   \n",
       "1  PXPN_10006 2024-11-05    0.0       0    0.0     32.0  31.0   11.0   13.0   \n",
       "2  PXPN_10006 2024-11-06    1.0       0    0.0     32.0  31.0   11.0   13.0   \n",
       "3  PXPN_10006 2024-11-07    2.0       0    0.0     32.0  31.0   11.0   13.0   \n",
       "4  PXPN_10006 2024-11-08    0.0       0    0.0     32.0  31.0   11.0   13.0   \n",
       "\n",
       "   CTQ_3  ...  SLT1  SLT2  SLT3  SLT4  SLT5  SLT6  total_sleep  severity  \\\n",
       "0   17.0  ...   NaN   NaN   NaN   NaN   NaN   NaN          NaN       NaN   \n",
       "1   17.0  ...   0.0  4.47  3.62  4.67  0.65  1.85        15.26       NaN   \n",
       "2   17.0  ...   0.0  0.00  0.20  4.07  1.43  1.68         7.38       NaN   \n",
       "3   17.0  ...   0.0  0.00  0.14  5.08  0.00  0.97         6.19       1.0   \n",
       "4   17.0  ...   NaN   NaN   NaN   NaN   NaN   NaN          NaN       NaN   \n",
       "\n",
       "   mood  contents  \n",
       "0   NaN       NaN  \n",
       "1   NaN       NaN  \n",
       "2   NaN       NaN  \n",
       "3   NaN       NaN  \n",
       "4   NaN       NaN  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scraped_data = pd.read_csv(os.path.join(DATA_PATH, f\"{scraped_data_filename}.csv\"))\n",
    "\n",
    "# check if all columns are present\n",
    "missing_cols = [col for col in all_vars if col not in scraped_data.columns]\n",
    "if missing_cols:\n",
    "    logging.warning(f\"Missing columns in scraped_data: {missing_cols}\")\n",
    "else:\n",
    "\tlogging.info(\"All expected columns are present in scraped_data.\")\n",
    "extra_cols = [col for col in scraped_data.columns if col not in all_cols + features_dict[\"excluded\"]]\n",
    "if extra_cols:\n",
    "\tlogging.warning(f\"Extra columns in scraped_data: {extra_cols}\")\n",
    "\n",
    "# convert date column to datetime format\n",
    "scraped_data['date'] = pd.to_datetime(scraped_data['date'], format='%Y-%m-%d')\n",
    "remove_columns(scraped_data, ['Unnamed: 0'])\n",
    "\n",
    "# remove any of the columns in features_dict[\"excluded\"] if they exist\n",
    "for col in features_dict[\"excluded\"]:\n",
    "\tif col in scraped_data.columns:\n",
    "\t\tscraped_data.drop(columns=[col], inplace=True)\n",
    "\n",
    "print(f\"Number of rows: {scraped_data.shape[0]}\")\n",
    "print(f\"Number of columns: {scraped_data.shape[1]}\")\n",
    "display(scraped_data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6024277b",
   "metadata": {},
   "source": [
    "# ‚öíÔ∏è | Data Preprocessing\n",
    "\n",
    "Changes from scraped data:\n",
    "- add `entry_id` to identify each entry: `'ID'_'date'`\n",
    "- add `dataset` to identify source: `SYM1`, `SYM2`, `PXPN`\n",
    "- convert `panic` (`0`, `1`, `2` = panic) to days befor panic (`dbp`) (panic = `0`, `1`, `2`)\n",
    "- add `panic_label` : whether a panic occurred in the entry (`boolean`)\n",
    "- demographic features were removed from preprocessed data (`data_pre`)\n",
    "- the data was filtered to remove entries with only demgraphic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5b1f06",
   "metadata": {},
   "source": [
    "## Initialize Preprocessed Data\n",
    "\n",
    "- add `entry_id` to identify each entry: `'ID'_'date'`\n",
    "- add `dataset` to identify source: `SYM1`, `SYM2`, `PXPN`\n",
    "- convert `panic` (`0`, `1`, `2` = panic) to days befor panic (`dbp`) (panic = `0`, `1`, `2`)\n",
    "- add `panic_label` (boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d5a6ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique entry IDs: 24386\n",
      "Scraped data shape: (24386, 79)\n",
      "Initialized preprocessed data shape: (24386, 80)\n"
     ]
    }
   ],
   "source": [
    "data_pre_init = create_empty_df()\n",
    "data_pre_init = scraped_data.copy()\n",
    "\n",
    "# Add 'entry_id' column: unique identifier for each row\n",
    "data_pre_init['entry_id'] = data_pre_init['ID'] + '_' + data_pre_init['date'].astype(str)\n",
    "instance_id_unique = data_pre_init['entry_id'].unique()\n",
    "move_column(data_pre_init, 'entry_id', 0)\n",
    "print(\"Number of unique entry IDs:\", len(instance_id_unique))\n",
    "# Check if 'entry_id' is unique\n",
    "if data_pre_init['entry_id'].duplicated().any():\n",
    "\t# return the rows with duplicate 'entry_id'\n",
    "\tduplicates = data_pre_init[data_pre_init['entry_id'].duplicated(keep=False)]\n",
    "\tdisplay(duplicates.head(5))\n",
    "\tsave_as_csv(duplicates, TMP_PATH, f\"duplicates_{scraped_data_filename}\")\n",
    "\traise ValueError(\"Duplicate 'entry_id' found in the data. Please resolve this issue before proceeding.\")\n",
    "\n",
    "# Add 'dataset' column: source of data\n",
    "data_pre_init['dataset'] = data_pre_init['ID'].str.split('_').str[0]\n",
    "data_pre_init['dataset'] = data_pre_init['dataset'].str.split('-').str[0]\n",
    "move_column(data_pre_init, 'dataset', 1)\n",
    "\n",
    "# Convert 'panic' column to Days Before Panic (dbp)\n",
    "data_pre_init['dbp'] = data_pre_init.apply(\n",
    "\tlambda row: np.nan if row['panic'] == 0\n",
    " \t\t\t\telse 0 if row['panic'] == 2 else row['panic'],\n",
    "\taxis=1\n",
    ")\n",
    "remove_columns(data_pre_init, ['panic'])\n",
    "\n",
    "# TODO: Temporarily remove 'diary' columns\n",
    "remove_columns(data_pre_init, features_dict['diary'])\n",
    "\n",
    "# Add panic_label column\n",
    "data_pre_init['panic_label'] = data_pre_init['dbp'].apply(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "# Update the features_dict\n",
    "if 'entry_id' not in features_dict['id']:\n",
    "\tfeatures_dict['id'].insert(0, 'entry_id')\n",
    "if 'dataset' not in features_dict['id']:\n",
    "\tfeatures_dict['id'].append('dataset')\n",
    "if 'dbp' not in features_dict['dailylog']:\n",
    "\tfeatures_dict['label'].insert(0, 'dbp')\n",
    "if 'panic_label' not in features_dict['label']:\n",
    "\tfeatures_dict['label'].insert(1, 'panic_label')\n",
    "if 'panic' in features_dict['dailylog']:\n",
    "\tfeatures_dict['dailylog'].remove('panic')\n",
    "\n",
    "# print scraped_data shape\n",
    "print(f\"Scraped data shape: {scraped_data.shape}\")\n",
    "print(f\"Initialized preprocessed data shape: {data_pre_init.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "276b12c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>gender</th>\n",
       "      <th>PHQ_9</th>\n",
       "      <th>STAI_X2</th>\n",
       "      <th>CSM</th>\n",
       "      <th>CTQ_1</th>\n",
       "      <th>CTQ_2</th>\n",
       "      <th>...</th>\n",
       "      <th>SLT1</th>\n",
       "      <th>SLT2</th>\n",
       "      <th>SLT3</th>\n",
       "      <th>SLT4</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>severity</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006_2024-11-04</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10006_2024-11-05</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>15.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PXPN_10006_2024-11-06</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.07</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.68</td>\n",
       "      <td>7.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PXPN_10006_2024-11-07</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>6.19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PXPN_10006_2024-11-08</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                entry_id dataset          ID       date  gender  PHQ_9  \\\n",
       "0  PXPN_10006_2024-11-04    PXPN  PXPN_10006 2024-11-04       0    0.0   \n",
       "1  PXPN_10006_2024-11-05    PXPN  PXPN_10006 2024-11-05       0    0.0   \n",
       "2  PXPN_10006_2024-11-06    PXPN  PXPN_10006 2024-11-06       0    0.0   \n",
       "3  PXPN_10006_2024-11-07    PXPN  PXPN_10006 2024-11-07       0    0.0   \n",
       "4  PXPN_10006_2024-11-08    PXPN  PXPN_10006 2024-11-08       0    0.0   \n",
       "\n",
       "   STAI_X2   CSM  CTQ_1  CTQ_2  ...  SLT1  SLT2  SLT3  SLT4  SLT5  SLT6  \\\n",
       "0     32.0  31.0   11.0   13.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1     32.0  31.0   11.0   13.0  ...   0.0  4.47  3.62  4.67  0.65  1.85   \n",
       "2     32.0  31.0   11.0   13.0  ...   0.0  0.00  0.20  4.07  1.43  1.68   \n",
       "3     32.0  31.0   11.0   13.0  ...   0.0  0.00  0.14  5.08  0.00  0.97   \n",
       "4     32.0  31.0   11.0   13.0  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "   total_sleep  severity  dbp  panic_label  \n",
       "0          NaN       NaN  NaN            0  \n",
       "1        15.26       NaN  NaN            0  \n",
       "2         7.38       NaN  1.0            0  \n",
       "3         6.19       1.0  0.0            1  \n",
       "4          NaN       NaN  NaN            0  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique sources in metadata_ljy:  ['PXPN' 'SYM1' 'SYM2']\n",
      "Number of entries in metadata_ljy: 24386\n",
      "    SYM entries: 23547\n",
      "    PXPN entries: 839\n",
      "Number of unique IDs in metadata_ljy: 429\n",
      "    SYM IDs:  400\n",
      "    PXPN IDs:  29\n",
      "Number of panic events (dbp=0): 802\n"
     ]
    }
   ],
   "source": [
    "display(data_pre_init.head(5))\n",
    "print(\"Unique sources in metadata_ljy: \", data_pre_init['dataset'].unique())\n",
    "print(\"Number of entries in metadata_ljy:\", data_pre_init.shape[0])\n",
    "sym1_n = data_pre_init[data_pre_init['dataset'] == 'SYM1'].shape[0]\n",
    "sym2_n = data_pre_init[data_pre_init['dataset'] == 'SYM2'].shape[0]\n",
    "print(\"    SYM entries:\", sym1_n+sym2_n)\n",
    "print(\"    PXPN entries:\", data_pre_init[data_pre_init['dataset'] == 'PXPN'].shape[0])\n",
    "print(\"Number of unique IDs in metadata_ljy:\", len(data_pre_init['ID'].unique()))\n",
    "# find the unique IDs for SYM1 and SYM2\n",
    "sym1_ids = data_pre_init[data_pre_init['dataset'] == 'SYM1']['ID'].unique()\n",
    "sym2_ids = data_pre_init[data_pre_init['dataset'] == 'SYM2']['ID'].unique()\n",
    "print(\"    SYM IDs: \", len(sym1_ids)+len(sym2_ids))\n",
    "print(\"    PXPN IDs: \", len(data_pre_init[data_pre_init['dataset'] == 'PXPN']['ID'].unique()))\n",
    "print(\"Number of panic events (dbp=0):\", data_pre_init[data_pre_init['dbp'] == 0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7cac54",
   "metadata": {},
   "source": [
    "## Initialize Metadata\n",
    "\n",
    "initialize `metadata` by adding\n",
    "- `demography_data` : whether demography data exists in the entry (`boolean`)\n",
    "- `dailylog_data`, `lifelog_data`, `questionnaire_data` : whether each data group exists in the entry (`boolean`)\n",
    "- `dtype_n` : how many of the 3 `state` groups exists in the entry (`int`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ed181f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>gender</th>\n",
       "      <th>PHQ_9</th>\n",
       "      <th>STAI_X2</th>\n",
       "      <th>CSM</th>\n",
       "      <th>dtype_n</th>\n",
       "      <th>CTQ_1</th>\n",
       "      <th>...</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>severity</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic_label</th>\n",
       "      <th>demography_data</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006_2024-11-04</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10006_2024-11-05</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>15.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PXPN_10006_2024-11-06</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.68</td>\n",
       "      <td>7.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PXPN_10006_2024-11-07</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>6.19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PXPN_10006_2024-11-08</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                entry_id dataset          ID       date  gender  PHQ_9  \\\n",
       "0  PXPN_10006_2024-11-04    PXPN  PXPN_10006 2024-11-04       0    0.0   \n",
       "1  PXPN_10006_2024-11-05    PXPN  PXPN_10006 2024-11-05       0    0.0   \n",
       "2  PXPN_10006_2024-11-06    PXPN  PXPN_10006 2024-11-06       0    0.0   \n",
       "3  PXPN_10006_2024-11-07    PXPN  PXPN_10006 2024-11-07       0    0.0   \n",
       "4  PXPN_10006_2024-11-08    PXPN  PXPN_10006 2024-11-08       0    0.0   \n",
       "\n",
       "   STAI_X2   CSM  dtype_n  CTQ_1  ...  SLT5  SLT6  total_sleep  severity  dbp  \\\n",
       "0     32.0  31.0        3   11.0  ...   NaN   NaN          NaN       NaN  NaN   \n",
       "1     32.0  31.0        3   11.0  ...  0.65  1.85        15.26       NaN  NaN   \n",
       "2     32.0  31.0        3   11.0  ...  1.43  1.68         7.38       NaN  1.0   \n",
       "3     32.0  31.0        3   11.0  ...  0.00  0.97         6.19       1.0  0.0   \n",
       "4     32.0  31.0        2   11.0  ...   NaN   NaN          NaN       NaN  NaN   \n",
       "\n",
       "   panic_label  demography_data  dailylog_data  lifelog_data  \\\n",
       "0            0                1              1             1   \n",
       "1            0                1              1             1   \n",
       "2            0                1              1             1   \n",
       "3            1                1              1             1   \n",
       "4            0                1              0             1   \n",
       "\n",
       "   questionnaire_data  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   1  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata_init = create_empty_df()\n",
    "metadata_init = data_pre_init.copy()\n",
    "\n",
    "metadata_init['demography_data'] = metadata_init[features_dict['demography']].notnull().any(axis=1).astype(int)\n",
    "metadata_init['dailylog_data'] = metadata_init[features_dict['dailylog']].notnull().any(axis=1).astype(int)\n",
    "metadata_init['lifelog_data'] = metadata_init[features_dict['lifelog']].notnull().any(axis=1).astype(int)\n",
    "metadata_init['questionnaire_data'] = metadata_init[features_dict['questionnaire']].notnull().any(axis=1).astype(int)\n",
    "metadata_init['dtype_n'] = metadata_init['dailylog_data'] + metadata_init['lifelog_data'] + metadata_init['questionnaire_data']\n",
    "move_column(metadata_init, 'dtype_n', 8)\n",
    "\n",
    "add_list = ['dailylog_data', 'lifelog_data', 'questionnaire_data', 'dtype_n']\n",
    "for item in add_list:\n",
    "\tif item not in features_dict['metadata']:\n",
    "\t\tfeatures_dict['metadata'].append(item)\n",
    "del add_list\n",
    "\n",
    "check_metadata = False\n",
    "if check_metadata:\n",
    "    check_type = 'questionnaire' # demography, dailylog, lifelog, questionnaire\n",
    "    check_for = 0\n",
    "    test = metadata_init[metadata_init[check_type+'_data'] == check_for].copy()\n",
    "    test = test[features_dict['id']+features_dict['metadata']+features_dict[check_type]]\n",
    "    print(f\"--------- TEST {test.shape[0]} ENTRIES WITH {check_type} = {check_for} ---------\")\n",
    "    display(test.head(10))\n",
    "    save_as_csv(test, TMP_PATH, f\"metadata_{check_type}_{check_for}\")\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    del test, check_type, check_for\n",
    "\n",
    "display(metadata_init.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dccf3dc",
   "metadata": {},
   "source": [
    "## Extract Demography Data\n",
    "\n",
    "- All patients within the scraped data were confirmed to have demographic data (`demography_data` = `True`)\n",
    "- as such demography_data will not be included in the `metadata`\n",
    "- Demography data was extracted and saved as `demography.csv` to the `output` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efc9a7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All demographic columns are unique for each ID in demo_data.\n",
      "Number of rows in demo_data: 429\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>marriage</th>\n",
       "      <th>job</th>\n",
       "      <th>smkHx</th>\n",
       "      <th>drinkHx</th>\n",
       "      <th>suicideHx</th>\n",
       "      <th>suicide_need</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10007</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PXPN_10008</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PXPN_10009</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PXPN_10010</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  gender   age  marriage  job  smkHx  drinkHx  suicideHx  \\\n",
       "0  PXPN_10006       0  32.0       0.0  1.0    1.0      1.0        0.0   \n",
       "1  PXPN_10007       1  38.0       1.0  1.0    0.0      0.0        0.0   \n",
       "2  PXPN_10008       0  38.0       1.0  0.0    0.0      1.0        0.0   \n",
       "3  PXPN_10009       1  28.0       0.0  0.0    1.0      0.0        1.0   \n",
       "4  PXPN_10010       1  21.0       0.0  0.0    1.0      1.0        0.0   \n",
       "\n",
       "   suicide_need  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - (text_utils.py) save_as_csv: Saved panic_demography_data(final_result_diary_20250616).csv to C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\cys\\_output\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/cyshi/OneDrive/Documents/GitHub/Panic-Project-CYS/cys/_output/panic_demography_data(final_result_diary_20250616).csv')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_matrix = [\n",
    "\t('gender_n', 'gender', 'nunique'),\n",
    "\t('age_n', 'age', 'nunique'),\n",
    "\t('marriage_n', 'marriage', 'nunique'),\n",
    "\t('job_n', 'job', 'nunique'),\n",
    "\t('smkHx_n', 'smkHx', 'nunique'),\n",
    "\t('drinkHx_n', 'drinkHx', 'nunique'),\n",
    "\t('suicideHx_n', 'suicideHx', 'nunique'),\n",
    "\t('suicide_need_n', 'suicide_need', 'nunique'),\n",
    "    ('gender', 'gender', 'first'),\n",
    "\t('age', 'age', 'first'),\n",
    "\t('marriage', 'marriage', 'first'),\n",
    "\t('job', 'job', 'first'),\n",
    "\t('smkHx', 'smkHx', 'first'),\n",
    "\t('drinkHx', 'drinkHx', 'first'),\n",
    "\t('suicideHx', 'suicideHx', 'first'),\n",
    "\t('suicide_need', 'suicide_need', 'first'),\n",
    "]\n",
    "demo_data = create_empty_df()\n",
    "demo_data = aggregate_by_column(metadata_init, 'ID', agg_matrix)\n",
    "# check if the length of each unique value is 1\n",
    "non_unique_cols = []\n",
    "for col in features_dict['demography']:\n",
    "\tif demo_data[col+'_n'].apply(lambda x: x > 1).any():\n",
    "\t\tnon_unique_cols.append(col)\n",
    "if non_unique_cols:\n",
    "\traise ValueError(f\"Demographic columns {non_unique_cols} are not unique for each ID in demo_data.\")\n",
    "else:\n",
    "\tprint(\"All demographic columns are unique for each ID in demo_data.\")\n",
    "\n",
    "for col in features_dict['demography']:\n",
    "\tremove_columns(demo_data, [col+'_n'])\n",
    "print(f\"Number of rows in demo_data: {demo_data.shape[0]}\")\n",
    "display(demo_data.head(5))\n",
    "\n",
    "save_as_csv(demo_data, OUTPUT_PATH, f\"panic_demography_data({scraped_data_filename})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd52f179",
   "metadata": {},
   "source": [
    "## Construct Intermediate Metadata\n",
    "- the current `metadata` (`metadata_init`) was filtered to include only columns for identification, added columns for metadata, and labels\n",
    "- the `metadata` was also filtered to get rid of all entries that only have demography data (`dtype_n` = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95b509aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset</th>\n",
       "      <th>coffee</th>\n",
       "      <th>smoking</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "      <th>dtype_n</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic_label</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006_2024-11-04</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10006_2024-11-05</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PXPN_10006_2024-11-06</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PXPN_10006_2024-11-07</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PXPN_10006_2024-11-08</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                entry_id          ID       date dataset  coffee  smoking  \\\n",
       "0  PXPN_10006_2024-11-04  PXPN_10006 2024-11-04    PXPN     NaN      NaN   \n",
       "1  PXPN_10006_2024-11-05  PXPN_10006 2024-11-05    PXPN     NaN      NaN   \n",
       "2  PXPN_10006_2024-11-06  PXPN_10006 2024-11-06    PXPN     NaN      NaN   \n",
       "3  PXPN_10006_2024-11-07  PXPN_10006 2024-11-07    PXPN     NaN      NaN   \n",
       "4  PXPN_10006_2024-11-08  PXPN_10006 2024-11-08    PXPN     NaN      NaN   \n",
       "\n",
       "   total_sleep  dailylog_data  lifelog_data  questionnaire_data  dtype_n  dbp  \\\n",
       "0          NaN              1             1                   1        3  NaN   \n",
       "1        15.26              1             1                   1        3  NaN   \n",
       "2         7.38              1             1                   1        3  1.0   \n",
       "3         6.19              1             1                   1        3  0.0   \n",
       "4          NaN              0             1                   1        2  NaN   \n",
       "\n",
       "   panic_label  severity  \n",
       "0            0       NaN  \n",
       "1            0       NaN  \n",
       "2            0       NaN  \n",
       "3            1       1.0  \n",
       "4            0       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata_int = create_empty_df()\n",
    "metadata_int = metadata_init.copy()\n",
    "\n",
    "metadata_int = metadata_int[features_dict['id'] + features_dict['metadata'] + features_dict['label']]\n",
    "move_column(metadata_int, 'severity', -1)\n",
    "metadata_int = metadata_int[metadata_int['dtype_n'] > 0]\n",
    "display(metadata_int.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c967c9",
   "metadata": {},
   "source": [
    "## Filter Preprocessed Data\n",
    "\n",
    "- demographic features were removed from preprocessed data (`data_pre`)\n",
    "- the data was filtered to remove entries with only demgraphic data\n",
    "- the removed IDs were checked to see if no relevant entries were discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e29ca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre = create_empty_df()\n",
    "data_pre = data_pre_init.copy()\n",
    "# Remove demographic features from data_proc\n",
    "remove_columns(data_pre, features_dict['demography'])\n",
    "# Filter data_proc to keep only rows with entry IDs present in metadata_int\n",
    "metadata_int_unique_ids = metadata_int['entry_id'].unique()\n",
    "data_pre = data_pre[data_pre['entry_id'].isin(metadata_int_unique_ids)]\n",
    "\n",
    "# remove rows with null dates\n",
    "data_pre = data_pre[data_pre['date'].notnull()]\n",
    "\n",
    "# Find IDs present in unfiltered_data but missing in filtered_data (i.e., lost after filtering)\n",
    "check_missing_ids = False\n",
    "if check_missing_ids:\n",
    "\tmissing_ids = np.setdiff1d(data_pre_init['ID'].unique(), data_pre['ID'].unique())\n",
    "\tmissing_data = data_pre_init[data_pre_init['ID'].isin(missing_ids)]\n",
    "\tprint(f\"Number of IDs lost after filtering: {len(missing_ids)}\")\n",
    "\t_ = save_as_csv(missing_data, TMP_PATH, f\"missing_{scraped_data_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cc84e1",
   "metadata": {},
   "source": [
    "## üíæ | Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2daa5322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - (text_utils.py) save_as_csv: Saved panic_pre_data(final_result_diary_20250616).csv to C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\cys\\_output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>PHQ_9</th>\n",
       "      <th>STAI_X2</th>\n",
       "      <th>CSM</th>\n",
       "      <th>CTQ_1</th>\n",
       "      <th>CTQ_2</th>\n",
       "      <th>CTQ_3</th>\n",
       "      <th>...</th>\n",
       "      <th>SLT1</th>\n",
       "      <th>SLT2</th>\n",
       "      <th>SLT3</th>\n",
       "      <th>SLT4</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>severity</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006_2024-11-04</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10006_2024-11-05</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>15.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PXPN_10006_2024-11-06</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.07</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.68</td>\n",
       "      <td>7.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                entry_id dataset          ID       date  PHQ_9  STAI_X2   CSM  \\\n",
       "0  PXPN_10006_2024-11-04    PXPN  PXPN_10006 2024-11-04    0.0     32.0  31.0   \n",
       "1  PXPN_10006_2024-11-05    PXPN  PXPN_10006 2024-11-05    0.0     32.0  31.0   \n",
       "2  PXPN_10006_2024-11-06    PXPN  PXPN_10006 2024-11-06    0.0     32.0  31.0   \n",
       "\n",
       "   CTQ_1  CTQ_2  CTQ_3  ...  SLT1  SLT2  SLT3  SLT4  SLT5  SLT6  total_sleep  \\\n",
       "0   11.0   13.0   17.0  ...   NaN   NaN   NaN   NaN   NaN   NaN          NaN   \n",
       "1   11.0   13.0   17.0  ...   0.0  4.47  3.62  4.67  0.65  1.85        15.26   \n",
       "2   11.0   13.0   17.0  ...   0.0  0.00  0.20  4.07  1.43  1.68         7.38   \n",
       "\n",
       "   severity  dbp  panic_label  \n",
       "0       NaN  NaN            0  \n",
       "1       NaN  NaN            0  \n",
       "2       NaN  1.0            0  \n",
       "\n",
       "[3 rows x 72 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Total entries in original:  24386\n",
      "    SYM entries: 23547\n",
      "    PXPN entries: 839\n",
      "Number of unique IDs in original: 429\n",
      "    SYM IDs:  400\n",
      "    PXPN IDs:  29\n",
      "Number of panic events (dbp=0): 802\n",
      "--------------------------------------------------------\n",
      "Total entries in filtered:  24105\n",
      "    SYM entries: 23291\n",
      "    PXPN entries: 814\n",
      "Number of unique IDs in filtered: 274\n",
      "    SYM IDs:  245\n",
      "    PXPN IDs:  29\n",
      "Number of panic events (dbp=0): 802\n"
     ]
    }
   ],
   "source": [
    "# save data_pre to CSV\n",
    "save_as_csv(data_pre, OUTPUT_PATH, f\"panic_pre_data({scraped_data_filename})\")\n",
    "\n",
    "display(data_pre.head(3))\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"Total entries in original: \", data_pre_init.shape[0])\n",
    "sym1_n = data_pre_init[data_pre_init['dataset'] == 'SYM1'].shape[0]\n",
    "sym2_n = data_pre_init[data_pre_init['dataset'] == 'SYM2'].shape[0]\n",
    "print(\"    SYM entries:\", sym1_n+sym2_n)\n",
    "print(\"    PXPN entries:\", data_pre_init[data_pre_init['dataset'] == 'PXPN'].shape[0])\n",
    "print(\"Number of unique IDs in original:\", len(data_pre_init['ID'].unique()))\n",
    "# find the unique IDs for SYM1 and SYM2\n",
    "sym1_ids = data_pre_init[data_pre_init['dataset'] == 'SYM1']['ID'].unique()\n",
    "sym2_ids = data_pre_init[data_pre_init['dataset'] == 'SYM2']['ID'].unique()\n",
    "print(\"    SYM IDs: \", len(sym1_ids)+len(sym2_ids))\n",
    "print(\"    PXPN IDs: \", len(data_pre_init[data_pre_init['dataset'] == 'PXPN']['ID'].unique()))\n",
    "print(\"Number of panic events (dbp=0):\", data_pre_init[data_pre_init['dbp'] == 0].shape[0])\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"Total entries in filtered: \", data_pre.shape[0])\n",
    "sym1_n = data_pre[data_pre['dataset'] == 'SYM1'].shape[0]\n",
    "sym2_n = data_pre[data_pre['dataset'] == 'SYM2'].shape[0]\n",
    "print(\"    SYM entries:\", sym1_n+sym2_n)\n",
    "print(\"    PXPN entries:\", data_pre[data_pre['dataset'] == 'PXPN'].shape[0])\n",
    "print(\"Number of unique IDs in filtered:\", len(data_pre['ID'].unique()))\n",
    "# find the unique IDs for SYM1 and SYM2\n",
    "sym1_ids = data_pre[data_pre['dataset'] == 'SYM1']['ID'].unique()\n",
    "sym2_ids = data_pre[data_pre['dataset'] == 'SYM2']['ID'].unique()\n",
    "print(\"    SYM IDs: \", len(sym1_ids)+len(sym2_ids))\n",
    "print(\"    PXPN IDs: \", len(data_pre[data_pre['dataset'] == 'PXPN']['ID'].unique()))\n",
    "print(\"Number of panic events (dbp=0):\", data_pre[data_pre['dbp'] == 0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7e6270",
   "metadata": {},
   "source": [
    "# üìñ | Metadata\n",
    "\n",
    "**Description**\n",
    "- `entry_id`: ID for each entry `'ID'_'date'`\n",
    "- `ID`: ID for each patient\n",
    "- `date`: logging date of each entry\n",
    "- `dataset`: source of entry (`SYM1`, `SYM2`, `PXPN`)\n",
    "- `dailylog_data`: whether daily log data exists in the entry (`boolean`)\n",
    "- `lifelog_data`: whether life log data exists in the entry (`boolean`)\n",
    "- `questionnaire_data`: whether questionnaire data exists in the entry (`boolean`)\n",
    "- `dtype_n`: how many of the 3 `state` groups exists in the entry (`int`)\n",
    "- `dbp`: number of consecutive days prior to panic. i.e. panic day = 0; 1 day prior = 1; etc. (up to 3)\n",
    "- `n_prior_data`: number of existing consecutive prior (days) entries\n",
    "- `ref_event_id`: the `entry_id` to which days before panic (`dbp`) is referencing\n",
    "- `valid_entry_3`: whether the entry has 3 consecutive days of prior data (`n_prior_data`)\n",
    "- `valid_entry_2`: whether the entry has 2 consecutive days of prior data (`n_prior_data`)\n",
    "- `valid_entry_1`: whether the entry has 1 consecutive days of prior data (`n_prior_data`)\n",
    "- `panic_label`: whether a panic occured in the entry (`boolean`)\n",
    "- `severity`: severity of the panic (1 ~ 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277e7f97",
   "metadata": {},
   "source": [
    "## Calculate Days Before Panic (``dbp``) and Prior Consecutive Days (``n_prior_data``)\n",
    "\n",
    "- calculate the consecutive 'days before panic' (`dbp`):\n",
    "  - day when panic occured -> `dbp` = 0\n",
    "  - 1 day before panic -> `dbp` = 1\n",
    "  - 2 day before panic -> `dbp` = 2\n",
    "  - 3 day before panic -> `dbp` = 3 (etc)\n",
    "  - stop calculating at a set limit (`delta_days`) or if a panic occurred within the limit\n",
    "- calculate the number of existing prior consecutive (days) entries (`n_prior_data`) (Default: 3)\n",
    "  - stop calculating at a certain limit (`lookback_limit`) (Default: 7)\n",
    "\n",
    "> May take ~ 1 to 2 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f133fed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 100.00% complete\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_20784\\605537347.py:54: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['n_prior_data'] = df['n_prior_data'].fillna(0).astype(int)\n"
     ]
    }
   ],
   "source": [
    "metadata_calc = create_empty_df()\n",
    "metadata_calc = metadata_int.copy()\n",
    "\n",
    "metadata_calc['n_prior_data']    = None\n",
    "metadata_calc['ref_event_id']    = None\n",
    "move_column(metadata_calc, 'panic_label', -1)\n",
    "move_column(metadata_calc, 'severity', -1)\n",
    "metadata_calc.sort_values(by=['ID', 'date'], ascending=False, inplace=True)\n",
    "\n",
    "d_days = 3\n",
    "l_back_lim = 7\n",
    "\n",
    "def calculate_days_before_panic(df, patient_id, delta_days=3, lookback_limit=7):\n",
    "    patient_data = df[df['ID'] == patient_id]\n",
    "    entry_dates_series = patient_data['date']\n",
    "    if len(set(entry_dates_series)) != len(entry_dates_series):\n",
    "        raise ValueError(f\"Duplicate dates found for patient {patient_id}. Please check the data.\")\n",
    "    panic_dates_series = patient_data[patient_data['dbp'] == 0]['date']\n",
    "    if len(set(panic_dates_series)) != len(panic_dates_series):\n",
    "        raise ValueError(f\"Duplicate panic dates found for patient {patient_id}. Please check the data.\")\n",
    "    \n",
    "    entry_dates = set(entry_dates_series)\n",
    "    panic_dates = set(panic_dates_series)\n",
    "\n",
    "    for panic_date in sorted(panic_dates, reverse=True): # Sort from latest to earliest\n",
    "        for j in range(1, delta_days + 1):\n",
    "            prior_date = panic_date - pd.Timedelta(days=j)\n",
    "            if prior_date in entry_dates:\n",
    "                index = patient_data[patient_data['date'] == prior_date].index[0]\n",
    "                df.loc[index, 'dbp'] = j\n",
    "                df.loc[index, 'ref_event_id'] = patient_data.loc[index, 'entry_id']\n",
    "    \n",
    "    for entry_date in sorted(entry_dates, reverse=True):\n",
    "        for j in range(1, lookback_limit + 1):\n",
    "            if j == lookback_limit:\n",
    "                df.loc[index, 'n_prior_data'] = j\n",
    "                break\n",
    "            prior_date = entry_date - pd.Timedelta(days=j)\n",
    "            if prior_date not in entry_dates:\n",
    "                break\n",
    "            index = patient_data[patient_data['date'] == prior_date].index[0]\n",
    "            if df.loc[index, 'panic_label'] == 1:\n",
    "                break\n",
    "            index = patient_data[patient_data['date'] == entry_date].index[0]\n",
    "            df.loc[index, 'n_prior_data'] = j\n",
    "\n",
    "def process_calculate_days_before_panic(df, delta_days=3, lookback_limit=7):\n",
    "    patient_ids = df['ID'].unique()\n",
    "    for patient_id in patient_ids:\n",
    "        calculate_days_before_panic(df, patient_id, delta_days, lookback_limit)\n",
    "        progress = (np.where(patient_ids == patient_id)[0][0] + 1) / len(patient_ids) * 100\n",
    "        print(f\"Processing: {progress:.2f}% complete\", end='\\r')\n",
    "    # replace None values in 'n_prior_data' with 0\n",
    "    df['n_prior_data'] = df['n_prior_data'].fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "metadata_int = process_calculate_days_before_panic(metadata_calc, delta_days=d_days, lookback_limit=l_back_lim)\n",
    "\n",
    "# update features_dict with metadata columns\n",
    "if 'ref_event_id' not in features_dict['metadata']:\n",
    "\tfeatures_dict['metadata'].append('ref_event_id')\n",
    "if 'n_prior_data' not in features_dict['metadata']:\n",
    "\tfeatures_dict['metadata'].append('n_prior_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6da162d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset</th>\n",
       "      <th>coffee</th>\n",
       "      <th>smoking</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "      <th>dtype_n</th>\n",
       "      <th>dbp</th>\n",
       "      <th>n_prior_data</th>\n",
       "      <th>ref_event_id</th>\n",
       "      <th>panic_label</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PXPN_10006_2024-12-02</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PXPN_10006_2024-12-01</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PXPN_10006_2024-11-30</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PXPN_10006_2024-11-29</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-29</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>PXPN_10006_2024-11-29</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PXPN_10006_2024-11-28</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-28</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>PXPN_10006_2024-11-28</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PXPN_10006_2024-11-27</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-27</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>PXPN_10006_2024-11-27</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PXPN_10006_2024-11-26</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-26</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PXPN_10006_2024-11-25</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PXPN_10006_2024-11-24</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-24</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PXPN_10006_2024-11-23</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-23</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.92</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 entry_id          ID       date dataset  coffee  smoking  \\\n",
       "28  PXPN_10006_2024-12-02  PXPN_10006 2024-12-02    PXPN     NaN      NaN   \n",
       "27  PXPN_10006_2024-12-01  PXPN_10006 2024-12-01    PXPN     NaN      NaN   \n",
       "26  PXPN_10006_2024-11-30  PXPN_10006 2024-11-30    PXPN     NaN      NaN   \n",
       "25  PXPN_10006_2024-11-29  PXPN_10006 2024-11-29    PXPN     NaN      NaN   \n",
       "24  PXPN_10006_2024-11-28  PXPN_10006 2024-11-28    PXPN     NaN      NaN   \n",
       "23  PXPN_10006_2024-11-27  PXPN_10006 2024-11-27    PXPN     1.0      NaN   \n",
       "22  PXPN_10006_2024-11-26  PXPN_10006 2024-11-26    PXPN     NaN      NaN   \n",
       "21  PXPN_10006_2024-11-25  PXPN_10006 2024-11-25    PXPN     NaN      NaN   \n",
       "20  PXPN_10006_2024-11-24  PXPN_10006 2024-11-24    PXPN     NaN      NaN   \n",
       "19  PXPN_10006_2024-11-23  PXPN_10006 2024-11-23    PXPN     NaN      NaN   \n",
       "\n",
       "    total_sleep  dailylog_data  lifelog_data  questionnaire_data  dtype_n  \\\n",
       "28          NaN              0             1                   1        2   \n",
       "27          NaN              1             1                   1        3   \n",
       "26          NaN              1             1                   1        3   \n",
       "25          NaN              0             1                   1        2   \n",
       "24          NaN              1             1                   1        3   \n",
       "23         5.72              1             1                   1        3   \n",
       "22         6.63              1             1                   1        3   \n",
       "21         1.96              1             1                   1        3   \n",
       "20          NaN              1             1                   1        3   \n",
       "19         8.92              1             1                   1        3   \n",
       "\n",
       "    dbp  n_prior_data           ref_event_id  panic_label  severity  \n",
       "28  NaN             1                   None            0       NaN  \n",
       "27  NaN             0                   None            0       NaN  \n",
       "26  0.0             7                   None            1       1.0  \n",
       "25  1.0             7  PXPN_10006_2024-11-29            0       NaN  \n",
       "24  2.0             7  PXPN_10006_2024-11-28            0       NaN  \n",
       "23  3.0             7  PXPN_10006_2024-11-27            0       NaN  \n",
       "22  NaN             7                   None            0       NaN  \n",
       "21  NaN             7                   None            0       NaN  \n",
       "20  NaN             7                   None            0       NaN  \n",
       "19  NaN             7                   None            0       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_id = 'PXPN_10006'\n",
    "disp_df = metadata_int[metadata_int['ID'] == p_id]\n",
    "display(disp_df.head(10))\n",
    "del disp_df, p_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded18a26",
   "metadata": {},
   "source": [
    "## Find Valid Entries\n",
    "- add `valid_entry_3`: whether the entry has 3 consecutive days of prior data (`n_prior_data`)\n",
    "- add `valid_entry_2`: whether the entry has 2 consecutive days of prior data (`n_prior_data`)\n",
    "- add `valid_entry_1`: whether the entry has 1 consecutive days of prior data (`n_prior_data`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3cb3f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset</th>\n",
       "      <th>coffee</th>\n",
       "      <th>smoking</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "      <th>dtype_n</th>\n",
       "      <th>dbp</th>\n",
       "      <th>n_prior_data</th>\n",
       "      <th>valid_entry_3</th>\n",
       "      <th>valid_entry_2</th>\n",
       "      <th>valid_entry_1</th>\n",
       "      <th>ref_event_id</th>\n",
       "      <th>panic_label</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24385</th>\n",
       "      <td>SYM2-1-96_2021-08-04</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24384</th>\n",
       "      <td>SYM2-1-96_2021-08-03</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24383</th>\n",
       "      <td>SYM2-1-96_2021-08-02</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-02</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24382</th>\n",
       "      <td>SYM2-1-96_2021-07-30</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-30</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24381</th>\n",
       "      <td>SYM2-1-96_2021-07-29</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-29</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   entry_id         ID       date dataset  coffee  smoking  \\\n",
       "24385  SYM2-1-96_2021-08-04  SYM2-1-96 2021-08-04    SYM2     NaN      NaN   \n",
       "24384  SYM2-1-96_2021-08-03  SYM2-1-96 2021-08-03    SYM2     NaN      NaN   \n",
       "24383  SYM2-1-96_2021-08-02  SYM2-1-96 2021-08-02    SYM2     NaN      NaN   \n",
       "24382  SYM2-1-96_2021-07-30  SYM2-1-96 2021-07-30    SYM2     NaN      NaN   \n",
       "24381  SYM2-1-96_2021-07-29  SYM2-1-96 2021-07-29    SYM2     NaN      NaN   \n",
       "\n",
       "       total_sleep  dailylog_data  lifelog_data  questionnaire_data  dtype_n  \\\n",
       "24385          NaN              0             1                   1        2   \n",
       "24384          NaN              0             1                   1        2   \n",
       "24383          NaN              0             1                   1        2   \n",
       "24382          NaN              0             1                   1        2   \n",
       "24381          NaN              0             1                   1        2   \n",
       "\n",
       "       dbp  n_prior_data  valid_entry_3  valid_entry_2  valid_entry_1  \\\n",
       "24385  NaN             2              0              1              1   \n",
       "24384  NaN             1              0              0              1   \n",
       "24383  NaN             0              0              0              0   \n",
       "24382  NaN             3              1              1              1   \n",
       "24381  NaN             2              0              1              1   \n",
       "\n",
       "      ref_event_id  panic_label  severity  \n",
       "24385         None            0       NaN  \n",
       "24384         None            0       NaN  \n",
       "24383         None            0       NaN  \n",
       "24382         None            0       NaN  \n",
       "24381         None            0       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata_int['valid_entry_3'] = metadata_int.apply(\n",
    "\tlambda row: 1 if row['n_prior_data'] >= 3 else 0,\n",
    "\taxis=1\n",
    ")\n",
    "metadata_int['valid_entry_2'] = metadata_int.apply(\n",
    "\tlambda row: 1 if row['n_prior_data'] >= 2 else 0,\n",
    "\taxis=1\n",
    ")\n",
    "metadata_int['valid_entry_1'] = metadata_int.apply(\n",
    "\tlambda row: 1 if row['n_prior_data'] >= 1 else 0,\n",
    "\taxis=1\n",
    ")\n",
    "move_column(metadata_int, 'ref_event_id', -1)\n",
    "move_column(metadata_int, 'panic_label', -1)\n",
    "move_column(metadata_int, 'severity', -1)\n",
    "display(metadata_int.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dea337",
   "metadata": {},
   "source": [
    "## üíæ | Save Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f69eeb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - (text_utils.py) save_as_csv: Saved panic_metadata(final_result_diary_20250616).csv to C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\cys\\_output\n",
      "DEBUG - (json_utils.py) save_dict_to_file: Dictionary saved successfully to C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\cys\\_output\\panic_features_dict.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset</th>\n",
       "      <th>coffee</th>\n",
       "      <th>smoking</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "      <th>dtype_n</th>\n",
       "      <th>dbp</th>\n",
       "      <th>n_prior_data</th>\n",
       "      <th>valid_entry_3</th>\n",
       "      <th>valid_entry_2</th>\n",
       "      <th>valid_entry_1</th>\n",
       "      <th>ref_event_id</th>\n",
       "      <th>panic_label</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24385</th>\n",
       "      <td>SYM2-1-96_2021-08-04</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24384</th>\n",
       "      <td>SYM2-1-96_2021-08-03</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24383</th>\n",
       "      <td>SYM2-1-96_2021-08-02</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-02</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24382</th>\n",
       "      <td>SYM2-1-96_2021-07-30</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-30</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24381</th>\n",
       "      <td>SYM2-1-96_2021-07-29</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-29</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24380</th>\n",
       "      <td>SYM2-1-96_2021-07-28</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-28</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24379</th>\n",
       "      <td>SYM2-1-96_2021-07-27</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24378</th>\n",
       "      <td>SYM2-1-96_2021-07-22</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-22</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24377</th>\n",
       "      <td>SYM2-1-96_2021-07-21</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-21</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24376</th>\n",
       "      <td>SYM2-1-96_2021-07-20</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-20</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   entry_id         ID       date dataset  coffee  smoking  \\\n",
       "24385  SYM2-1-96_2021-08-04  SYM2-1-96 2021-08-04    SYM2     NaN      NaN   \n",
       "24384  SYM2-1-96_2021-08-03  SYM2-1-96 2021-08-03    SYM2     NaN      NaN   \n",
       "24383  SYM2-1-96_2021-08-02  SYM2-1-96 2021-08-02    SYM2     NaN      NaN   \n",
       "24382  SYM2-1-96_2021-07-30  SYM2-1-96 2021-07-30    SYM2     NaN      NaN   \n",
       "24381  SYM2-1-96_2021-07-29  SYM2-1-96 2021-07-29    SYM2     NaN      NaN   \n",
       "24380  SYM2-1-96_2021-07-28  SYM2-1-96 2021-07-28    SYM2     NaN      NaN   \n",
       "24379  SYM2-1-96_2021-07-27  SYM2-1-96 2021-07-27    SYM2     NaN      NaN   \n",
       "24378  SYM2-1-96_2021-07-22  SYM2-1-96 2021-07-22    SYM2     NaN      NaN   \n",
       "24377  SYM2-1-96_2021-07-21  SYM2-1-96 2021-07-21    SYM2     NaN      NaN   \n",
       "24376  SYM2-1-96_2021-07-20  SYM2-1-96 2021-07-20    SYM2     NaN      NaN   \n",
       "\n",
       "       total_sleep  dailylog_data  lifelog_data  questionnaire_data  dtype_n  \\\n",
       "24385          NaN              0             1                   1        2   \n",
       "24384          NaN              0             1                   1        2   \n",
       "24383          NaN              0             1                   1        2   \n",
       "24382          NaN              0             1                   1        2   \n",
       "24381          NaN              0             1                   1        2   \n",
       "24380          NaN              0             1                   1        2   \n",
       "24379          NaN              0             1                   1        2   \n",
       "24378          NaN              0             1                   1        2   \n",
       "24377          NaN              0             1                   1        2   \n",
       "24376          NaN              0             1                   1        2   \n",
       "\n",
       "       dbp  n_prior_data  valid_entry_3  valid_entry_2  valid_entry_1  \\\n",
       "24385  NaN             2              0              1              1   \n",
       "24384  NaN             1              0              0              1   \n",
       "24383  NaN             0              0              0              0   \n",
       "24382  NaN             3              1              1              1   \n",
       "24381  NaN             2              0              1              1   \n",
       "24380  NaN             1              0              0              1   \n",
       "24379  NaN             0              0              0              0   \n",
       "24378  NaN             7              1              1              1   \n",
       "24377  NaN             7              1              1              1   \n",
       "24376  NaN             7              1              1              1   \n",
       "\n",
       "      ref_event_id  panic_label  severity  \n",
       "24385         None            0       NaN  \n",
       "24384         None            0       NaN  \n",
       "24383         None            0       NaN  \n",
       "24382         None            0       NaN  \n",
       "24381         None            0       NaN  \n",
       "24380         None            0       NaN  \n",
       "24379         None            0       NaN  \n",
       "24378         None            0       NaN  \n",
       "24377         None            0       NaN  \n",
       "24376         None            0       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata = create_empty_df()\n",
    "metadata = metadata_int.copy()\n",
    "save_as_csv(metadata, OUTPUT_PATH, f\"panic_metadata({scraped_data_filename})\")\n",
    "save_dict_to_file(features_dict, OUTPUT_PATH, \"panic_features_dict\")\n",
    "\n",
    "display(metadata.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef5553a",
   "metadata": {},
   "source": [
    "# üîç | Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf6ff081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped data shape: (24386, 79)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>panic</th>\n",
       "      <th>gender</th>\n",
       "      <th>PHQ_9</th>\n",
       "      <th>STAI_X2</th>\n",
       "      <th>CSM</th>\n",
       "      <th>CTQ_1</th>\n",
       "      <th>CTQ_2</th>\n",
       "      <th>CTQ_3</th>\n",
       "      <th>...</th>\n",
       "      <th>SLT1</th>\n",
       "      <th>SLT2</th>\n",
       "      <th>SLT3</th>\n",
       "      <th>SLT4</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>severity</th>\n",
       "      <th>mood</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>15.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID       date  panic  gender  PHQ_9  STAI_X2   CSM  CTQ_1  CTQ_2  \\\n",
       "0  PXPN_10006 2024-11-04    0.0       0    0.0     32.0  31.0   11.0   13.0   \n",
       "1  PXPN_10006 2024-11-05    0.0       0    0.0     32.0  31.0   11.0   13.0   \n",
       "\n",
       "   CTQ_3  ...  SLT1  SLT2  SLT3  SLT4  SLT5  SLT6  total_sleep  severity  \\\n",
       "0   17.0  ...   NaN   NaN   NaN   NaN   NaN   NaN          NaN       NaN   \n",
       "1   17.0  ...   0.0  4.47  3.62  4.67  0.65  1.85        15.26       NaN   \n",
       "\n",
       "   mood  contents  \n",
       "0   NaN       NaN  \n",
       "1   NaN       NaN  \n",
       "\n",
       "[2 rows x 79 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessed shape: (24105, 72)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>PHQ_9</th>\n",
       "      <th>STAI_X2</th>\n",
       "      <th>CSM</th>\n",
       "      <th>CTQ_1</th>\n",
       "      <th>CTQ_2</th>\n",
       "      <th>CTQ_3</th>\n",
       "      <th>...</th>\n",
       "      <th>SLT1</th>\n",
       "      <th>SLT2</th>\n",
       "      <th>SLT3</th>\n",
       "      <th>SLT4</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>severity</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006_2024-11-04</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10006_2024-11-05</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>15.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                entry_id dataset          ID       date  PHQ_9  STAI_X2   CSM  \\\n",
       "0  PXPN_10006_2024-11-04    PXPN  PXPN_10006 2024-11-04    0.0     32.0  31.0   \n",
       "1  PXPN_10006_2024-11-05    PXPN  PXPN_10006 2024-11-05    0.0     32.0  31.0   \n",
       "\n",
       "   CTQ_1  CTQ_2  CTQ_3  ...  SLT1  SLT2  SLT3  SLT4  SLT5  SLT6  total_sleep  \\\n",
       "0   11.0   13.0   17.0  ...   NaN   NaN   NaN   NaN   NaN   NaN          NaN   \n",
       "1   11.0   13.0   17.0  ...   0.0  4.47  3.62  4.67  0.65  1.85        15.26   \n",
       "\n",
       "   severity  dbp  panic_label  \n",
       "0       NaN  NaN            0  \n",
       "1       NaN  NaN            0  \n",
       "\n",
       "[2 rows x 72 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata shape: (24105, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset</th>\n",
       "      <th>coffee</th>\n",
       "      <th>smoking</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "      <th>dtype_n</th>\n",
       "      <th>dbp</th>\n",
       "      <th>n_prior_data</th>\n",
       "      <th>valid_entry_3</th>\n",
       "      <th>valid_entry_2</th>\n",
       "      <th>valid_entry_1</th>\n",
       "      <th>ref_event_id</th>\n",
       "      <th>panic_label</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24385</th>\n",
       "      <td>SYM2-1-96_2021-08-04</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24384</th>\n",
       "      <td>SYM2-1-96_2021-08-03</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   entry_id         ID       date dataset  coffee  smoking  \\\n",
       "24385  SYM2-1-96_2021-08-04  SYM2-1-96 2021-08-04    SYM2     NaN      NaN   \n",
       "24384  SYM2-1-96_2021-08-03  SYM2-1-96 2021-08-03    SYM2     NaN      NaN   \n",
       "\n",
       "       total_sleep  dailylog_data  lifelog_data  questionnaire_data  dtype_n  \\\n",
       "24385          NaN              0             1                   1        2   \n",
       "24384          NaN              0             1                   1        2   \n",
       "\n",
       "       dbp  n_prior_data  valid_entry_3  valid_entry_2  valid_entry_1  \\\n",
       "24385  NaN             2              0              1              1   \n",
       "24384  NaN             1              0              0              1   \n",
       "\n",
       "      ref_event_id  panic_label  severity  \n",
       "24385         None            0       NaN  \n",
       "24384         None            0       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Scraped data shape:\", scraped_data.shape)\n",
    "display(scraped_data.head(2))\n",
    "print(\"Data preprocessed shape:\", data_pre.shape)\n",
    "display(data_pre.head(2))\n",
    "print(\"Metadata shape:\", metadata.shape)\n",
    "display(metadata.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40357bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped Entries: 24386 -> 24105 after preprocessing. discarded 281 entries.\n"
     ]
    }
   ],
   "source": [
    "scraped_data_n = len(scraped_data)\n",
    "data_pre_entry_ids = data_pre['entry_id'].unique()\n",
    "print(f\"Scraped Entries: {scraped_data_n} -> {len(data_pre_entry_ids)} after preprocessing. discarded {scraped_data_n - len(data_pre_entry_ids)} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01ea0faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped Data (n): 429 -> Preprocessed Data (n): 274\n",
      "155 patient data were discarded during preprocessing due to entries having only demographic data\n"
     ]
    }
   ],
   "source": [
    "scraped_data_ids = scraped_data['ID'].unique()\n",
    "data_pre_ids = data_pre['ID'].unique()\n",
    "print(f\"Scraped Data (n): {len(scraped_data_ids)} -> Preprocessed Data (n): {len(data_pre_ids)}\")\n",
    "print(f\"{len(scraped_data_ids) - len(data_pre_ids)} patient data were discarded during preprocessing due to entries having only demographic data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dhlab-panic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
