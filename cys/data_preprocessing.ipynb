{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72f4fd25",
   "metadata": {},
   "source": [
    "# Panic Project (DHLAB) - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5634a08",
   "metadata": {},
   "source": [
    "author:  `@cyshin971`  \n",
    "\n",
    "date:    `2025-06-20`  \n",
    "\n",
    "version: `2.0`\n",
    "\n",
    "> version `1.0`: Derived from `data_analysis.ipynb` version `1.0`  \n",
    "> version `2.0`: Updated to consensus on progress meeting `20250619`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "534a5112",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"2-0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42654e1",
   "metadata": {},
   "source": [
    "# üìö | Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9df09cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config as cfg\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "\n",
    "from library.pandas_utils import move_column, remove_columns, aggregate_by_column, create_empty_df, read_csv\n",
    "from library.text_utils import save_as_csv\n",
    "from library.json_utils import save_dict_to_file\n",
    "from library.path_utils import get_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfc0e3f",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è | Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e80a7b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_data_filename = \"final_result_20250620_360\" # Name of the scraped data file without extension (.csv)\n",
    "\n",
    "save_unnaccounted_data = False  # Set to True (Default: False) if you want to save the unaccounted data to TMP_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa403ca",
   "metadata": {},
   "source": [
    "# üìÅ | Path Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd8780ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./_data\"\n",
    "TMP_PATH = \"./cys/_tmp\"\n",
    "OUT_PATH = f\"./cys/_output\"\n",
    "OUTPUT_PATH = f\"{OUT_PATH}/{scraped_data_filename}/preprocessed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bbe0e9",
   "metadata": {},
   "source": [
    "# ‚õèÔ∏è | Scraped Data\n",
    "\n",
    "load preprocessed data (by `junyeol_lee`)\n",
    "- Each entry are the datapoints for a patient (`ID`) on a specific date (`date`)\n",
    "- If there were multiple datapoints for a specific date (`date`) for a specific patient (`ID`), the values were statistically processed (`sum`, `avg`, etc.) to a representation for the day\n",
    "- Questionnaire data was treated as a 'semi-trait' variable\n",
    "  - The first entry to a questionnaire was forward filled until a second entry to the questionnaire.\n",
    "  - All subsequent entries to the questionnaire was forward filled\n",
    "- Diary contents were added (20250613)\n",
    "\t- `mood`, `contents`\n",
    "- Certain columns were added back (20250613)\n",
    "  - demography: `suicide_need` (`boolean`)\n",
    "  - dailylog:\n",
    "    - `steps_maximum`\n",
    "\t- `steps_mean`\n",
    "\t- `step_hvar_mean`\n",
    "\t- `step_delta`\n",
    "\t- `step_max_delta`\n",
    "\t- `step_mean_delta`\n",
    "\t- `step_hvar_mean_delta`\n",
    "\t- `step_delta2`\n",
    "\t- `step_max_delta2`\n",
    "\t- `step_mean_delta2`\n",
    "\t- `step_hvar_mean_delta2`\n",
    "\t- `steps_variance`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dbe912",
   "metadata": {},
   "source": [
    "## Scraped Data Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aab7722c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables: 75\n",
      "   Demographic variables: 8\n",
      "   Daily log variables: 13\n",
      "   Life log variables: 37\n",
      "   Questionnaire variables: 17\n"
     ]
    }
   ],
   "source": [
    "features_dict = {\n",
    "    \"scraped_data_filename\": scraped_data_filename,\n",
    "    \"preproc_version\": version,\n",
    "\t\"demography\": [\n",
    "\t\t'gender', 'age', 'marriage', 'job', 'smkHx', 'drinkHx', 'suicideHx', 'suicide_need'\n",
    "\t],\n",
    "\t\"dailylog\": [\n",
    "\t\t'panic', 'severity', # NOTE: Caution when constructing dataset as these values are typically labels\n",
    "  \t\t'exercise', 'alcohol', 'coffee', 'menstruation',\n",
    "\t\t'smoking', 'positive_feeling', 'negative_feeling', 'positive_E', 'negative_E',\n",
    "\t\t'anxiety', 'annoying'\n",
    "\t],\n",
    "\t\"lifelog\": [\n",
    "        'HR_var', 'HR_max', 'HR_mean', 'HR_hvar_mean', 'HR_acrophase', 'HR_amplitude', 'HR_mesor',\n",
    "        'HR_acrophase_difference', 'HR_acrophase_difference_2d', 'HR_amplitude_difference',\n",
    "        'HR_amplitude_difference_2d', 'HR_mesor_difference', 'HR_mesor_difference_2d',\n",
    "        'bandpower(0.001-0.0005Hz)', 'bandpower(0.0005-0.0001Hz)', 'bandpower(0.0001-0.00005Hz)', 'bandpower(0.00005-0.00001Hz)',\n",
    "        'steps', 'SLT1', 'SLT2', 'SLT3', 'SLT4', 'SLT5', 'SLT6', 'total_sleep',\n",
    "        'steps_maximum', 'steps_mean', 'step_hvar_mean', 'step_delta',\n",
    "        'step_max_delta', 'step_mean_delta', 'step_hvar_mean_delta',\n",
    "        'step_delta2', 'step_max_delta2', 'step_mean_delta2', 'step_hvar_mean_delta2', 'steps_variance'\n",
    "\t],\n",
    "\t\"questionnaire\": [\n",
    "\t\t'PHQ_9', 'STAI_X2', 'CSM', 'CTQ_1', 'CTQ_2', 'CTQ_3', 'CTQ_4', 'CTQ_5', 'KRQ', 'MDQ',\n",
    "\t\t'ACQ', 'APPQ_1', 'APPQ_2', 'APPQ_3', 'BSQ', 'GAD_7', 'BRIAN'\n",
    "\t],\n",
    "\t# \"diary\":[\n",
    "    #     'mood', 'contents'\n",
    "\t# ],\n",
    "\t\"excluded\": [ # Dropped as variables were only in SYM dataset\n",
    "\t\t'SPAQ_1', 'SPAQ_2', 'BFNE', 'CES_D', 'KOSSSF', 'SADS', 'STAI_X1', 'medication_in_month',\n",
    "        'Unnamed: 0' # Placeholder column\n",
    "\t],\n",
    "    \"id\": [\n",
    "        'ID', 'date'\n",
    "    ],\n",
    "    \"label\": [\n",
    "        'panic', 'severity'\n",
    "    ],\n",
    "    \"metadata\": []\n",
    "}\n",
    "\n",
    "demo_vars = features_dict[\"demography\"]\n",
    "dailylog_vars = features_dict[\"dailylog\"]\n",
    "lifelog_vars = features_dict[\"lifelog\"]\n",
    "questionnaire_vars = features_dict[\"questionnaire\"]\n",
    "\n",
    "state_vars = demo_vars\n",
    "trait_vars = dailylog_vars + lifelog_vars + questionnaire_vars\n",
    "all_vars = state_vars + dailylog_vars + lifelog_vars + questionnaire_vars\n",
    "all_cols = features_dict[\"id\"] + all_vars # + features_dict[\"diary\"]\n",
    "\n",
    "print(f'Number of variables: {len(all_vars)}')\n",
    "print(f'   Demographic variables: {len(state_vars)}')\n",
    "print(f'   Daily log variables: {len(dailylog_vars)}')\n",
    "print(f'   Life log variables: {len(lifelog_vars)}')\n",
    "print(f'   Questionnaire variables: {len(questionnaire_vars)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81218b4a",
   "metadata": {},
   "source": [
    "## Load Scraped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a279cfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (2246184437.py) <module>: All expected columns are present in scraped_data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 29002\n",
      "Number of columns: 77\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>panic</th>\n",
       "      <th>gender</th>\n",
       "      <th>PHQ_9</th>\n",
       "      <th>STAI_X2</th>\n",
       "      <th>CSM</th>\n",
       "      <th>CTQ_1</th>\n",
       "      <th>CTQ_2</th>\n",
       "      <th>CTQ_3</th>\n",
       "      <th>...</th>\n",
       "      <th>HR_mean</th>\n",
       "      <th>HR_hvar_mean</th>\n",
       "      <th>SLT1</th>\n",
       "      <th>SLT2</th>\n",
       "      <th>SLT3</th>\n",
       "      <th>SLT4</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.33</td>\n",
       "      <td>123.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.81</td>\n",
       "      <td>29.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>15.26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.71</td>\n",
       "      <td>50.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.07</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.68</td>\n",
       "      <td>7.38</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>79.18</td>\n",
       "      <td>72.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>6.19</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>87.58</td>\n",
       "      <td>228.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID       date  panic  gender  PHQ_9  STAI_X2   CSM  CTQ_1  CTQ_2  \\\n",
       "0  PXPN_10006 2024-11-04    0.0       0    0.0     32.0  31.0   11.0   13.0   \n",
       "1  PXPN_10006 2024-11-05    0.0       0    0.0     32.0  31.0   11.0   13.0   \n",
       "2  PXPN_10006 2024-11-06    1.0       0    0.0     32.0  31.0   11.0   13.0   \n",
       "3  PXPN_10006 2024-11-07    2.0       0    0.0     32.0  31.0   11.0   13.0   \n",
       "4  PXPN_10006 2024-11-08    0.0       0    0.0     32.0  31.0   11.0   13.0   \n",
       "\n",
       "   CTQ_3  ...  HR_mean  HR_hvar_mean  SLT1  SLT2  SLT3  SLT4  SLT5  SLT6  \\\n",
       "0   17.0  ...    74.33        123.22   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1   17.0  ...    54.81         29.40   0.0  4.47  3.62  4.67  0.65  1.85   \n",
       "2   17.0  ...    62.71         50.58   0.0  0.00  0.20  4.07  1.43  1.68   \n",
       "3   17.0  ...    79.18         72.70   0.0  0.00  0.14  5.08  0.00  0.97   \n",
       "4   17.0  ...    87.58        228.52   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "   total_sleep  severity  \n",
       "0          NaN       NaN  \n",
       "1        15.26       NaN  \n",
       "2         7.38       NaN  \n",
       "3         6.19       1.0  \n",
       "4          NaN       NaN  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scraped_data = read_csv(get_file_path(DATA_PATH, scraped_data_filename+'.csv'))\n",
    "\n",
    "# check if all columns are present\n",
    "missing_cols = [col for col in all_vars if col not in scraped_data.columns]\n",
    "if missing_cols:\n",
    "    logging.warning(f\"Missing columns in scraped_data: {missing_cols}\")\n",
    "else:\n",
    "\tlogging.info(\"All expected columns are present in scraped_data.\")\n",
    "extra_cols = [col for col in scraped_data.columns if col not in all_cols + features_dict[\"excluded\"]]\n",
    "if extra_cols:\n",
    "\tlogging.warning(f\"Extra columns in scraped_data: {extra_cols}\")\n",
    "\n",
    "# convert date column to datetime format\n",
    "scraped_data['date'] = pd.to_datetime(scraped_data['date'], format='%Y-%m-%d')\n",
    "remove_columns(scraped_data, ['Unnamed: 0'])\n",
    "\n",
    "# remove any of the columns in features_dict[\"excluded\"] if they exist\n",
    "for col in features_dict[\"excluded\"]:\n",
    "\tif col in scraped_data.columns:\n",
    "\t\tlogging.info(f\"Removing excluded column: {col}\")\n",
    "\t\tscraped_data.drop(columns=[col], inplace=True)\n",
    "\n",
    "print(f\"Number of rows: {scraped_data.shape[0]}\")\n",
    "print(f\"Number of columns: {scraped_data.shape[1]}\")\n",
    "display(scraped_data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6024277b",
   "metadata": {},
   "source": [
    "# ‚öíÔ∏è | Data Preprocessing\n",
    "\n",
    "Changes from scraped data:\n",
    "- add `entry_id` to identify each entry: `'ID'_'date'`\n",
    "- add `dataset` to identify source: `SYM1`, `SYM2`, `PXPN`\n",
    "- convert `panic` (`0`, `1`, `2` = panic) to days before panic (`dbp`) (panic = `0`, `1`, `2`)\n",
    "- keep `panic` column instead of removing it (`20250617`)\n",
    "- add `panic_label` : whether a panic occurred in the entry (`boolean`)\n",
    "- demographic features were removed from preprocessed data (`data_pre`) and extracted\n",
    "- diary features were removed from preprocessed data (`data_pre`) and extracted\n",
    "- the data was filtered to remove entries with only demgraphic data (no `dailylog`, `lifelog`, `questionnaire`, or `diary` entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5b1f06",
   "metadata": {},
   "source": [
    "## Initialize Preprocessed Data\n",
    "\n",
    "- add `entry_id` to identify each entry: `'ID'_'date'`\n",
    "- add `dataset` to identify source: `SYM1`, `SYM2`, `PXPN`\n",
    "- convert `panic` (`0`, `1`, `2` = panic) to days befor panic (`dbp`) (panic = `0`, `1`, `2`)\n",
    "- add `panic_label` (boolean)\n",
    "- keep `panic` column instead of removing it (`20250617`)\n",
    "> If using `panic` column as a label this must be removed as a feature from final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d5a6ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique entry IDs: 29002\n",
      "Scraped data shape: (29002, 77)\n",
      "Initialized preprocessed data shape: (29002, 81)\n"
     ]
    }
   ],
   "source": [
    "data_pre_init = create_empty_df()\n",
    "data_pre_init = scraped_data.copy()\n",
    "\n",
    "# Add 'entry_id' column: unique identifier for each row\n",
    "data_pre_init['entry_id'] = data_pre_init['ID'] + '_' + data_pre_init['date'].astype(str)\n",
    "instance_id_unique = data_pre_init['entry_id'].unique()\n",
    "move_column(data_pre_init, 'entry_id', 0)\n",
    "print(\"Number of unique entry IDs:\", len(instance_id_unique))\n",
    "# Check if 'entry_id' is unique\n",
    "if data_pre_init['entry_id'].duplicated().any():\n",
    "\t# return the rows with duplicate 'entry_id'\n",
    "\tduplicates = data_pre_init[data_pre_init['entry_id'].duplicated(keep=False)]\n",
    "\tdisplay(duplicates.head(5))\n",
    "\tsave_as_csv(duplicates, TMP_PATH, f\"duplicates_{scraped_data_filename}\")\n",
    "\traise ValueError(\"Duplicate 'entry_id' found in the data. Please resolve this issue before proceeding.\")\n",
    "\n",
    "# Add 'dataset' column: source of data\n",
    "data_pre_init['dataset'] = data_pre_init['ID'].str.split('_').str[0]\n",
    "data_pre_init['dataset'] = data_pre_init['dataset'].str.split('-').str[0]\n",
    "move_column(data_pre_init, 'dataset', 1)\n",
    "\n",
    "# Convert 'panic' column to Days Before Panic (dbp)\n",
    "data_pre_init['dbp'] = data_pre_init.apply(\n",
    "\tlambda row: np.nan if row['panic'] == 0\n",
    " \t\t\t\telse 0 if row['panic'] == 2 else row['panic'],\n",
    "\taxis=1\n",
    ")\n",
    "\n",
    "# Add panic_label column\n",
    "data_pre_init['panic_label'] = data_pre_init['panic'].apply(lambda x: 1 if x == 2 else 0)\n",
    "\n",
    "# Update the features_dict\n",
    "if 'entry_id' not in features_dict['id']:\n",
    "\tfeatures_dict['id'].insert(0, 'entry_id')\n",
    "if 'dataset' not in features_dict['id']:\n",
    "\tfeatures_dict['id'].append('dataset')\n",
    "if 'dbp' not in features_dict['dailylog']:\n",
    "\tfeatures_dict['label'].insert(0, 'dbp')\n",
    "if 'panic_label' not in features_dict['label']:\n",
    "\tfeatures_dict['label'].append('panic_label')\n",
    "# Remove 'panic' from dailylog features (as it is a label) #NOTE: Need to remove as panic null values were filled with 0 in scraped_data\n",
    "if 'panic' in features_dict['dailylog']:\n",
    "\tfeatures_dict['dailylog'].remove('panic')\n",
    "\n",
    "# print scraped_data shape\n",
    "print(f\"Scraped data shape: {scraped_data.shape}\")\n",
    "print(f\"Initialized preprocessed data shape: {data_pre_init.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "276b12c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>panic</th>\n",
       "      <th>gender</th>\n",
       "      <th>PHQ_9</th>\n",
       "      <th>STAI_X2</th>\n",
       "      <th>CSM</th>\n",
       "      <th>CTQ_1</th>\n",
       "      <th>...</th>\n",
       "      <th>SLT1</th>\n",
       "      <th>SLT2</th>\n",
       "      <th>SLT3</th>\n",
       "      <th>SLT4</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>severity</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006_2024-11-04</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10006_2024-11-05</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>15.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PXPN_10006_2024-11-06</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.07</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.68</td>\n",
       "      <td>7.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PXPN_10006_2024-11-07</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>6.19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PXPN_10006_2024-11-08</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                entry_id dataset          ID       date  panic  gender  PHQ_9  \\\n",
       "0  PXPN_10006_2024-11-04    PXPN  PXPN_10006 2024-11-04    0.0       0    0.0   \n",
       "1  PXPN_10006_2024-11-05    PXPN  PXPN_10006 2024-11-05    0.0       0    0.0   \n",
       "2  PXPN_10006_2024-11-06    PXPN  PXPN_10006 2024-11-06    1.0       0    0.0   \n",
       "3  PXPN_10006_2024-11-07    PXPN  PXPN_10006 2024-11-07    2.0       0    0.0   \n",
       "4  PXPN_10006_2024-11-08    PXPN  PXPN_10006 2024-11-08    0.0       0    0.0   \n",
       "\n",
       "   STAI_X2   CSM  CTQ_1  ...  SLT1  SLT2  SLT3  SLT4  SLT5  SLT6  total_sleep  \\\n",
       "0     32.0  31.0   11.0  ...   NaN   NaN   NaN   NaN   NaN   NaN          NaN   \n",
       "1     32.0  31.0   11.0  ...   0.0  4.47  3.62  4.67  0.65  1.85        15.26   \n",
       "2     32.0  31.0   11.0  ...   0.0  0.00  0.20  4.07  1.43  1.68         7.38   \n",
       "3     32.0  31.0   11.0  ...   0.0  0.00  0.14  5.08  0.00  0.97         6.19   \n",
       "4     32.0  31.0   11.0  ...   NaN   NaN   NaN   NaN   NaN   NaN          NaN   \n",
       "\n",
       "   severity  dbp  panic_label  \n",
       "0       NaN  NaN            0  \n",
       "1       NaN  NaN            0  \n",
       "2       NaN  1.0            0  \n",
       "3       1.0  0.0            1  \n",
       "4       NaN  NaN            0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique sources in metadata_ljy:  ['PXPN' 'SYM1' 'SYM2']\n",
      "Number of entries in metadata_ljy: 29002\n",
      "    SYM entries: 28163\n",
      "    PXPN entries: 839\n",
      "Number of unique IDs in metadata_ljy: 429\n",
      "    SYM IDs:  400\n",
      "    PXPN IDs:  29\n",
      "Number of panic events (dbp=0): 811\n"
     ]
    }
   ],
   "source": [
    "display(data_pre_init.head(5))\n",
    "print(\"Unique sources in metadata_ljy: \", data_pre_init['dataset'].unique())\n",
    "print(\"Number of entries in metadata_ljy:\", data_pre_init.shape[0])\n",
    "sym1_n = data_pre_init[data_pre_init['dataset'] == 'SYM1'].shape[0]\n",
    "sym2_n = data_pre_init[data_pre_init['dataset'] == 'SYM2'].shape[0]\n",
    "print(\"    SYM entries:\", sym1_n+sym2_n)\n",
    "print(\"    PXPN entries:\", data_pre_init[data_pre_init['dataset'] == 'PXPN'].shape[0])\n",
    "print(\"Number of unique IDs in metadata_ljy:\", len(data_pre_init['ID'].unique()))\n",
    "# find the unique IDs for SYM1 and SYM2\n",
    "sym1_ids = data_pre_init[data_pre_init['dataset'] == 'SYM1']['ID'].unique()\n",
    "sym2_ids = data_pre_init[data_pre_init['dataset'] == 'SYM2']['ID'].unique()\n",
    "print(\"    SYM IDs: \", len(sym1_ids)+len(sym2_ids))\n",
    "print(\"    PXPN IDs: \", len(data_pre_init[data_pre_init['dataset'] == 'PXPN']['ID'].unique()))\n",
    "print(\"Number of panic events (dbp=0):\", data_pre_init[data_pre_init['dbp'] == 0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7cac54",
   "metadata": {},
   "source": [
    "## Initialize Metadata\n",
    "\n",
    "initialize `metadata` by adding\n",
    "- `demography_data` : whether demography data exists in the entry (`boolean`)\n",
    "- `dailylog_data`, `lifelog_data`, `questionnaire_data` : whether each data group exists in the entry (`boolean`)\n",
    "- `dtype_n` : how many of the 3 `state` groups exists in the entry (`int`)\n",
    "- `diary_data`: whether panic diary data group exists in the entry (`boolean`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ed181f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>panic</th>\n",
       "      <th>gender</th>\n",
       "      <th>PHQ_9</th>\n",
       "      <th>STAI_X2</th>\n",
       "      <th>dtype_n</th>\n",
       "      <th>CSM</th>\n",
       "      <th>...</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>severity</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic_label</th>\n",
       "      <th>demography_data</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006_2024-11-04</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10006_2024-11-05</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>15.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PXPN_10006_2024-11-06</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.68</td>\n",
       "      <td>7.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PXPN_10006_2024-11-07</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>6.19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PXPN_10006_2024-11-08</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                entry_id dataset          ID       date  panic  gender  PHQ_9  \\\n",
       "0  PXPN_10006_2024-11-04    PXPN  PXPN_10006 2024-11-04    0.0       0    0.0   \n",
       "1  PXPN_10006_2024-11-05    PXPN  PXPN_10006 2024-11-05    0.0       0    0.0   \n",
       "2  PXPN_10006_2024-11-06    PXPN  PXPN_10006 2024-11-06    1.0       0    0.0   \n",
       "3  PXPN_10006_2024-11-07    PXPN  PXPN_10006 2024-11-07    2.0       0    0.0   \n",
       "4  PXPN_10006_2024-11-08    PXPN  PXPN_10006 2024-11-08    0.0       0    0.0   \n",
       "\n",
       "   STAI_X2  dtype_n   CSM  ...  SLT5  SLT6  total_sleep  severity  dbp  \\\n",
       "0     32.0        3  31.0  ...   NaN   NaN          NaN       NaN  NaN   \n",
       "1     32.0        3  31.0  ...  0.65  1.85        15.26       NaN  NaN   \n",
       "2     32.0        3  31.0  ...  1.43  1.68         7.38       NaN  1.0   \n",
       "3     32.0        3  31.0  ...  0.00  0.97         6.19       1.0  0.0   \n",
       "4     32.0        2  31.0  ...   NaN   NaN          NaN       NaN  NaN   \n",
       "\n",
       "   panic_label  demography_data  dailylog_data  lifelog_data  \\\n",
       "0            0                1              1             1   \n",
       "1            0                1              1             1   \n",
       "2            0                1              1             1   \n",
       "3            1                1              1             1   \n",
       "4            0                1              0             1   \n",
       "\n",
       "   questionnaire_data  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   1  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata_init = create_empty_df()\n",
    "metadata_init = data_pre_init.copy()\n",
    "\n",
    "metadata_init['demography_data'] = metadata_init[features_dict['demography']].notnull().any(axis=1).astype(int)\n",
    "metadata_init['dailylog_data'] = metadata_init[features_dict['dailylog']].notnull().any(axis=1).astype(int)\n",
    "metadata_init['lifelog_data'] = metadata_init[features_dict['lifelog']].notnull().any(axis=1).astype(int)\n",
    "metadata_init['questionnaire_data'] = metadata_init[features_dict['questionnaire']].notnull().any(axis=1).astype(int)\n",
    "# metadata_init['diary_data'] = metadata_init[features_dict['diary']].notnull().any(axis=1).astype(int)\n",
    "\n",
    "# TODO: Diary data is not used in the current analysis, but can be useful for future reference\n",
    "metadata_init['dtype_n'] = metadata_init['dailylog_data'] + metadata_init['lifelog_data'] + metadata_init['questionnaire_data'] #TODO: + metadata_init['diary_data']\n",
    "move_column(metadata_init, 'dtype_n', 8)\n",
    "\n",
    "add_list = ['dailylog_data', 'lifelog_data', 'questionnaire_data', 'dtype_n'] # , 'diary_data']\n",
    "for item in add_list:\n",
    "\tif item not in features_dict['metadata']:\n",
    "\t\tfeatures_dict['metadata'].append(item)\n",
    "del add_list\n",
    "\n",
    "check_metadata = False\n",
    "if check_metadata:\n",
    "    check_type = 'questionnaire' # demography, dailylog, lifelog, questionnaire\n",
    "    check_for = 0\n",
    "    test = metadata_init[metadata_init[check_type+'_data'] == check_for].copy()\n",
    "    test = test[features_dict['id']+features_dict['metadata']+features_dict[check_type]]\n",
    "    print(f\"--------- TEST {test.shape[0]} ENTRIES WITH {check_type} = {check_for} ---------\")\n",
    "    display(test.head(10))\n",
    "    save_as_csv(test, TMP_PATH, f\"metadata_{check_type}_{check_for}\")\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    del test, check_type, check_for\n",
    "\n",
    "display(metadata_init.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dccf3dc",
   "metadata": {},
   "source": [
    "## Extract Demography Data\n",
    "\n",
    "- All patients within the scraped data were confirmed to have demographic data (`demography_data` = `True`)\n",
    "- as such demography_data will not be included in the `metadata`\n",
    "- demographic features were removed from preprocessed data (`data_pre`)\n",
    "- Demography data was extracted and saved as `demography.csv` to the `output` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efc9a7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All demographic columns are unique for each ID in demo_data.\n",
      "Number of rows in demo_data: 429\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>marriage</th>\n",
       "      <th>job</th>\n",
       "      <th>smkHx</th>\n",
       "      <th>drinkHx</th>\n",
       "      <th>suicideHx</th>\n",
       "      <th>suicide_need</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10007</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PXPN_10008</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PXPN_10009</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PXPN_10010</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  gender   age  marriage  job  smkHx  drinkHx  suicideHx  \\\n",
       "0  PXPN_10006       0  32.0       0.0  1.0    1.0      1.0        0.0   \n",
       "1  PXPN_10007       1  38.0       1.0  1.0    0.0      0.0        0.0   \n",
       "2  PXPN_10008       0  38.0       1.0  0.0    0.0      1.0        0.0   \n",
       "3  PXPN_10009       1  28.0       0.0  0.0    1.0      0.0        1.0   \n",
       "4  PXPN_10010       1  21.0       0.0  0.0    1.0      1.0        0.0   \n",
       "\n",
       "   suicide_need  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - (path_utils.py) make_dir: Created directory: C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\cys\\_output\\final_result_20250620_360\\preprocessed\n",
      "DEBUG - (text_utils.py) save_as_csv: Saved panic_demography_data_2-0(final_result_20250620_360).csv to C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\cys\\_output\\final_result_20250620_360\\preprocessed\n"
     ]
    }
   ],
   "source": [
    "agg_matrix = [\n",
    "\t('gender_n', 'gender', 'nunique'),\n",
    "\t('age_n', 'age', 'nunique'),\n",
    "\t('marriage_n', 'marriage', 'nunique'),\n",
    "\t('job_n', 'job', 'nunique'),\n",
    "\t('smkHx_n', 'smkHx', 'nunique'),\n",
    "\t('drinkHx_n', 'drinkHx', 'nunique'),\n",
    "\t('suicideHx_n', 'suicideHx', 'nunique'),\n",
    "\t('suicide_need_n', 'suicide_need', 'nunique'),\n",
    "    ('gender', 'gender', 'first'),\n",
    "\t('age', 'age', 'first'),\n",
    "\t('marriage', 'marriage', 'first'),\n",
    "\t('job', 'job', 'first'),\n",
    "\t('smkHx', 'smkHx', 'first'),\n",
    "\t('drinkHx', 'drinkHx', 'first'),\n",
    "\t('suicideHx', 'suicideHx', 'first'),\n",
    "\t('suicide_need', 'suicide_need', 'first'),\n",
    "]\n",
    "demo_data = create_empty_df()\n",
    "demo_data = aggregate_by_column(metadata_init, 'ID', agg_matrix)\n",
    "\n",
    "# check if the length of each unique value is 1\n",
    "non_unique_cols = []\n",
    "for col in features_dict['demography']:\n",
    "\tif demo_data[col+'_n'].apply(lambda x: x > 1).any():\n",
    "\t\tnon_unique_cols.append(col)\n",
    "if non_unique_cols:\n",
    "\traise ValueError(f\"Demographic columns {non_unique_cols} are not unique for each ID in demo_data.\")\n",
    "else:\n",
    "\tprint(\"All demographic columns are unique for each ID in demo_data.\")\n",
    "\n",
    "for col in features_dict['demography']:\n",
    "\tremove_columns(demo_data, [col+'_n'])\n",
    "print(f\"Number of rows in demo_data: {demo_data.shape[0]}\")\n",
    "display(demo_data.head(5))\n",
    "\n",
    "save_as_csv(demo_data, OUTPUT_PATH, f\"panic_demography_data_{version}({scraped_data_filename})\")\n",
    "# Remove demographic features from data_proc\n",
    "remove_columns(data_pre_init, features_dict['demography'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e384fd55",
   "metadata": {},
   "source": [
    "## Extract Panic Diary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26c08088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if all(col in data_pre_init.columns for col in features_dict['diary']):\n",
    "# \tpanic_diary_data = create_empty_df()\n",
    "# \tpanic_diary_data = data_pre_init[features_dict['id'] + features_dict['diary']].copy()\n",
    "\n",
    "# \tpanic_diary_entries = metadata_init[metadata_init['diary_data'] == 1]['entry_id'].unique()\n",
    "# \t# Filter panic_diary_data to only include entries with diary data\n",
    "# \tpanic_diary_data = panic_diary_data[panic_diary_data['entry_id'].isin(panic_diary_entries)]\n",
    "\n",
    "# \tprint(f\"Number of rows in panic_diary_data: {panic_diary_data.shape[0]}\")\n",
    "# \tprint(f\"Number of unique patients in panic_diary_data: {panic_diary_data['ID'].nunique()}\")\n",
    "# \tprint(f\"Unique datasets in panic_diary_data: {panic_diary_data['dataset'].unique()}\")\n",
    "# \tdisplay(panic_diary_data.head(5))\n",
    "\n",
    "# \tsave_as_csv(panic_diary_data, OUTPUT_PATH, f\"panic_diary_data_{version}({scraped_data_filename})\")\n",
    "# \tremove_columns(data_pre_init, features_dict['diary'])  # Remove diary columns from data_pre_init\n",
    "# else:\n",
    "# \tprint(\"No diary data found in the scraped data. Skipping panic_diary_data creation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd52f179",
   "metadata": {},
   "source": [
    "## Construct Intermediate Metadata\n",
    "- the current `metadata` (`metadata_init`) was filtered to include only columns for identification, added columns for metadata, and labels\n",
    "- the `metadata` was also filtered to get rid of all entries that only have demography data (`dtype_n` = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95b509aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "      <th>dtype_n</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic</th>\n",
       "      <th>severity</th>\n",
       "      <th>panic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006_2024-11-04</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10006_2024-11-05</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PXPN_10006_2024-11-06</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PXPN_10006_2024-11-07</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PXPN_10006_2024-11-08</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                entry_id          ID       date dataset  dailylog_data  \\\n",
       "0  PXPN_10006_2024-11-04  PXPN_10006 2024-11-04    PXPN              1   \n",
       "1  PXPN_10006_2024-11-05  PXPN_10006 2024-11-05    PXPN              1   \n",
       "2  PXPN_10006_2024-11-06  PXPN_10006 2024-11-06    PXPN              1   \n",
       "3  PXPN_10006_2024-11-07  PXPN_10006 2024-11-07    PXPN              1   \n",
       "4  PXPN_10006_2024-11-08  PXPN_10006 2024-11-08    PXPN              0   \n",
       "\n",
       "   lifelog_data  questionnaire_data  dtype_n  dbp  panic  severity  \\\n",
       "0             1                   1        3  NaN    0.0       NaN   \n",
       "1             1                   1        3  NaN    0.0       NaN   \n",
       "2             1                   1        3  1.0    1.0       NaN   \n",
       "3             1                   1        3  0.0    2.0       1.0   \n",
       "4             1                   1        2  NaN    0.0       NaN   \n",
       "\n",
       "   panic_label  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            1  \n",
       "4            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata_int = create_empty_df()\n",
    "metadata_int = metadata_init.copy()\n",
    "\n",
    "metadata_int = metadata_int[features_dict['id'] + features_dict['metadata'] + features_dict['label']]\n",
    "move_column(metadata_int, 'severity', -1)\n",
    "move_column(metadata_int, 'panic_label', -1)\n",
    "metadata_int = metadata_int[metadata_int['dtype_n'] > 0]\n",
    "metadata_int = metadata_int[metadata_int['date'].notnull()]\n",
    "display(metadata_int.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c967c9",
   "metadata": {},
   "source": [
    "## Filter Preprocessed Data\n",
    "\n",
    "- the data was filtered to remove entries with only demgraphic data\n",
    "- the removed IDs were checked to see if no relevant entries were discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e29ca52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>PHQ_9</th>\n",
       "      <th>STAI_X2</th>\n",
       "      <th>CSM</th>\n",
       "      <th>CTQ_1</th>\n",
       "      <th>CTQ_2</th>\n",
       "      <th>CTQ_3</th>\n",
       "      <th>...</th>\n",
       "      <th>SLT2</th>\n",
       "      <th>SLT3</th>\n",
       "      <th>SLT4</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic</th>\n",
       "      <th>severity</th>\n",
       "      <th>panic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006_2024-11-04</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10006_2024-11-05</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.47</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>15.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PXPN_10006_2024-11-06</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.07</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.68</td>\n",
       "      <td>7.38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PXPN_10006_2024-11-07</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>6.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PXPN_10006_2024-11-08</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                entry_id dataset          ID       date  PHQ_9  STAI_X2   CSM  \\\n",
       "0  PXPN_10006_2024-11-04    PXPN  PXPN_10006 2024-11-04    0.0     32.0  31.0   \n",
       "1  PXPN_10006_2024-11-05    PXPN  PXPN_10006 2024-11-05    0.0     32.0  31.0   \n",
       "2  PXPN_10006_2024-11-06    PXPN  PXPN_10006 2024-11-06    0.0     32.0  31.0   \n",
       "3  PXPN_10006_2024-11-07    PXPN  PXPN_10006 2024-11-07    0.0     32.0  31.0   \n",
       "4  PXPN_10006_2024-11-08    PXPN  PXPN_10006 2024-11-08    0.0     32.0  31.0   \n",
       "\n",
       "   CTQ_1  CTQ_2  CTQ_3  ...  SLT2  SLT3  SLT4  SLT5  SLT6  total_sleep  dbp  \\\n",
       "0   11.0   13.0   17.0  ...   NaN   NaN   NaN   NaN   NaN          NaN  NaN   \n",
       "1   11.0   13.0   17.0  ...  4.47  3.62  4.67  0.65  1.85        15.26  NaN   \n",
       "2   11.0   13.0   17.0  ...  0.00  0.20  4.07  1.43  1.68         7.38  1.0   \n",
       "3   11.0   13.0   17.0  ...  0.00  0.14  5.08  0.00  0.97         6.19  0.0   \n",
       "4   11.0   13.0   17.0  ...   NaN   NaN   NaN   NaN   NaN          NaN  NaN   \n",
       "\n",
       "   panic  severity  panic_label  \n",
       "0    0.0       NaN            0  \n",
       "1    0.0       NaN            0  \n",
       "2    1.0       NaN            0  \n",
       "3    2.0       1.0            1  \n",
       "4    0.0       NaN            0  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_pre = create_empty_df()\n",
    "data_pre = data_pre_init.copy()\n",
    "\n",
    "# Filter data_proc to keep only rows with entry IDs present in metadata_int\n",
    "metadata_int_unique_ids = metadata_int['entry_id'].unique()\n",
    "data_pre = data_pre[data_pre['entry_id'].isin(metadata_int_unique_ids)]\n",
    "\n",
    "# remove rows with null dates\n",
    "data_pre = data_pre[data_pre['date'].notnull()]\n",
    "\n",
    "# Move label columns to the end\n",
    "move_column(data_pre, 'dbp', -1)\n",
    "move_column(data_pre, 'panic', -1)\n",
    "move_column(data_pre, 'severity', -1)\n",
    "move_column(data_pre, 'panic_label', -1)\n",
    "\n",
    "display(data_pre.head(5))\n",
    "\n",
    "# Find IDs present in unfiltered_data but missing in filtered_data (i.e., lost after filtering)\n",
    "check_missing_ids = False\n",
    "if check_missing_ids:\n",
    "\tmissing_ids = np.setdiff1d(data_pre_init['ID'].unique(), data_pre['ID'].unique())\n",
    "\tmissing_data = data_pre_init[data_pre_init['ID'].isin(missing_ids)]\n",
    "\tprint(f\"Number of IDs lost after filtering: {len(missing_ids)}\")\n",
    "\t_ = save_as_csv(missing_data, TMP_PATH, f\"missing_{scraped_data_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cc84e1",
   "metadata": {},
   "source": [
    "## üíæ | Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2daa5322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - (text_utils.py) save_as_csv: Saved panic_pre_data_2-0(final_result_20250620_360).csv to C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\cys\\_output\\final_result_20250620_360\\preprocessed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>PHQ_9</th>\n",
       "      <th>STAI_X2</th>\n",
       "      <th>CSM</th>\n",
       "      <th>CTQ_1</th>\n",
       "      <th>CTQ_2</th>\n",
       "      <th>CTQ_3</th>\n",
       "      <th>...</th>\n",
       "      <th>SLT2</th>\n",
       "      <th>SLT3</th>\n",
       "      <th>SLT4</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic</th>\n",
       "      <th>severity</th>\n",
       "      <th>panic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006_2024-11-04</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10006_2024-11-05</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.47</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>15.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PXPN_10006_2024-11-06</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.07</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.68</td>\n",
       "      <td>7.38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                entry_id dataset          ID       date  PHQ_9  STAI_X2   CSM  \\\n",
       "0  PXPN_10006_2024-11-04    PXPN  PXPN_10006 2024-11-04    0.0     32.0  31.0   \n",
       "1  PXPN_10006_2024-11-05    PXPN  PXPN_10006 2024-11-05    0.0     32.0  31.0   \n",
       "2  PXPN_10006_2024-11-06    PXPN  PXPN_10006 2024-11-06    0.0     32.0  31.0   \n",
       "\n",
       "   CTQ_1  CTQ_2  CTQ_3  ...  SLT2  SLT3  SLT4  SLT5  SLT6  total_sleep  dbp  \\\n",
       "0   11.0   13.0   17.0  ...   NaN   NaN   NaN   NaN   NaN          NaN  NaN   \n",
       "1   11.0   13.0   17.0  ...  4.47  3.62  4.67  0.65  1.85        15.26  NaN   \n",
       "2   11.0   13.0   17.0  ...  0.00  0.20  4.07  1.43  1.68         7.38  1.0   \n",
       "\n",
       "   panic  severity  panic_label  \n",
       "0    0.0       NaN            0  \n",
       "1    0.0       NaN            0  \n",
       "2    1.0       NaN            0  \n",
       "\n",
       "[3 rows x 73 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Total entries in original:  29002\n",
      "    SYM entries: 28163\n",
      "    PXPN entries: 839\n",
      "Number of unique IDs in original: 429\n",
      "    SYM IDs:  400\n",
      "    PXPN IDs:  29\n",
      "Number of panic events (dbp=0): 811\n",
      "--------------------------------------------------------\n",
      "Total entries in filtered:  23828\n",
      "    SYM entries: 23014\n",
      "    PXPN entries: 814\n",
      "Number of unique IDs in filtered: 273\n",
      "    SYM IDs:  244\n",
      "    PXPN IDs:  29\n",
      "Number of panic events (dbp=0): 811\n"
     ]
    }
   ],
   "source": [
    "# save data_pre to CSV\n",
    "save_as_csv(data_pre, OUTPUT_PATH, f\"panic_pre_data_{version}({scraped_data_filename})\")\n",
    "\n",
    "display(data_pre.head(3))\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"Total entries in original: \", data_pre_init.shape[0])\n",
    "sym1_n = data_pre_init[data_pre_init['dataset'] == 'SYM1'].shape[0]\n",
    "sym2_n = data_pre_init[data_pre_init['dataset'] == 'SYM2'].shape[0]\n",
    "print(\"    SYM entries:\", sym1_n+sym2_n)\n",
    "print(\"    PXPN entries:\", data_pre_init[data_pre_init['dataset'] == 'PXPN'].shape[0])\n",
    "print(\"Number of unique IDs in original:\", len(data_pre_init['ID'].unique()))\n",
    "# find the unique IDs for SYM1 and SYM2\n",
    "sym1_ids = data_pre_init[data_pre_init['dataset'] == 'SYM1']['ID'].unique()\n",
    "sym2_ids = data_pre_init[data_pre_init['dataset'] == 'SYM2']['ID'].unique()\n",
    "print(\"    SYM IDs: \", len(sym1_ids)+len(sym2_ids))\n",
    "print(\"    PXPN IDs: \", len(data_pre_init[data_pre_init['dataset'] == 'PXPN']['ID'].unique()))\n",
    "print(\"Number of panic events (dbp=0):\", data_pre_init[data_pre_init['dbp'] == 0].shape[0])\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"Total entries in filtered: \", data_pre.shape[0])\n",
    "sym1_n = data_pre[data_pre['dataset'] == 'SYM1'].shape[0]\n",
    "sym2_n = data_pre[data_pre['dataset'] == 'SYM2'].shape[0]\n",
    "print(\"    SYM entries:\", sym1_n+sym2_n)\n",
    "print(\"    PXPN entries:\", data_pre[data_pre['dataset'] == 'PXPN'].shape[0])\n",
    "print(\"Number of unique IDs in filtered:\", len(data_pre['ID'].unique()))\n",
    "# find the unique IDs for SYM1 and SYM2\n",
    "sym1_ids = data_pre[data_pre['dataset'] == 'SYM1']['ID'].unique()\n",
    "sym2_ids = data_pre[data_pre['dataset'] == 'SYM2']['ID'].unique()\n",
    "print(\"    SYM IDs: \", len(sym1_ids)+len(sym2_ids))\n",
    "print(\"    PXPN IDs: \", len(data_pre[data_pre['dataset'] == 'PXPN']['ID'].unique()))\n",
    "print(\"Number of panic events (dbp=0):\", data_pre[data_pre['dbp'] == 0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7e6270",
   "metadata": {},
   "source": [
    "# üìñ | Metadata\n",
    "\n",
    "**Description**\n",
    "- `entry_id`: ID for each entry `'ID'_'date'`\n",
    "- `ID`: ID for each patient\n",
    "- `date`: logging date of each entry\n",
    "- `dataset`: source of entry (`SYM1`, `SYM2`, `PXPN`)\n",
    "- `dailylog_data`: whether daily log data exists in the entry (`boolean`)\n",
    "- `lifelog_data`: whether life log data exists in the entry (`boolean`)\n",
    "- `questionnaire_data`: whether questionnaire data exists in the entry (`boolean`)\n",
    "- `dtype_n`: how many of the 3 `state` groups exists in the entry (`int`)\n",
    "- `diary_data`: whether panic diary data exists in the entry (`boolean`)\n",
    "- `dbp`: number of consecutive days prior to panic. i.e. panic day = 0; 1 day prior = 1; etc. (up to 3)\n",
    "- `n_prior_data`: number of existing consecutive prior (days) entries\n",
    "- `ref_event_id`: the `entry_id` to which days before panic (`dbp`) is referencing\n",
    "- `valid_entry_3`: whether the entry has 3 consecutive days of prior data (`n_prior_data`)\n",
    "- `valid_entry_2`: whether the entry has 2 consecutive days of prior data (`n_prior_data`)\n",
    "- `valid_entry_1`: whether the entry has 1 consecutive days of prior data (`n_prior_data`)\n",
    "- `panic_label`: whether a panic occured in the entry (`boolean`)\n",
    "- `severity`: severity of the panic (1 ~ 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277e7f97",
   "metadata": {},
   "source": [
    "## Calculate Days Before Panic (``dbp``) and Prior Consecutive Days (``n_prior_data``)\n",
    "\n",
    "- calculate the consecutive 'days before panic' (`dbp`):\n",
    "  - day when panic occured -> `dbp` = 0\n",
    "  - 1 day before panic -> `dbp` = 1\n",
    "  - 2 day before panic -> `dbp` = 2\n",
    "  - 3 day before panic -> `dbp` = 3 (etc)\n",
    "  - stop calculating at a set limit (`delta_days`) or if a panic occurred within the limit\n",
    "- calculate the number of existing prior consecutive (days) entries (`n_prior_data`) (Default: 3)\n",
    "  - stop calculating at a certain limit (`lookback_limit`) (Default: 7)\n",
    "\n",
    "> May take ~ 1 to 2 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f133fed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 100.00% complete\r"
     ]
    }
   ],
   "source": [
    "from cys.utils import process_calculate_days_before_panic\n",
    "\n",
    "metadata_calc = create_empty_df()\n",
    "metadata_calc = metadata_int.copy()\n",
    "\n",
    "metadata_calc['n_prior_data']    = None\n",
    "metadata_calc['ref_event_id']    = None\n",
    "move_column(metadata_calc, 'panic_label', -1)\n",
    "move_column(metadata_calc, 'severity', -1)\n",
    "metadata_calc.sort_values(by=['ID', 'date'], ascending=False, inplace=True)\n",
    "\n",
    "d_days = 3\n",
    "l_back_lim = 7\n",
    "\n",
    "metadata_int = process_calculate_days_before_panic(metadata_calc, delta_days=d_days, lookback_limit=l_back_lim)\n",
    "\n",
    "# update features_dict with metadata columns\n",
    "if 'ref_event_id' not in features_dict['metadata']:\n",
    "\tfeatures_dict['metadata'].append('ref_event_id')\n",
    "if 'n_prior_data' not in features_dict['metadata']:\n",
    "\tfeatures_dict['metadata'].append('n_prior_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6da162d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "      <th>dtype_n</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic</th>\n",
       "      <th>n_prior_data</th>\n",
       "      <th>ref_event_id</th>\n",
       "      <th>panic_label</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27164</th>\n",
       "      <td>SYM2-1-422_2022-05-24</td>\n",
       "      <td>SYM2-1-422</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27163</th>\n",
       "      <td>SYM2-1-422_2022-05-23</td>\n",
       "      <td>SYM2-1-422</td>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27162</th>\n",
       "      <td>SYM2-1-422_2022-05-22</td>\n",
       "      <td>SYM2-1-422</td>\n",
       "      <td>2022-05-22</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27161</th>\n",
       "      <td>SYM2-1-422_2022-05-21</td>\n",
       "      <td>SYM2-1-422</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27160</th>\n",
       "      <td>SYM2-1-422_2022-05-20</td>\n",
       "      <td>SYM2-1-422</td>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    entry_id          ID       date dataset  dailylog_data  \\\n",
       "27164  SYM2-1-422_2022-05-24  SYM2-1-422 2022-05-24    SYM2              0   \n",
       "27163  SYM2-1-422_2022-05-23  SYM2-1-422 2022-05-23    SYM2              1   \n",
       "27162  SYM2-1-422_2022-05-22  SYM2-1-422 2022-05-22    SYM2              1   \n",
       "27161  SYM2-1-422_2022-05-21  SYM2-1-422 2022-05-21    SYM2              1   \n",
       "27160  SYM2-1-422_2022-05-20  SYM2-1-422 2022-05-20    SYM2              1   \n",
       "\n",
       "       lifelog_data  questionnaire_data  dtype_n  dbp  panic  n_prior_data  \\\n",
       "27164             1                   0        1  NaN    0.0             4   \n",
       "27163             1                   0        2  NaN    0.0             3   \n",
       "27162             1                   0        2  NaN    0.0             2   \n",
       "27161             1                   0        2  NaN    0.0             1   \n",
       "27160             1                   0        2  NaN    0.0             0   \n",
       "\n",
       "      ref_event_id  panic_label  severity  \n",
       "27164         None            0       NaN  \n",
       "27163         None            0       NaN  \n",
       "27162         None            0       NaN  \n",
       "27161         None            0       NaN  \n",
       "27160         None            0       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_id = 'SYM2-1-422'\n",
    "disp_df = metadata_int[metadata_int['ID'] == p_id]\n",
    "display(disp_df.head(5))\n",
    "del disp_df, p_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded18a26",
   "metadata": {},
   "source": [
    "## Find Valid Entries\n",
    "- add `valid_entry_3`: whether the entry has 3 consecutive days of prior data (`n_prior_data`)\n",
    "- add `valid_entry_2`: whether the entry has 2 consecutive days of prior data (`n_prior_data`)\n",
    "- add `valid_entry_1`: whether the entry has 1 consecutive days of prior data (`n_prior_data`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3cb3f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "      <th>dtype_n</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic</th>\n",
       "      <th>n_prior_data</th>\n",
       "      <th>valid_entry_3</th>\n",
       "      <th>valid_entry_2</th>\n",
       "      <th>valid_entry_1</th>\n",
       "      <th>ref_event_id</th>\n",
       "      <th>panic_label</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29001</th>\n",
       "      <td>SYM2-1-96_2021-08-04</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29000</th>\n",
       "      <td>SYM2-1-96_2021-08-03</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28999</th>\n",
       "      <td>SYM2-1-96_2021-08-02</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-02</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28996</th>\n",
       "      <td>SYM2-1-96_2021-07-30</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-30</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28995</th>\n",
       "      <td>SYM2-1-96_2021-07-29</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-29</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   entry_id         ID       date dataset  dailylog_data  \\\n",
       "29001  SYM2-1-96_2021-08-04  SYM2-1-96 2021-08-04    SYM2              0   \n",
       "29000  SYM2-1-96_2021-08-03  SYM2-1-96 2021-08-03    SYM2              0   \n",
       "28999  SYM2-1-96_2021-08-02  SYM2-1-96 2021-08-02    SYM2              0   \n",
       "28996  SYM2-1-96_2021-07-30  SYM2-1-96 2021-07-30    SYM2              0   \n",
       "28995  SYM2-1-96_2021-07-29  SYM2-1-96 2021-07-29    SYM2              0   \n",
       "\n",
       "       lifelog_data  questionnaire_data  dtype_n  dbp  panic  n_prior_data  \\\n",
       "29001             1                   0        1  NaN    0.0             2   \n",
       "29000             1                   0        1  NaN    0.0             1   \n",
       "28999             1                   0        1  NaN    0.0             0   \n",
       "28996             1                   0        1  NaN    0.0             2   \n",
       "28995             1                   0        1  NaN    0.0             1   \n",
       "\n",
       "       valid_entry_3  valid_entry_2  valid_entry_1 ref_event_id  panic_label  \\\n",
       "29001              0              1              1         None            0   \n",
       "29000              0              0              1         None            0   \n",
       "28999              0              0              0         None            0   \n",
       "28996              0              1              1         None            0   \n",
       "28995              0              0              1         None            0   \n",
       "\n",
       "       severity  \n",
       "29001       NaN  \n",
       "29000       NaN  \n",
       "28999       NaN  \n",
       "28996       NaN  \n",
       "28995       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata_int['valid_entry_3'] = metadata_int.apply(\n",
    "\tlambda row: 1 if row['n_prior_data'] >= 3 else 0,\n",
    "\taxis=1\n",
    ")\n",
    "metadata_int['valid_entry_2'] = metadata_int.apply(\n",
    "\tlambda row: 1 if row['n_prior_data'] >= 2 else 0,\n",
    "\taxis=1\n",
    ")\n",
    "metadata_int['valid_entry_1'] = metadata_int.apply(\n",
    "\tlambda row: 1 if row['n_prior_data'] >= 1 else 0,\n",
    "\taxis=1\n",
    ")\n",
    "move_column(metadata_int, 'ref_event_id', -1)\n",
    "move_column(metadata_int, 'panic_label', -1)\n",
    "move_column(metadata_int, 'severity', -1)\n",
    "display(metadata_int.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "262ff9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for panic labeling consistency\n",
    "# Panic events should have dbp = 0, panic = 2\n",
    "test_panic_dbpnot0 = metadata_int[(metadata_int['panic'] == 2) & (metadata_int['dbp'] != 0)]['entry_id'].unique()\n",
    "test_panic_dbp1 = metadata_int[(metadata_int['panic'] == 1) & (metadata_int['dbp'] != 1)]['entry_id'].unique()\n",
    "if len(test_panic_dbpnot0) != 0:\n",
    "\traise ValueError(\"Entries found with dbp != 0 for panic events. Please check the data.\")\n",
    "if len(test_panic_dbp1) != 0:\n",
    "\traise ValueError(\"Entries found with dbp != 1 for panic = 1. Please check the data.\")\n",
    "del test_panic_dbpnot0, test_panic_dbp1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dea337",
   "metadata": {},
   "source": [
    "## üíæ | Save Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f69eeb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - (text_utils.py) save_as_csv: Saved panic_metadata_2-0(final_result_20250620_360).csv to C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\cys\\_output\\final_result_20250620_360\\preprocessed\n",
      "DEBUG - (json_utils.py) save_dict_to_file: Dictionary saved successfully to C:\\Users\\cyshi\\OneDrive\\Documents\\GitHub\\Panic-Project-CYS\\cys\\_output\\panic_features_dict.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "      <th>dtype_n</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic</th>\n",
       "      <th>n_prior_data</th>\n",
       "      <th>valid_entry_3</th>\n",
       "      <th>valid_entry_2</th>\n",
       "      <th>valid_entry_1</th>\n",
       "      <th>ref_event_id</th>\n",
       "      <th>panic_label</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29001</th>\n",
       "      <td>SYM2-1-96_2021-08-04</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29000</th>\n",
       "      <td>SYM2-1-96_2021-08-03</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28999</th>\n",
       "      <td>SYM2-1-96_2021-08-02</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-02</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28996</th>\n",
       "      <td>SYM2-1-96_2021-07-30</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-30</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28995</th>\n",
       "      <td>SYM2-1-96_2021-07-29</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-29</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28994</th>\n",
       "      <td>SYM2-1-96_2021-07-28</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-28</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28988</th>\n",
       "      <td>SYM2-1-96_2021-07-22</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-22</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28987</th>\n",
       "      <td>SYM2-1-96_2021-07-21</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-21</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28975</th>\n",
       "      <td>SYM2-1-96_2021-07-09</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-09</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28974</th>\n",
       "      <td>SYM2-1-96_2021-07-08</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-07-08</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   entry_id         ID       date dataset  dailylog_data  \\\n",
       "29001  SYM2-1-96_2021-08-04  SYM2-1-96 2021-08-04    SYM2              0   \n",
       "29000  SYM2-1-96_2021-08-03  SYM2-1-96 2021-08-03    SYM2              0   \n",
       "28999  SYM2-1-96_2021-08-02  SYM2-1-96 2021-08-02    SYM2              0   \n",
       "28996  SYM2-1-96_2021-07-30  SYM2-1-96 2021-07-30    SYM2              0   \n",
       "28995  SYM2-1-96_2021-07-29  SYM2-1-96 2021-07-29    SYM2              0   \n",
       "28994  SYM2-1-96_2021-07-28  SYM2-1-96 2021-07-28    SYM2              0   \n",
       "28988  SYM2-1-96_2021-07-22  SYM2-1-96 2021-07-22    SYM2              0   \n",
       "28987  SYM2-1-96_2021-07-21  SYM2-1-96 2021-07-21    SYM2              0   \n",
       "28975  SYM2-1-96_2021-07-09  SYM2-1-96 2021-07-09    SYM2              0   \n",
       "28974  SYM2-1-96_2021-07-08  SYM2-1-96 2021-07-08    SYM2              0   \n",
       "\n",
       "       lifelog_data  questionnaire_data  dtype_n  dbp  panic  n_prior_data  \\\n",
       "29001             1                   0        1  NaN    0.0             2   \n",
       "29000             1                   0        1  NaN    0.0             1   \n",
       "28999             1                   0        1  NaN    0.0             0   \n",
       "28996             1                   0        1  NaN    0.0             2   \n",
       "28995             1                   0        1  NaN    0.0             1   \n",
       "28994             1                   0        1  NaN    0.0             0   \n",
       "28988             1                   0        1  NaN    0.0             1   \n",
       "28987             1                   0        1  NaN    0.0             0   \n",
       "28975             1                   0        1  NaN    0.0             5   \n",
       "28974             1                   0        1  NaN    0.0             4   \n",
       "\n",
       "       valid_entry_3  valid_entry_2  valid_entry_1 ref_event_id  panic_label  \\\n",
       "29001              0              1              1         None            0   \n",
       "29000              0              0              1         None            0   \n",
       "28999              0              0              0         None            0   \n",
       "28996              0              1              1         None            0   \n",
       "28995              0              0              1         None            0   \n",
       "28994              0              0              0         None            0   \n",
       "28988              0              0              1         None            0   \n",
       "28987              0              0              0         None            0   \n",
       "28975              1              1              1         None            0   \n",
       "28974              1              1              1         None            0   \n",
       "\n",
       "       severity  \n",
       "29001       NaN  \n",
       "29000       NaN  \n",
       "28999       NaN  \n",
       "28996       NaN  \n",
       "28995       NaN  \n",
       "28994       NaN  \n",
       "28988       NaN  \n",
       "28987       NaN  \n",
       "28975       NaN  \n",
       "28974       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata = create_empty_df()\n",
    "metadata = metadata_int.copy()\n",
    "save_as_csv(metadata, OUTPUT_PATH, f\"panic_metadata_{version}({scraped_data_filename})\")\n",
    "save_dict_to_file(features_dict, OUT_PATH, \"panic_features_dict\")\n",
    "\n",
    "display(metadata.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef5553a",
   "metadata": {},
   "source": [
    "# üîç | Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d41478",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c518179e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped Unique IDs: 429 -> 273 after preprocessing. discarded 156 IDs.\n",
      "Scraped Entries: 29002 -> 23828 after preprocessing. discarded 5174 entries.\n",
      "    Unnaccounted entry removal: 5018 entries removed\n",
      "Scraped Panic Events: 811 -> 811 after preprocessing. discarded 0 panic events.\n"
     ]
    }
   ],
   "source": [
    "scraped_unique_ids = scraped_data['ID'].unique()\n",
    "data_pre_unique_ids = data_pre['ID'].unique()\n",
    "print(f\"Scraped Unique IDs: {len(scraped_unique_ids)} -> {len(data_pre_unique_ids)} after preprocessing. discarded {len(scraped_unique_ids) - len(data_pre_unique_ids)} IDs.\")\n",
    "scraped_data_n = len(scraped_data)\n",
    "data_pre_entry_ids = data_pre['entry_id'].unique()\n",
    "print(f\"Scraped Entries: {scraped_data_n} -> {len(data_pre_entry_ids)} after preprocessing. discarded {scraped_data_n - len(data_pre_entry_ids)} entries.\")\n",
    "print(f\"    Unnaccounted entry removal: {scraped_data_n - len(data_pre_entry_ids) - (len(scraped_unique_ids) - len(data_pre_unique_ids))} entries removed\")\n",
    "scraped_panic_events = scraped_data[scraped_data['panic'] == 2].shape[0]\n",
    "data_pre_panic_events = data_pre[data_pre['panic'] == 2].shape[0]\n",
    "data_pre_dbp_panic_events = data_pre[data_pre['dbp'] == 0].shape[0]\n",
    "data_pre_label_panic_events = data_pre[data_pre['panic_label'] == 1].shape[0]\n",
    "if data_pre_dbp_panic_events != data_pre_panic_events:\n",
    "\traise ValueError(\"Mismatch in panic events count: dbp panic events and panic events do not match.\")\n",
    "if data_pre_label_panic_events != data_pre_panic_events:\n",
    "\traise ValueError(\"Mismatch in panic events count: label panic events and panic events do not match.\")\n",
    "print(f\"Scraped Panic Events: {scraped_panic_events} -> {data_pre_panic_events} after preprocessing. discarded {scraped_panic_events - data_pre_panic_events} panic events.\")\n",
    "\n",
    "if save_unnaccounted_data:\n",
    "    logging.info(\"Saving unaccounted data...\")\n",
    "    # find the entry_ids in scraped_data that are not in pre_data\n",
    "    missing_entry_ids = set(data_pre_init['entry_id']) - set(data_pre['entry_id'])\n",
    "    if len(missing_entry_ids) != 0:\n",
    "        print(f\"Missing entry IDs: {len(missing_entry_ids)}\")\n",
    "        unnaccounted_data = data_pre_init[data_pre_init['entry_id'].isin(missing_entry_ids)]\n",
    "        save_as_csv(unnaccounted_data, TMP_PATH, f\"unnaccounted_data_{scraped_data_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adb68775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of daily log entries: 14854 / 23828 (62.34%)\n",
      "Total number of life log entries: 12408 / 23828 (52.07%)\n",
      "Total number of questionnaire entries: 17978 / 23828 (75.45%)\n"
     ]
    }
   ],
   "source": [
    "data_pre_entry_ids = data_pre['entry_id'].unique()\n",
    "print(f\"Total number of daily log entries: {metadata[metadata['dailylog_data'] == 1].shape[0]} / {len(data_pre_entry_ids)} ({metadata[metadata['dailylog_data'] == 1].shape[0] / len(data_pre_entry_ids) * 100:.2f}%)\")\n",
    "print(f\"Total number of life log entries: {metadata[metadata['lifelog_data'] == 1].shape[0]} / {len(data_pre_entry_ids)} ({metadata[metadata['lifelog_data'] == 1].shape[0] / len(data_pre_entry_ids) * 100:.2f}%)\")\n",
    "print(f\"Total number of questionnaire entries: {metadata[metadata['questionnaire_data'] == 1].shape[0]} / {len(data_pre_entry_ids)} ({metadata[metadata['questionnaire_data'] == 1].shape[0] / len(data_pre_entry_ids) * 100:.2f}%)\")\n",
    "# print(f\"Total number of panic diary entries: {metadata[metadata['diary_data'] == 1].shape[0]} / {len(data_pre_entry_ids)} ({metadata[metadata['diary_data'] == 1].shape[0] / len(data_pre_entry_ids) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77ec40eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of patients with panic events: 105\n"
     ]
    }
   ],
   "source": [
    "panic_patients = metadata[metadata['panic_label'] == 1]['ID'].unique()\n",
    "print(f\"Total number of patients with panic events: {len(panic_patients)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28531a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of entries with dbp = 1 (panic = 1): 502 / 23828 (2.11%)\n",
      "Total number of entries with dbp = 2: 384 / 23828 (1.61%)\n",
      "Total number of entries with dbp = 3: 326 / 23828 (1.37%)\n",
      "Total number of entries with panic = 0: 22515 / 23828 (94.49%)\n"
     ]
    }
   ],
   "source": [
    "panic_1_entries = metadata[metadata['panic'] == 1].shape[0]\n",
    "dbp_1_entries = metadata[metadata['dbp'] == 1].shape[0]\n",
    "if panic_1_entries != dbp_1_entries:\n",
    "\traise ValueError(\"Mismatch in panic entries count: panic entries and dbp entries do not match.\")\n",
    "if len(metadata) != len(data_pre):\n",
    "    raise ValueError(\"Error\")\n",
    "print(f\"Total number of entries with dbp = 1 (panic = 1): {panic_1_entries} / {len(data_pre_entry_ids)} ({panic_1_entries / len(data_pre_entry_ids) * 100:.2f}%)\")\n",
    "dbp_2_entries = metadata[metadata['dbp'] == 2].shape[0]\n",
    "print(f\"Total number of entries with dbp = 2: {dbp_2_entries} / {len(data_pre_entry_ids)} ({dbp_2_entries / len(data_pre_entry_ids) * 100:.2f}%)\")\n",
    "dbp_3_entries = metadata[metadata['dbp'] == 3].shape[0]\n",
    "print(f\"Total number of entries with dbp = 3: {dbp_3_entries} / {len(data_pre_entry_ids)} ({dbp_3_entries / len(data_pre_entry_ids) * 100:.2f}%)\")\n",
    "panic_0_entries = metadata[metadata['panic'] == 0].shape[0]\n",
    "print(f\"Total number of entries with panic = 0: {panic_0_entries} / {len(data_pre_entry_ids)} ({panic_0_entries / len(data_pre_entry_ids) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842e58bd",
   "metadata": {},
   "source": [
    "## Data Displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf6ff081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped data shape: (29002, 77)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>panic</th>\n",
       "      <th>gender</th>\n",
       "      <th>PHQ_9</th>\n",
       "      <th>STAI_X2</th>\n",
       "      <th>CSM</th>\n",
       "      <th>CTQ_1</th>\n",
       "      <th>CTQ_2</th>\n",
       "      <th>CTQ_3</th>\n",
       "      <th>...</th>\n",
       "      <th>HR_mean</th>\n",
       "      <th>HR_hvar_mean</th>\n",
       "      <th>SLT1</th>\n",
       "      <th>SLT2</th>\n",
       "      <th>SLT3</th>\n",
       "      <th>SLT4</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.33</td>\n",
       "      <td>123.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.81</td>\n",
       "      <td>29.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>15.26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID       date  panic  gender  PHQ_9  STAI_X2   CSM  CTQ_1  CTQ_2  \\\n",
       "0  PXPN_10006 2024-11-04    0.0       0    0.0     32.0  31.0   11.0   13.0   \n",
       "1  PXPN_10006 2024-11-05    0.0       0    0.0     32.0  31.0   11.0   13.0   \n",
       "\n",
       "   CTQ_3  ...  HR_mean  HR_hvar_mean  SLT1  SLT2  SLT3  SLT4  SLT5  SLT6  \\\n",
       "0   17.0  ...    74.33        123.22   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1   17.0  ...    54.81         29.40   0.0  4.47  3.62  4.67  0.65  1.85   \n",
       "\n",
       "   total_sleep  severity  \n",
       "0          NaN       NaN  \n",
       "1        15.26       NaN  \n",
       "\n",
       "[2 rows x 77 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessed shape: (23828, 73)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>PHQ_9</th>\n",
       "      <th>STAI_X2</th>\n",
       "      <th>CSM</th>\n",
       "      <th>CTQ_1</th>\n",
       "      <th>CTQ_2</th>\n",
       "      <th>CTQ_3</th>\n",
       "      <th>...</th>\n",
       "      <th>SLT2</th>\n",
       "      <th>SLT3</th>\n",
       "      <th>SLT4</th>\n",
       "      <th>SLT5</th>\n",
       "      <th>SLT6</th>\n",
       "      <th>total_sleep</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic</th>\n",
       "      <th>severity</th>\n",
       "      <th>panic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006_2024-11-04</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10006_2024-11-05</td>\n",
       "      <td>PXPN</td>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.47</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>15.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                entry_id dataset          ID       date  PHQ_9  STAI_X2   CSM  \\\n",
       "0  PXPN_10006_2024-11-04    PXPN  PXPN_10006 2024-11-04    0.0     32.0  31.0   \n",
       "1  PXPN_10006_2024-11-05    PXPN  PXPN_10006 2024-11-05    0.0     32.0  31.0   \n",
       "\n",
       "   CTQ_1  CTQ_2  CTQ_3  ...  SLT2  SLT3  SLT4  SLT5  SLT6  total_sleep  dbp  \\\n",
       "0   11.0   13.0   17.0  ...   NaN   NaN   NaN   NaN   NaN          NaN  NaN   \n",
       "1   11.0   13.0   17.0  ...  4.47  3.62  4.67  0.65  1.85        15.26  NaN   \n",
       "\n",
       "   panic  severity  panic_label  \n",
       "0    0.0       NaN            0  \n",
       "1    0.0       NaN            0  \n",
       "\n",
       "[2 rows x 73 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata shape: (23828, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dailylog_data</th>\n",
       "      <th>lifelog_data</th>\n",
       "      <th>questionnaire_data</th>\n",
       "      <th>dtype_n</th>\n",
       "      <th>dbp</th>\n",
       "      <th>panic</th>\n",
       "      <th>n_prior_data</th>\n",
       "      <th>valid_entry_3</th>\n",
       "      <th>valid_entry_2</th>\n",
       "      <th>valid_entry_1</th>\n",
       "      <th>ref_event_id</th>\n",
       "      <th>panic_label</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29001</th>\n",
       "      <td>SYM2-1-96_2021-08-04</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29000</th>\n",
       "      <td>SYM2-1-96_2021-08-03</td>\n",
       "      <td>SYM2-1-96</td>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>SYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   entry_id         ID       date dataset  dailylog_data  \\\n",
       "29001  SYM2-1-96_2021-08-04  SYM2-1-96 2021-08-04    SYM2              0   \n",
       "29000  SYM2-1-96_2021-08-03  SYM2-1-96 2021-08-03    SYM2              0   \n",
       "\n",
       "       lifelog_data  questionnaire_data  dtype_n  dbp  panic  n_prior_data  \\\n",
       "29001             1                   0        1  NaN    0.0             2   \n",
       "29000             1                   0        1  NaN    0.0             1   \n",
       "\n",
       "       valid_entry_3  valid_entry_2  valid_entry_1 ref_event_id  panic_label  \\\n",
       "29001              0              1              1         None            0   \n",
       "29000              0              0              1         None            0   \n",
       "\n",
       "       severity  \n",
       "29001       NaN  \n",
       "29000       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Scraped data shape:\", scraped_data.shape)\n",
    "display(scraped_data.head(2))\n",
    "print(\"Data preprocessed shape:\", data_pre.shape)\n",
    "display(data_pre.head(2))\n",
    "print(\"Metadata shape:\", metadata.shape)\n",
    "display(metadata.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab214fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dhlab-panic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
