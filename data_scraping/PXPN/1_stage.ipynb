{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required Packages:\n",
    "- pandas  : 1.5.3\n",
    "- openpyxl: 3.1.5\n",
    "- xlrd    : 2.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📚 | Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config as cfg\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import xlrd\n",
    "import os\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "\n",
    "from library.path_utils import get_file_path\n",
    "\n",
    "print(\"pandas  :\", pd.__version__)\n",
    "print(\"openpyxl:\", openpyxl.__version__)\n",
    "print(\"xlrd    :\", xlrd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⚙️ | Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_PXPN_DIR = \"./raw_data/PXPN\"\n",
    "\n",
    "# 엑셀 파일 경로 (실제 경로로 수정)\n",
    "enroll_file_name = \"1. 픽셀패닉 enroll 정보_250516\"\n",
    "\n",
    "zip_file_name = \"pixelpanic_raw_data.zip\"\n",
    "output_folder_name = \"./_tmp/PXPN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enroll_path = get_file_path(RAW_PXPN_DIR, f\"{enroll_file_name}.xlsx\")\n",
    "zip_path = get_file_path(RAW_PXPN_DIR, f\"{zip_file_name}\")\n",
    "output_folder = get_file_path(output_folder_name)\n",
    "csv_path = get_file_path(RAW_PXPN_DIR, f\"{enroll_file_name}.csv\")\n",
    "\n",
    "# 엑셀 읽고 csv로 저장\n",
    "df = pd.read_excel(enroll_path)\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "enroll_path = get_file_path(RAW_PXPN_DIR, f\"{enroll_file_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설문 리스트\n",
    "top_5 = [\n",
    "    '특성 불안 설문', '한국형 회복탄력성 지수', '한국어판 아침형-저녁형 설문지',\n",
    "    '한글판 생물학적 리듬 평가 설문지', '유년기 외상 척도', '한국형 기분장애 설문지',\n",
    "    '광장공포 인지 설문지', '알바니 공황-공포 질문지', '신체감각 설문지',\n",
    "    '한글판 범불안 장애', '한국어판 우울증 선별도구'\n",
    "]\n",
    "\n",
    "# 결과 DataFrame 초기화: patient_code, date 컬럼 확보\n",
    "result = pd.DataFrame(columns=['patient_code', '날짜'])\n",
    "\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as outer_zip:\n",
    "    for i in range(6, 41):\n",
    "        formatted_index = f'{i:02d}'\n",
    "        patient_code = f'PXPN_100{formatted_index}'\n",
    "\n",
    "        # 내부 zip 파일 경로\n",
    "        inner_zip_name = f'ActiveData/{patient_code}_ActiveData.zip'\n",
    "        if inner_zip_name not in outer_zip.namelist():\n",
    "            continue\n",
    "\n",
    "        inner_zip_bytes = BytesIO(outer_zip.read(inner_zip_name))\n",
    "        with zipfile.ZipFile(inner_zip_bytes, 'r') as inner_zip:\n",
    "            inner_file_name = f'{patient_code}_SurveyResponse.csv'\n",
    "            if inner_file_name not in inner_zip.namelist():\n",
    "                continue\n",
    "\n",
    "            with inner_zip.open(inner_file_name) as f:\n",
    "                df = pd.read_csv(f)\n",
    "\n",
    "                # 작성일 컬럼에서 날짜만 추출\n",
    "                date_value = pd.to_datetime(df['작성일'].iloc[0]).date()\n",
    "\n",
    "                # 새로운 환자-작성일 행 추가\n",
    "                if not ((result['patient_code'] == patient_code) & (result['날짜'] == date_value)).any():\n",
    "                    new_row = pd.DataFrame({\n",
    "                        'patient_code': [patient_code],\n",
    "                        '날짜': [date_value]\n",
    "                    })\n",
    "                    result = pd.concat([result, new_row], ignore_index=True)\n",
    "\n",
    "                # 점수 처리\n",
    "                for j in top_5:\n",
    "                    sub_df = df[df['설문명'] == j].reset_index(drop=True)\n",
    "                    if sub_df.empty:\n",
    "                        continue\n",
    "\n",
    "                    # 역채점 점수가 있으면 사용\n",
    "                    scores = []\n",
    "                    for idx, row in sub_df.iterrows():\n",
    "                        if row['역채점인 경우 역채점 점수'] != '-':\n",
    "                            scores.append(float(row['역채점인 경우 역채점 점수']))\n",
    "                        else:\n",
    "                            val = row['점수']\n",
    "                            scores.append('***' if pd.isna(val) else float(val))\n",
    "\n",
    "                    # 컬럼명 생성 및 값 삽입\n",
    "                    if j == '특성 불안 설문':\n",
    "                        prefix = 'STAI_X2'\n",
    "                    elif j == '한국형 회복탄력성 지수':\n",
    "                        prefix = 'KRQ'\n",
    "                    elif j == '한국어판 아침형-저녁형 설문지':\n",
    "                        prefix = 'CSM'\n",
    "                    elif j == '한글판 생물학적 리듬 평가 설문지':\n",
    "                        prefix = 'BRIAN'\n",
    "                    elif j == '한국형 기분장애 설문지':\n",
    "                        prefix = 'MDQ'\n",
    "                    elif j == '광장공포 인지 설문지':\n",
    "                        prefix = 'ACQ'\n",
    "                    elif j == '신체감각 설문지':\n",
    "                        prefix = 'BSQ'\n",
    "                    elif j == '한글판 범불안 장애':\n",
    "                        prefix = 'GAD'\n",
    "                    elif j == '한국어판 우울증 선별도구':\n",
    "                        prefix = 'PHQ'\n",
    "\n",
    "                    # 주제별 분리 처리 필요 설문\n",
    "                    if j in ['유년기 외상 척도', '알바니 공황-공포 질문지']:\n",
    "                        grouped = sub_df.copy()\n",
    "                        grouped['real_score'] = scores\n",
    "                        topic_order = {t: i+1 for i, t in enumerate(sorted(grouped['주제'].unique()))}\n",
    "                        for topic, order in topic_order.items():\n",
    "                            topic_df = grouped[grouped['주제'] == topic].reset_index(drop=True)\n",
    "                            for qnum, sc in enumerate(topic_df['real_score'], start=1):\n",
    "                                col_name = f\"{('CTQ' if j=='유년기 외상 척도' else 'APPQ')}-{order}-{qnum}\"\n",
    "                                result.loc[\n",
    "                                    (result['patient_code'] == patient_code) &\n",
    "                                    (result['날짜'] == date_value),\n",
    "                                    col_name\n",
    "                                ] = sc\n",
    "                    else:\n",
    "                        for idx, sc in enumerate(scores, start=1):\n",
    "                            col_name = f\"{prefix}-{idx}\"\n",
    "                            result.loc[\n",
    "                                (result['patient_code'] == patient_code) &\n",
    "                                (result['날짜'] == date_value),\n",
    "                                col_name\n",
    "                            ] = sc\n",
    "\n",
    "# 컬럼 순서 재배열: patient_code, date, 나머지\n",
    "cols = ['patient_code', '날짜'] + [c for c in result.columns if c not in ['patient_code', '날짜']]\n",
    "result = result[cols]\n",
    "\n",
    "# 불필요 컬럼 삭제\n",
    "result = result.drop(columns=['MDQ-14', 'MDQ-15', 'PHQ-10'], errors='ignore')\n",
    "\n",
    "# 저장\n",
    "\n",
    "output_path = os.path.join(output_folder, \"questionnaire.csv\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "result.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 접두어 목록\n",
    "prefixes = [\"PHQ\", \"STAI_X2\", \"CSM\", \"CTQ-1\", \"CTQ-2\", \"CTQ-3\", \"CTQ-4\", \"CTQ-5\", \"KRQ\", \"MDQ\", \"ACQ\", \"APPQ-1\", \"APPQ-2\", \"APPQ-3\", \"BSQ\", \"GAD\", \"BRIAN\"]\n",
    "# 결과를 저장할 데이터프레임\n",
    "aggregated_df = result[['patient_code', '날짜']].copy()\n",
    "\n",
    "for prefix in prefixes:\n",
    "    # 해당 접두어로 시작하는 컬럼 찾기\n",
    "    matched_cols = [col for col in result.columns if col.startswith(prefix)]\n",
    "    \n",
    "    # 값 합산해서 새로운 컬럼으로 추가\n",
    "    aggregated_df[f'{prefix.rstrip(\"-\")}'] = result[matched_cols].apply(pd.to_numeric, errors='coerce').sum(axis=1)\n",
    "\n",
    "display(aggregated_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엑셀 파일 경로\n",
    "file_path = enroll_path\n",
    "\n",
    "# 엑셀 시트 읽기\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 컬럼 이름 변경\n",
    "df = df.rename(columns={'회원코드': 'patient_code', '2. 성별': 'gender'})\n",
    "\n",
    "# 필요한 컬럼만 선택\n",
    "df = df[['patient_code', '연구시작일', '연구종료일', 'gender']]\n",
    "\n",
    "# 날짜 형식으로 변환\n",
    "df['연구시작일'] = pd.to_datetime(df['연구시작일'], errors='coerce')\n",
    "df['연구종료일'] = pd.to_datetime(df['연구종료일'], errors='coerce')\n",
    "\n",
    "# 각 환자에 대해 날짜 생성\n",
    "expanded_rows = []\n",
    "for _, row in df.iterrows():\n",
    "    if pd.notnull(row['연구시작일']) and pd.notnull(row['연구종료일']):\n",
    "        date_range = pd.date_range(start=row['연구시작일'], end=row['연구종료일'])\n",
    "        for date in date_range:\n",
    "            expanded_rows.append({'patient_code': row['patient_code'], '날짜': date, 'gender': row['gender']})\n",
    "\n",
    "# 결과 데이터프레임 생성\n",
    "expanded_df = pd.DataFrame(expanded_rows)\n",
    "expanded_df = expanded_df.replace({'남': '0', '여': '1'})\n",
    "print(expanded_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엑셀 파일 경로\n",
    "file_path = enroll_path\n",
    "\n",
    "# CSV 읽기\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 컬럼 이름 변경 (생년월일 컬럼도 추가)\n",
    "df = df.rename(columns={\n",
    "    '회원코드': 'patient_code',\n",
    "    '2. 성별': 'gender'  # 생년월일 컬럼 이름이 실제 다르면 이 부분 수정 필요\n",
    "})\n",
    "\n",
    "# 필요한 컬럼만 선택\n",
    "df = df[['patient_code', '연구시작일', '연구종료일', 'gender', '3. 생년월일']]\n",
    "\n",
    "# 날짜 형식으로 변환\n",
    "df['연구시작일'] = pd.to_datetime(df['연구시작일'], errors='coerce')\n",
    "df['연구종료일'] = pd.to_datetime(df['연구종료일'], errors='coerce')\n",
    "df['3. 생년월일'] = pd.to_datetime(df['3. 생년월일'], errors='coerce')\n",
    "\n",
    "\n",
    "# 각 환자에 대해 날짜 생성\n",
    "expanded_rows = []\n",
    "for _, row in df.iterrows():\n",
    "    if pd.notnull(row['연구시작일']) and pd.notnull(row['연구종료일']):\n",
    "        date_range = pd.date_range(start=row['연구시작일'], end=row['연구종료일'])\n",
    "        for date in date_range:\n",
    "            expanded_rows.append({\n",
    "                'patient_code': row['patient_code'],\n",
    "                '날짜': date,\n",
    "                'gender': '0' if row['gender'] == '남' else '1'\n",
    "            })\n",
    "\n",
    "# 결과 데이터프레임 생성\n",
    "expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# 출력\n",
    "print(expanded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df['날짜']    = pd.to_datetime(expanded_df['날짜'])\n",
    "aggregated_df['날짜'] = pd.to_datetime(aggregated_df['날짜'])\n",
    "expanded_answer = pd.merge(expanded_df, aggregated_df, on=['patient_code', '날짜'], how='outer')\n",
    "expanded_answer = expanded_answer.rename(columns={'patient_code': 'ID', '날짜': 'date', 'GAD': 'GAD_7', 'CTQ-1': 'CTQ_1', 'CTQ-2': 'CTQ_2', 'CTQ-3': 'CTQ_3', 'CTQ-4': 'CTQ_4', 'CTQ-5': 'CTQ_5', 'APPQ-1': 'APPQ_1', 'APPQ-2': 'APPQ_2', 'APPQ-3': 'APPQ_3', 'PHQ': 'PHQ_9'})\n",
    "output_path = os.path.join(output_folder, \"questionnaire_test.csv\")\n",
    "expanded_answer.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. 날짜 형식 통일\n",
    "expanded_answer['date'] = pd.to_datetime(expanded_answer['date'])\n",
    "\n",
    "# 1. PXPN별 Panic 날짜 수집\n",
    "PXPN_panic_dates = pd.DataFrame(columns=['ID', 'date'])\n",
    "main_zip_path = zip_path  # 예: '/Users/.../ActiveData.zip'\n",
    "\n",
    "with zipfile.ZipFile(main_zip_path, 'r') as outer_zip:\n",
    "    for inner_name in outer_zip.namelist():\n",
    "        if inner_name.startswith(\"ActiveData/\") and inner_name.endswith('_ActiveData.zip'):\n",
    "            pid = os.path.basename(inner_name).replace('_ActiveData.zip', '')\n",
    "\n",
    "            with outer_zip.open(inner_name) as inner_file:\n",
    "                data = inner_file.read()\n",
    "                inner_bytes = BytesIO(data)\n",
    "\n",
    "                if not zipfile.is_zipfile(inner_bytes):\n",
    "                    print(f\"❌ 내부 zip 아님 (무시됨): {inner_name}\")\n",
    "                    continue\n",
    "\n",
    "                with zipfile.ZipFile(inner_bytes, 'r') as active_zip:\n",
    "                    panic_csvs = [f for f in active_zip.namelist() if f.endswith('Panic.csv')]\n",
    "                    if not panic_csvs:\n",
    "                        print(f\"⚠️ Panic.csv 없음: {inner_name}\")\n",
    "                        continue\n",
    "\n",
    "                    with active_zip.open(panic_csvs[0]) as f:\n",
    "                        df_panic = pd.read_csv(f)\n",
    "                        if '작성일' not in df_panic.columns:\n",
    "                            print(f\"⚠️ '작성일' 없음: {inner_name}\")\n",
    "                            continue\n",
    "\n",
    "                        for 작성일 in df_panic['작성일']:\n",
    "                            PXPN_panic_dates = pd.concat([\n",
    "                                PXPN_panic_dates,\n",
    "                                pd.DataFrame({'ID': [pid], 'date': [작성일]})\n",
    "                            ], ignore_index=True)\n",
    "\n",
    "# 2. 날짜 및 panic 정리\n",
    "PXPN_panic_dates['panic'] = 2\n",
    "PXPN_panic_dates['date'] = pd.to_datetime(PXPN_panic_dates['date']).dt.strftime('%Y-%m-%d')\n",
    "expanded_answer['date'] = pd.to_datetime(expanded_answer['date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# 3. outer merge\n",
    "merged = pd.merge(\n",
    "    PXPN_panic_dates,\n",
    "    expanded_answer,\n",
    "    on=['ID', 'date'],\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# 4. 우선순위 panic 값 유지\n",
    "merged = (\n",
    "    merged\n",
    "    .sort_values(['ID', 'date', 'panic'], ascending=[True, True, False])\n",
    "    .drop_duplicates(subset=['ID', 'date'], keep='first')\n",
    ")\n",
    "\n",
    "# 5. 전날 panic=1 적용\n",
    "df = merged.copy()\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "for _, row in df[df['panic'] == 2].iterrows():\n",
    "    pid = row['ID']\n",
    "    curr_date = row['date']\n",
    "    prev_date = curr_date - pd.Timedelta(days=1)\n",
    "\n",
    "    # 연속된 2 제거\n",
    "    while ((df['ID'] == pid) & (df['date'] == prev_date) & (df['panic'] == 2)).any():\n",
    "        prev_date -= pd.Timedelta(days=1)\n",
    "\n",
    "    mask = (df['ID'] == pid) & (df['date'] == prev_date)\n",
    "    if mask.any():\n",
    "        df.loc[mask & (df['panic'].fillna(0) < 1), 'panic'] = 1\n",
    "\n",
    "df = df.sort_values(['ID', 'date']).reset_index(drop=True)\n",
    "df['date'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "df['panic'] = df['panic'].fillna(0)\n",
    "\n",
    "# 6. Enroll 병합 (age)\n",
    "enroll_df = pd.read_csv(enroll_path, encoding='utf-8')\n",
    "enroll_df = enroll_df.rename(columns={\n",
    "    '회원코드': 'patient_code',\n",
    "    '3. 생년월일': 'birthdate',\n",
    "    '연구종료일': 'end_date'\n",
    "})\n",
    "enroll_df['birthdate'] = pd.to_datetime(enroll_df['birthdate'], errors='coerce')\n",
    "enroll_df['end_date'] = pd.to_datetime(enroll_df['end_date'], errors='coerce')\n",
    "enroll_df['age'] = enroll_df['end_date'].dt.year - enroll_df['birthdate'].dt.year\n",
    "\n",
    "age_df = enroll_df[['patient_code', 'age']].drop_duplicates().rename(columns={'patient_code': 'ID'})\n",
    "final_df = df.merge(age_df, on='ID', how='left')\n",
    "\n",
    "# 7. 저장\n",
    "output_path = os.path.join(output_folder, \"questionnaire_and_panic_date.csv\")\n",
    "final_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 경로\n",
    "csv_path = output_path\n",
    "zip_path = zip_path\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv(csv_path)\n",
    "df = df[df[\"ID\"].str.startswith(\"PXPN\")].copy()\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# 컬럼 초기화\n",
    "for col in ['marriage', 'job', 'alcohol', 'coffee', 'smoking', 'menstruation', 'exercise',\n",
    "            'smkHx', 'drinkHx', 'suicideHx',\n",
    "            'suicide_need']: \n",
    "    df[col] = np.nan\n",
    "\n",
    "# ZIP 열기\n",
    "with zipfile.ZipFile(zip_path, 'r') as outer_zip:\n",
    "    for pid in df['ID'].unique():\n",
    "        inner_zip_name = f\"ActiveData/{pid}_ActiveData.zip\"\n",
    "        if inner_zip_name not in outer_zip.namelist():\n",
    "            continue\n",
    "\n",
    "        # 내부 ZIP 열기\n",
    "        with outer_zip.open(inner_zip_name) as inner_zip_file:\n",
    "            inner_zip_bytes = BytesIO(inner_zip_file.read())\n",
    "            with zipfile.ZipFile(inner_zip_bytes) as inner_zip:\n",
    "\n",
    "                # 1. Sociodemographic 처리\n",
    "                soc_path = f\"{pid}_Sociodemographic.csv\"\n",
    "                if soc_path in inner_zip.namelist():\n",
    "                    soc = pd.read_csv(inner_zip.open(soc_path), header=None, index_col=0).T\n",
    "                    if '결혼' in soc.columns:\n",
    "                        df.loc[df['ID'] == pid, 'marriage'] = 1 if soc['결혼'].values[0] == '기혼' else 0\n",
    "                    if '현재 직업 유무' in soc.columns:\n",
    "                        df.loc[df['ID'] == pid, 'job'] = 1 if soc['현재 직업 유무'].values[0] == 'Y' else 0\n",
    "                    if '과거 흡연 여부' in soc.columns:\n",
    "                        df.loc[df['ID'] == pid, 'smkHx'] = 1 if soc['과거 흡연 여부'].values[0] == 'Y' else 0\n",
    "                    if '지금까지 음주 여부' in soc.columns:\n",
    "                        df.loc[df['ID'] == pid, 'drinkHx'] = 1 if soc['지금까지 음주 여부'].values[0] == 'Y' else 0\n",
    "                    if '과거 자살 시도 여부' in soc.columns:\n",
    "                        df.loc[df['ID'] == pid, 'suicideHx'] = 1 if soc['과거 자살 시도 여부'].values[0] == 'Y' else 0\n",
    "                    if '지난 1달간 자살시도 여부' in soc.columns:\n",
    "                        df.loc[df['ID'] == pid, 'suicide_need'] = 1 if soc['지난 1달간 자살시도 여부'].values[0] == 'Y' else 0\n",
    "\n",
    "\n",
    "                # 2. Pattern 처리\n",
    "                pat_path = f\"{pid}_Pattern.csv\"\n",
    "                if pat_path in inner_zip.namelist():\n",
    "                    pat = pd.read_csv(inner_zip.open(pat_path))\n",
    "                    pat['작성일'] = pd.to_datetime(pat['작성일'], errors='coerce')\n",
    "\n",
    "                    for idx, row in df[df[\"ID\"] == pid].iterrows():\n",
    "                        d = row[\"date\"]\n",
    "                        today_rows = pat[pat[\"작성일\"] == d]\n",
    "                        for _, r in today_rows.iterrows():\n",
    "                            t = r.get('종류', '')\n",
    "                            st = r.get('세부종류', '')\n",
    "                            amount = r.get('양', None)  # '양' 컬럼 값\n",
    "                            # 운동\n",
    "                            if t == '운동':\n",
    "                                # 양 값이 있으면 그 값을, 없으면 1 로 디폴트\n",
    "                                df.at[idx, 'exercise'] = amount if pd.notna(amount) else 1\n",
    "                            # 카페인\n",
    "                            if t == '카페인':\n",
    "                                df.at[idx, 'coffee'] = amount if pd.notna(amount) else 1\n",
    "                            # 흡연\n",
    "                            if t == '흡연':\n",
    "                                df.at[idx, 'smoking'] = amount if pd.notna(amount) else 1\n",
    "                            # 음주(양이 아닌 단순 여부만 원하면 기존처럼 1로)\n",
    "                            if t == '음주':\n",
    "                                df.at[idx, 'alcohol'] = amount if pd.notna(amount) else 1\n",
    "                            # 생리\n",
    "                            if t == '생리' and st == '생리중':\n",
    "                                df.at[idx, 'menstruation'] = 1\n",
    "\n",
    "output_path = os.path.join(output_folder, \"questionnaire_and_panic_dates_and_demo.csv\")\n",
    "df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 경로 설정\n",
    "zip_path = zip_path\n",
    "processed = df  \n",
    "\n",
    "# 3. PXPN ID 목록 추출\n",
    "pxpn_ids = processed[processed['ID'].astype(str).str.startswith('PXPN')]['ID'].unique()\n",
    "\n",
    "# 4. 감정 관련 컬럼 초기화\n",
    "emotion_cols = ['positive_feeling', 'negative', 'positive_E', 'negative_E', 'anxiety', 'annoying']\n",
    "for col in emotion_cols:\n",
    "    if col not in processed.columns:\n",
    "        processed[col] = np.nan\n",
    "\n",
    "# 5. 디버그용 카운터 및 정보\n",
    "match_count = 0\n",
    "no_date_match = 0\n",
    "processed_ids = set()\n",
    "debug_info = []\n",
    "\n",
    "# 6. 외부 zip 열기\n",
    "try:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as outer_zip:\n",
    "\n",
    "        # 7. 모든 PXPN ID에 대해 반복\n",
    "        for pid in pxpn_ids:\n",
    "            pid = str(pid).strip()\n",
    "            inner_zip_name = f\"ActiveData/{pid}_ActiveData.zip\"\n",
    "\n",
    "            if inner_zip_name not in outer_zip.namelist():\n",
    "                debug_info.append(f\"❌ ID {pid}: 내부 ZIP 없음 → {inner_zip_name}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                with outer_zip.open(inner_zip_name) as inner_zip_file:\n",
    "                    inner_zip_bytes = BytesIO(inner_zip_file.read())\n",
    "\n",
    "                    with zipfile.ZipFile(inner_zip_bytes) as inner_zip:\n",
    "                        checkup_filename = f\"{pid}_Checkup.csv\"\n",
    "\n",
    "                        if checkup_filename not in inner_zip.namelist():\n",
    "                            debug_info.append(f\"⚠️ ID {pid}: Checkup 파일 없음\")\n",
    "                            continue\n",
    "\n",
    "                        # Checkup CSV 읽기\n",
    "                        checkup = pd.read_csv(inner_zip.open(checkup_filename))\n",
    "\n",
    "                        # 날짜 타입 변환\n",
    "                        processed_pid = processed[processed['ID'] == pid].copy()\n",
    "                        processed_pid['date'] = pd.to_datetime(processed_pid['date'], errors='coerce')\n",
    "                        checkup['작성일'] = pd.to_datetime(checkup['작성일'], errors='coerce')\n",
    "\n",
    "                        # 감정 카테고리별 처리\n",
    "                        for category in ['기분', '에너지', '불안', '짜증']:\n",
    "                            category_data = checkup[checkup['종류'] == category]\n",
    "\n",
    "                            for _, row in category_data.iterrows():\n",
    "                                checkup_date = row['작성일']\n",
    "                                score = row['척도']\n",
    "\n",
    "                                for idx, proc_row in processed_pid.iterrows():\n",
    "                                    proc_date = proc_row['date']\n",
    "                                    if (\n",
    "                                        proc_date.year == checkup_date.year and\n",
    "                                        proc_date.month == checkup_date.month and\n",
    "                                        proc_date.day == checkup_date.day\n",
    "                                    ):\n",
    "                                        if category == '기분':\n",
    "                                            if score > 0:\n",
    "                                                processed.at[idx, 'positive_feeling'] = score\n",
    "                                            elif score < 0:\n",
    "                                                processed.at[idx, 'negative'] = score\n",
    "                                        elif category == '에너지':\n",
    "                                            if score > 0:\n",
    "                                                processed.at[idx, 'positive_E'] = score\n",
    "                                            elif score < 0:\n",
    "                                                processed.at[idx, 'negative_E'] = score\n",
    "                                        elif category == '불안':\n",
    "                                            processed.at[idx, 'anxiety'] = score\n",
    "                                        elif category == '짜증':\n",
    "                                            processed.at[idx, 'annoying'] = score\n",
    "\n",
    "                                        match_count += 1\n",
    "                                        processed_ids.add(pid)\n",
    "            except Exception as e:\n",
    "                debug_info.append(f\"❗ ID {pid} 처리 중 오류: {str(e)}\")\n",
    "except Exception as e:\n",
    "    debug_info.append(f\"ZIP 파일 처리 전체 실패: {str(e)}\")\n",
    "\n",
    "\n",
    "# 8. 기분 및 에너지 충돌 조정 (절대값 기준)\n",
    "mask_mood = processed['positive_feeling'].notna() & processed['negative'].notna()\n",
    "for idx in processed[mask_mood].index:\n",
    "    pos = processed.at[idx, 'positive_feeling']\n",
    "    neg = processed.at[idx, 'negative']\n",
    "    if abs(pos) > abs(neg):\n",
    "        processed.at[idx, 'negative'] = 0\n",
    "    elif abs(pos) < abs(neg):\n",
    "        processed.at[idx, 'positive_feeling'] = 0\n",
    "    else:\n",
    "        processed.at[idx, 'positive_feeling'] = 0  # 동일하면 긍정 제거, 부정 유지\n",
    "\n",
    "mask_energy = processed['positive_E'].notna() & processed['negative_E'].notna()\n",
    "for idx in processed[mask_energy].index:\n",
    "    posE = processed.at[idx, 'positive_E']\n",
    "    negE = processed.at[idx, 'negative_E']\n",
    "    if abs(posE) > abs(negE):\n",
    "        processed.at[idx, 'negative_E'] = 0\n",
    "    elif abs(posE) < abs(negE):\n",
    "        processed.at[idx, 'positive_E'] = 0\n",
    "    else:\n",
    "        processed.at[idx, 'positive_E'] = 0\n",
    "\n",
    "# 9. 값이 한쪽만 있을 경우 다른 쪽을 0으로 설정\n",
    "processed.loc[\n",
    "    processed['positive_feeling'].notna() & processed['negative'].isna(),\n",
    "    'negative'\n",
    "] = 0\n",
    "processed.loc[\n",
    "    processed['negative'].notna() & processed['positive_feeling'].isna(),\n",
    "    'positive_feeling'\n",
    "] = 0\n",
    "\n",
    "processed.loc[\n",
    "    processed['positive_E'].notna() & processed['negative_E'].isna(),\n",
    "    'negative_E'\n",
    "] = 0\n",
    "processed.loc[\n",
    "    processed['negative_E'].notna() & processed['positive_E'].isna(),\n",
    "    'positive_E'\n",
    "] = 0\n",
    "\n",
    "# 10. 디버그 출력 (최대 20개)\n",
    "for info in debug_info[:20]:\n",
    "    print(info)\n",
    "\n",
    "\n",
    "output_path = os.path.join(output_folder, \"questionnaire_panic_demo_mood.csv\")\n",
    "processed.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype, is_string_dtype, is_datetime64_any_dtype\n",
    "\n",
    "# 전체 컬럼 순회하며 형식 통일\n",
    "for col in processed.columns:\n",
    "    if col == 'ID':\n",
    "        processed[col] = processed[col].astype(str).str.strip()\n",
    "    elif col == 'date':\n",
    "        processed[col] = pd.to_datetime(processed[col], errors='coerce')  # 문자열 포함 시 자동 처리\n",
    "    elif is_datetime64_any_dtype(processed[col]):\n",
    "        processed[col] = pd.to_datetime(processed[col], errors='coerce')  # datetime이면 그대로\n",
    "    elif is_string_dtype(processed[col]):\n",
    "        processed[col] = processed[col].astype(str).str.strip()  # 문자열이면 정리\n",
    "    else:\n",
    "        # 예외적인 경우도 문자열로 통일\n",
    "        processed[col] = processed[col].astype(str).str.strip()\n",
    "\n",
    "\n",
    "output_path = os.path.join(output_folder, \"processed.csv\")\n",
    "processed.to_csv(output_path, index=False)\n",
    "print(\"모든 컬럼 형식 통일 완료 및 저장됨.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processed.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dhlab-panic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
