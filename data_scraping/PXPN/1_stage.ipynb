{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required Packages:\n",
    "- pandas  : 1.5.3\n",
    "- openpyxl: 3.1.5\n",
    "- xlrd    : 2.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“š | Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config as cfg\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import xlrd\n",
    "import os\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "\n",
    "from library.path_utils import get_file_path\n",
    "\n",
    "print(\"pandas  :\", pd.__version__)\n",
    "print(\"openpyxl:\", openpyxl.__version__)\n",
    "print(\"xlrd    :\", xlrd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# âš™ï¸ | Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_PXPN_DIR = \"./raw_data/PXPN\"\n",
    "\n",
    "# ì—‘ì…€ íŒŒì¼ ê²½ë¡œ (ì‹¤ì œ ê²½ë¡œë¡œ ìˆ˜ì •)\n",
    "enroll_file_name = \"1. í”½ì…€íŒ¨ë‹‰ enroll ì •ë³´_250516\"\n",
    "\n",
    "zip_file_name = \"pixelpanic_raw_data.zip\"\n",
    "output_folder_name = \"./_tmp/PXPN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enroll_path = get_file_path(RAW_PXPN_DIR, f\"{enroll_file_name}.xlsx\")\n",
    "zip_path = get_file_path(RAW_PXPN_DIR, f\"{zip_file_name}\")\n",
    "output_folder = get_file_path(output_folder_name)\n",
    "csv_path = get_file_path(RAW_PXPN_DIR, f\"{enroll_file_name}.csv\")\n",
    "\n",
    "# ì—‘ì…€ ì½ê³  csvë¡œ ì €ì¥\n",
    "df = pd.read_excel(enroll_path)\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "enroll_path = get_file_path(RAW_PXPN_DIR, f\"{enroll_file_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¤ë¬¸ ë¦¬ìŠ¤íŠ¸\n",
    "top_5 = [\n",
    "    'íŠ¹ì„± ë¶ˆì•ˆ ì„¤ë¬¸', 'í•œêµ­í˜• íšŒë³µíƒ„ë ¥ì„± ì§€ìˆ˜', 'í•œêµ­ì–´íŒ ì•„ì¹¨í˜•-ì €ë…í˜• ì„¤ë¬¸ì§€',\n",
    "    'í•œê¸€íŒ ìƒë¬¼í•™ì  ë¦¬ë“¬ í‰ê°€ ì„¤ë¬¸ì§€', 'ìœ ë…„ê¸° ì™¸ìƒ ì²™ë„', 'í•œêµ­í˜• ê¸°ë¶„ì¥ì•  ì„¤ë¬¸ì§€',\n",
    "    'ê´‘ì¥ê³µí¬ ì¸ì§€ ì„¤ë¬¸ì§€', 'ì•Œë°”ë‹ˆ ê³µí™©-ê³µí¬ ì§ˆë¬¸ì§€', 'ì‹ ì²´ê°ê° ì„¤ë¬¸ì§€',\n",
    "    'í•œê¸€íŒ ë²”ë¶ˆì•ˆ ì¥ì• ', 'í•œêµ­ì–´íŒ ìš°ìš¸ì¦ ì„ ë³„ë„êµ¬'\n",
    "]\n",
    "\n",
    "# ê²°ê³¼ DataFrame ì´ˆê¸°í™”: patient_code, date ì»¬ëŸ¼ í™•ë³´\n",
    "result = pd.DataFrame(columns=['patient_code', 'ë‚ ì§œ'])\n",
    "\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as outer_zip:\n",
    "    for i in range(6, 41):\n",
    "        formatted_index = f'{i:02d}'\n",
    "        patient_code = f'PXPN_100{formatted_index}'\n",
    "\n",
    "        # ë‚´ë¶€ zip íŒŒì¼ ê²½ë¡œ\n",
    "        inner_zip_name = f'ActiveData/{patient_code}_ActiveData.zip'\n",
    "        if inner_zip_name not in outer_zip.namelist():\n",
    "            continue\n",
    "\n",
    "        inner_zip_bytes = BytesIO(outer_zip.read(inner_zip_name))\n",
    "        with zipfile.ZipFile(inner_zip_bytes, 'r') as inner_zip:\n",
    "            inner_file_name = f'{patient_code}_SurveyResponse.csv'\n",
    "            if inner_file_name not in inner_zip.namelist():\n",
    "                continue\n",
    "\n",
    "            with inner_zip.open(inner_file_name) as f:\n",
    "                df = pd.read_csv(f)\n",
    "\n",
    "                # ì‘ì„±ì¼ ì»¬ëŸ¼ì—ì„œ ë‚ ì§œë§Œ ì¶”ì¶œ\n",
    "                date_value = pd.to_datetime(df['ì‘ì„±ì¼'].iloc[0]).date()\n",
    "\n",
    "                # ìƒˆë¡œìš´ í™˜ì-ì‘ì„±ì¼ í–‰ ì¶”ê°€\n",
    "                if not ((result['patient_code'] == patient_code) & (result['ë‚ ì§œ'] == date_value)).any():\n",
    "                    new_row = pd.DataFrame({\n",
    "                        'patient_code': [patient_code],\n",
    "                        'ë‚ ì§œ': [date_value]\n",
    "                    })\n",
    "                    result = pd.concat([result, new_row], ignore_index=True)\n",
    "\n",
    "                # ì ìˆ˜ ì²˜ë¦¬\n",
    "                for j in top_5:\n",
    "                    sub_df = df[df['ì„¤ë¬¸ëª…'] == j].reset_index(drop=True)\n",
    "                    if sub_df.empty:\n",
    "                        continue\n",
    "\n",
    "                    # ì—­ì±„ì  ì ìˆ˜ê°€ ìˆìœ¼ë©´ ì‚¬ìš©\n",
    "                    scores = []\n",
    "                    for idx, row in sub_df.iterrows():\n",
    "                        if row['ì—­ì±„ì ì¸ ê²½ìš° ì—­ì±„ì  ì ìˆ˜'] != '-':\n",
    "                            scores.append(float(row['ì—­ì±„ì ì¸ ê²½ìš° ì—­ì±„ì  ì ìˆ˜']))\n",
    "                        else:\n",
    "                            val = row['ì ìˆ˜']\n",
    "                            scores.append('***' if pd.isna(val) else float(val))\n",
    "\n",
    "                    # ì»¬ëŸ¼ëª… ìƒì„± ë° ê°’ ì‚½ì…\n",
    "                    if j == 'íŠ¹ì„± ë¶ˆì•ˆ ì„¤ë¬¸':\n",
    "                        prefix = 'STAI_X2'\n",
    "                    elif j == 'í•œêµ­í˜• íšŒë³µíƒ„ë ¥ì„± ì§€ìˆ˜':\n",
    "                        prefix = 'KRQ'\n",
    "                    elif j == 'í•œêµ­ì–´íŒ ì•„ì¹¨í˜•-ì €ë…í˜• ì„¤ë¬¸ì§€':\n",
    "                        prefix = 'CSM'\n",
    "                    elif j == 'í•œê¸€íŒ ìƒë¬¼í•™ì  ë¦¬ë“¬ í‰ê°€ ì„¤ë¬¸ì§€':\n",
    "                        prefix = 'BRIAN'\n",
    "                    elif j == 'í•œêµ­í˜• ê¸°ë¶„ì¥ì•  ì„¤ë¬¸ì§€':\n",
    "                        prefix = 'MDQ'\n",
    "                    elif j == 'ê´‘ì¥ê³µí¬ ì¸ì§€ ì„¤ë¬¸ì§€':\n",
    "                        prefix = 'ACQ'\n",
    "                    elif j == 'ì‹ ì²´ê°ê° ì„¤ë¬¸ì§€':\n",
    "                        prefix = 'BSQ'\n",
    "                    elif j == 'í•œê¸€íŒ ë²”ë¶ˆì•ˆ ì¥ì• ':\n",
    "                        prefix = 'GAD'\n",
    "                    elif j == 'í•œêµ­ì–´íŒ ìš°ìš¸ì¦ ì„ ë³„ë„êµ¬':\n",
    "                        prefix = 'PHQ'\n",
    "\n",
    "                    # ì£¼ì œë³„ ë¶„ë¦¬ ì²˜ë¦¬ í•„ìš” ì„¤ë¬¸\n",
    "                    if j in ['ìœ ë…„ê¸° ì™¸ìƒ ì²™ë„', 'ì•Œë°”ë‹ˆ ê³µí™©-ê³µí¬ ì§ˆë¬¸ì§€']:\n",
    "                        grouped = sub_df.copy()\n",
    "                        grouped['real_score'] = scores\n",
    "                        topic_order = {t: i+1 for i, t in enumerate(sorted(grouped['ì£¼ì œ'].unique()))}\n",
    "                        for topic, order in topic_order.items():\n",
    "                            topic_df = grouped[grouped['ì£¼ì œ'] == topic].reset_index(drop=True)\n",
    "                            for qnum, sc in enumerate(topic_df['real_score'], start=1):\n",
    "                                col_name = f\"{('CTQ' if j=='ìœ ë…„ê¸° ì™¸ìƒ ì²™ë„' else 'APPQ')}-{order}-{qnum}\"\n",
    "                                result.loc[\n",
    "                                    (result['patient_code'] == patient_code) &\n",
    "                                    (result['ë‚ ì§œ'] == date_value),\n",
    "                                    col_name\n",
    "                                ] = sc\n",
    "                    else:\n",
    "                        for idx, sc in enumerate(scores, start=1):\n",
    "                            col_name = f\"{prefix}-{idx}\"\n",
    "                            result.loc[\n",
    "                                (result['patient_code'] == patient_code) &\n",
    "                                (result['ë‚ ì§œ'] == date_value),\n",
    "                                col_name\n",
    "                            ] = sc\n",
    "\n",
    "# ì»¬ëŸ¼ ìˆœì„œ ì¬ë°°ì—´: patient_code, date, ë‚˜ë¨¸ì§€\n",
    "cols = ['patient_code', 'ë‚ ì§œ'] + [c for c in result.columns if c not in ['patient_code', 'ë‚ ì§œ']]\n",
    "result = result[cols]\n",
    "\n",
    "# ë¶ˆí•„ìš” ì»¬ëŸ¼ ì‚­ì œ\n",
    "result = result.drop(columns=['MDQ-14', 'MDQ-15', 'PHQ-10'], errors='ignore')\n",
    "\n",
    "# ì €ì¥\n",
    "\n",
    "output_path = os.path.join(output_folder, \"questionnaire.csv\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "result.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ìš©í•  ì ‘ë‘ì–´ ëª©ë¡\n",
    "prefixes = [\"PHQ\", \"STAI_X2\", \"CSM\", \"CTQ-1\", \"CTQ-2\", \"CTQ-3\", \"CTQ-4\", \"CTQ-5\", \"KRQ\", \"MDQ\", \"ACQ\", \"APPQ-1\", \"APPQ-2\", \"APPQ-3\", \"BSQ\", \"GAD\", \"BRIAN\"]\n",
    "# ê²°ê³¼ë¥¼ ì €ì¥í•  ë°ì´í„°í”„ë ˆì„\n",
    "aggregated_df = result[['patient_code', 'ë‚ ì§œ']].copy()\n",
    "\n",
    "for prefix in prefixes:\n",
    "    # í•´ë‹¹ ì ‘ë‘ì–´ë¡œ ì‹œì‘í•˜ëŠ” ì»¬ëŸ¼ ì°¾ê¸°\n",
    "    matched_cols = [col for col in result.columns if col.startswith(prefix)]\n",
    "    \n",
    "    # ê°’ í•©ì‚°í•´ì„œ ìƒˆë¡œìš´ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€\n",
    "    aggregated_df[f'{prefix.rstrip(\"-\")}'] = result[matched_cols].apply(pd.to_numeric, errors='coerce').sum(axis=1)\n",
    "\n",
    "display(aggregated_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—‘ì…€ íŒŒì¼ ê²½ë¡œ\n",
    "file_path = enroll_path\n",
    "\n",
    "# ì—‘ì…€ ì‹œíŠ¸ ì½ê¸°\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½\n",
    "df = df.rename(columns={'íšŒì›ì½”ë“œ': 'patient_code', '2. ì„±ë³„': 'gender'})\n",
    "\n",
    "# í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ\n",
    "df = df[['patient_code', 'ì—°êµ¬ì‹œì‘ì¼', 'ì—°êµ¬ì¢…ë£Œì¼', 'gender']]\n",
    "\n",
    "# ë‚ ì§œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "df['ì—°êµ¬ì‹œì‘ì¼'] = pd.to_datetime(df['ì—°êµ¬ì‹œì‘ì¼'], errors='coerce')\n",
    "df['ì—°êµ¬ì¢…ë£Œì¼'] = pd.to_datetime(df['ì—°êµ¬ì¢…ë£Œì¼'], errors='coerce')\n",
    "\n",
    "# ê° í™˜ìì— ëŒ€í•´ ë‚ ì§œ ìƒì„±\n",
    "expanded_rows = []\n",
    "for _, row in df.iterrows():\n",
    "    if pd.notnull(row['ì—°êµ¬ì‹œì‘ì¼']) and pd.notnull(row['ì—°êµ¬ì¢…ë£Œì¼']):\n",
    "        date_range = pd.date_range(start=row['ì—°êµ¬ì‹œì‘ì¼'], end=row['ì—°êµ¬ì¢…ë£Œì¼'])\n",
    "        for date in date_range:\n",
    "            expanded_rows.append({'patient_code': row['patient_code'], 'ë‚ ì§œ': date, 'gender': row['gender']})\n",
    "\n",
    "# ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "expanded_df = pd.DataFrame(expanded_rows)\n",
    "expanded_df = expanded_df.replace({'ë‚¨': '0', 'ì—¬': '1'})\n",
    "print(expanded_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—‘ì…€ íŒŒì¼ ê²½ë¡œ\n",
    "file_path = enroll_path\n",
    "\n",
    "# CSV ì½ê¸°\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½ (ìƒë…„ì›”ì¼ ì»¬ëŸ¼ë„ ì¶”ê°€)\n",
    "df = df.rename(columns={\n",
    "    'íšŒì›ì½”ë“œ': 'patient_code',\n",
    "    '2. ì„±ë³„': 'gender'  # ìƒë…„ì›”ì¼ ì»¬ëŸ¼ ì´ë¦„ì´ ì‹¤ì œ ë‹¤ë¥´ë©´ ì´ ë¶€ë¶„ ìˆ˜ì • í•„ìš”\n",
    "})\n",
    "\n",
    "# í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ\n",
    "df = df[['patient_code', 'ì—°êµ¬ì‹œì‘ì¼', 'ì—°êµ¬ì¢…ë£Œì¼', 'gender', '3. ìƒë…„ì›”ì¼']]\n",
    "\n",
    "# ë‚ ì§œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "df['ì—°êµ¬ì‹œì‘ì¼'] = pd.to_datetime(df['ì—°êµ¬ì‹œì‘ì¼'], errors='coerce')\n",
    "df['ì—°êµ¬ì¢…ë£Œì¼'] = pd.to_datetime(df['ì—°êµ¬ì¢…ë£Œì¼'], errors='coerce')\n",
    "df['3. ìƒë…„ì›”ì¼'] = pd.to_datetime(df['3. ìƒë…„ì›”ì¼'], errors='coerce')\n",
    "\n",
    "\n",
    "# ê° í™˜ìì— ëŒ€í•´ ë‚ ì§œ ìƒì„±\n",
    "expanded_rows = []\n",
    "for _, row in df.iterrows():\n",
    "    if pd.notnull(row['ì—°êµ¬ì‹œì‘ì¼']) and pd.notnull(row['ì—°êµ¬ì¢…ë£Œì¼']):\n",
    "        date_range = pd.date_range(start=row['ì—°êµ¬ì‹œì‘ì¼'], end=row['ì—°êµ¬ì¢…ë£Œì¼'])\n",
    "        for date in date_range:\n",
    "            expanded_rows.append({\n",
    "                'patient_code': row['patient_code'],\n",
    "                'ë‚ ì§œ': date,\n",
    "                'gender': '0' if row['gender'] == 'ë‚¨' else '1'\n",
    "            })\n",
    "\n",
    "# ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# ì¶œë ¥\n",
    "print(expanded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df['ë‚ ì§œ']    = pd.to_datetime(expanded_df['ë‚ ì§œ'])\n",
    "aggregated_df['ë‚ ì§œ'] = pd.to_datetime(aggregated_df['ë‚ ì§œ'])\n",
    "expanded_answer = pd.merge(expanded_df, aggregated_df, on=['patient_code', 'ë‚ ì§œ'], how='outer')\n",
    "expanded_answer = expanded_answer.rename(columns={'patient_code': 'ID', 'ë‚ ì§œ': 'date', 'GAD': 'GAD_7', 'CTQ-1': 'CTQ_1', 'CTQ-2': 'CTQ_2', 'CTQ-3': 'CTQ_3', 'CTQ-4': 'CTQ_4', 'CTQ-5': 'CTQ_5', 'APPQ-1': 'APPQ_1', 'APPQ-2': 'APPQ_2', 'APPQ-3': 'APPQ_3', 'PHQ': 'PHQ_9'})\n",
    "output_path = os.path.join(output_folder, \"questionnaire_test.csv\")\n",
    "expanded_answer.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. ë‚ ì§œ í˜•ì‹ í†µì¼\n",
    "expanded_answer['date'] = pd.to_datetime(expanded_answer['date'])\n",
    "\n",
    "# 1. PXPNë³„ Panic ë‚ ì§œ ìˆ˜ì§‘\n",
    "PXPN_panic_dates = pd.DataFrame(columns=['ID', 'date'])\n",
    "main_zip_path = zip_path  # ì˜ˆ: '/Users/.../ActiveData.zip'\n",
    "\n",
    "with zipfile.ZipFile(main_zip_path, 'r') as outer_zip:\n",
    "    for inner_name in outer_zip.namelist():\n",
    "        if inner_name.startswith(\"ActiveData/\") and inner_name.endswith('_ActiveData.zip'):\n",
    "            pid = os.path.basename(inner_name).replace('_ActiveData.zip', '')\n",
    "\n",
    "            with outer_zip.open(inner_name) as inner_file:\n",
    "                data = inner_file.read()\n",
    "                inner_bytes = BytesIO(data)\n",
    "\n",
    "                if not zipfile.is_zipfile(inner_bytes):\n",
    "                    print(f\"âŒ ë‚´ë¶€ zip ì•„ë‹˜ (ë¬´ì‹œë¨): {inner_name}\")\n",
    "                    continue\n",
    "\n",
    "                with zipfile.ZipFile(inner_bytes, 'r') as active_zip:\n",
    "                    panic_csvs = [f for f in active_zip.namelist() if f.endswith('Panic.csv')]\n",
    "                    if not panic_csvs:\n",
    "                        print(f\"âš ï¸ Panic.csv ì—†ìŒ: {inner_name}\")\n",
    "                        continue\n",
    "\n",
    "                    with active_zip.open(panic_csvs[0]) as f:\n",
    "                        df_panic = pd.read_csv(f)\n",
    "                        if 'ì‘ì„±ì¼' not in df_panic.columns:\n",
    "                            print(f\"âš ï¸ 'ì‘ì„±ì¼' ì—†ìŒ: {inner_name}\")\n",
    "                            continue\n",
    "\n",
    "                        for ì‘ì„±ì¼ in df_panic['ì‘ì„±ì¼']:\n",
    "                            PXPN_panic_dates = pd.concat([\n",
    "                                PXPN_panic_dates,\n",
    "                                pd.DataFrame({'ID': [pid], 'date': [ì‘ì„±ì¼]})\n",
    "                            ], ignore_index=True)\n",
    "\n",
    "# 2. ë‚ ì§œ ë° panic ì •ë¦¬\n",
    "PXPN_panic_dates['panic'] = 2\n",
    "PXPN_panic_dates['date'] = pd.to_datetime(PXPN_panic_dates['date']).dt.strftime('%Y-%m-%d')\n",
    "expanded_answer['date'] = pd.to_datetime(expanded_answer['date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# 3. outer merge\n",
    "merged = pd.merge(\n",
    "    PXPN_panic_dates,\n",
    "    expanded_answer,\n",
    "    on=['ID', 'date'],\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# 4. ìš°ì„ ìˆœìœ„ panic ê°’ ìœ ì§€\n",
    "merged = (\n",
    "    merged\n",
    "    .sort_values(['ID', 'date', 'panic'], ascending=[True, True, False])\n",
    "    .drop_duplicates(subset=['ID', 'date'], keep='first')\n",
    ")\n",
    "\n",
    "# 5. ì „ë‚  panic=1 ì ìš©\n",
    "df = merged.copy()\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "for _, row in df[df['panic'] == 2].iterrows():\n",
    "    pid = row['ID']\n",
    "    curr_date = row['date']\n",
    "    prev_date = curr_date - pd.Timedelta(days=1)\n",
    "\n",
    "    # ì—°ì†ëœ 2 ì œê±°\n",
    "    while ((df['ID'] == pid) & (df['date'] == prev_date) & (df['panic'] == 2)).any():\n",
    "        prev_date -= pd.Timedelta(days=1)\n",
    "\n",
    "    mask = (df['ID'] == pid) & (df['date'] == prev_date)\n",
    "    if mask.any():\n",
    "        df.loc[mask & (df['panic'].fillna(0) < 1), 'panic'] = 1\n",
    "\n",
    "df = df.sort_values(['ID', 'date']).reset_index(drop=True)\n",
    "df['date'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "df['panic'] = df['panic'].fillna(0)\n",
    "\n",
    "# 6. Enroll ë³‘í•© (age)\n",
    "enroll_df = pd.read_csv(enroll_path, encoding='utf-8')\n",
    "enroll_df = enroll_df.rename(columns={\n",
    "    'íšŒì›ì½”ë“œ': 'patient_code',\n",
    "    '3. ìƒë…„ì›”ì¼': 'birthdate',\n",
    "    'ì—°êµ¬ì¢…ë£Œì¼': 'end_date'\n",
    "})\n",
    "enroll_df['birthdate'] = pd.to_datetime(enroll_df['birthdate'], errors='coerce')\n",
    "enroll_df['end_date'] = pd.to_datetime(enroll_df['end_date'], errors='coerce')\n",
    "enroll_df['age'] = enroll_df['end_date'].dt.year - enroll_df['birthdate'].dt.year\n",
    "\n",
    "age_df = enroll_df[['patient_code', 'age']].drop_duplicates().rename(columns={'patient_code': 'ID'})\n",
    "final_df = df.merge(age_df, on='ID', how='left')\n",
    "\n",
    "# 7. ì €ì¥\n",
    "output_path = os.path.join(output_folder, \"questionnaire_and_panic_date.csv\")\n",
    "final_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒŒì¼ ê²½ë¡œ\n",
    "csv_path = output_path\n",
    "zip_path = zip_path\n",
    "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(csv_path)\n",
    "df = df[df[\"ID\"].str.startswith(\"PXPN\")].copy()\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# ì»¬ëŸ¼ ì´ˆê¸°í™”\n",
    "for col in ['marriage', 'job', 'alcohol', 'coffee', 'smoking', 'menstruation', 'exercise',\n",
    "            'smkHx', 'drinkHx', 'suicideHx',\n",
    "            'suicide_need']: \n",
    "    df[col] = np.nan\n",
    "\n",
    "# ZIP ì—´ê¸°\n",
    "with zipfile.ZipFile(zip_path, 'r') as outer_zip:\n",
    "    for pid in df['ID'].unique():\n",
    "        inner_zip_name = f\"ActiveData/{pid}_ActiveData.zip\"\n",
    "        if inner_zip_name not in outer_zip.namelist():\n",
    "            continue\n",
    "\n",
    "        # ë‚´ë¶€ ZIP ì—´ê¸°\n",
    "        with outer_zip.open(inner_zip_name) as inner_zip_file:\n",
    "            inner_zip_bytes = BytesIO(inner_zip_file.read())\n",
    "            with zipfile.ZipFile(inner_zip_bytes) as inner_zip:\n",
    "\n",
    "                # 1. Sociodemographic ì²˜ë¦¬\n",
    "                soc_path = f\"{pid}_Sociodemographic.csv\"\n",
    "                if soc_path in inner_zip.namelist():\n",
    "                    soc = pd.read_csv(inner_zip.open(soc_path), header=None, index_col=0).T\n",
    "                    if 'ê²°í˜¼' in soc.columns:\n",
    "                        df.loc[df['ID'] == pid, 'marriage'] = 1 if soc['ê²°í˜¼'].values[0] == 'ê¸°í˜¼' else 0\n",
    "                    if 'í˜„ì¬ ì§ì—… ìœ ë¬´' in soc.columns:\n",
    "                        df.loc[df['ID'] == pid, 'job'] = 1 if soc['í˜„ì¬ ì§ì—… ìœ ë¬´'].values[0] == 'Y' else 0\n",
    "                    if 'ê³¼ê±° í¡ì—° ì—¬ë¶€' in soc.columns:\n",
    "                        df.loc[df['ID'] == pid, 'smkHx'] = 1 if soc['ê³¼ê±° í¡ì—° ì—¬ë¶€'].values[0] == 'Y' else 0\n",
    "                    if 'ì§€ê¸ˆê¹Œì§€ ìŒì£¼ ì—¬ë¶€' in soc.columns:\n",
    "                        df.loc[df['ID'] == pid, 'drinkHx'] = 1 if soc['ì§€ê¸ˆê¹Œì§€ ìŒì£¼ ì—¬ë¶€'].values[0] == 'Y' else 0\n",
    "                    if 'ê³¼ê±° ìì‚´ ì‹œë„ ì—¬ë¶€' in soc.columns:\n",
    "                        df.loc[df['ID'] == pid, 'suicideHx'] = 1 if soc['ê³¼ê±° ìì‚´ ì‹œë„ ì—¬ë¶€'].values[0] == 'Y' else 0\n",
    "                    if 'ì§€ë‚œ 1ë‹¬ê°„ ìì‚´ì‹œë„ ì—¬ë¶€' in soc.columns:\n",
    "                        df.loc[df['ID'] == pid, 'suicide_need'] = 1 if soc['ì§€ë‚œ 1ë‹¬ê°„ ìì‚´ì‹œë„ ì—¬ë¶€'].values[0] == 'Y' else 0\n",
    "\n",
    "\n",
    "                # 2. Pattern ì²˜ë¦¬\n",
    "                pat_path = f\"{pid}_Pattern.csv\"\n",
    "                if pat_path in inner_zip.namelist():\n",
    "                    pat = pd.read_csv(inner_zip.open(pat_path))\n",
    "                    pat['ì‘ì„±ì¼'] = pd.to_datetime(pat['ì‘ì„±ì¼'], errors='coerce')\n",
    "\n",
    "                    for idx, row in df[df[\"ID\"] == pid].iterrows():\n",
    "                        d = row[\"date\"]\n",
    "                        today_rows = pat[pat[\"ì‘ì„±ì¼\"] == d]\n",
    "                        for _, r in today_rows.iterrows():\n",
    "                            t = r.get('ì¢…ë¥˜', '')\n",
    "                            st = r.get('ì„¸ë¶€ì¢…ë¥˜', '')\n",
    "                            amount = r.get('ì–‘', None)  # 'ì–‘' ì»¬ëŸ¼ ê°’\n",
    "                            # ìš´ë™\n",
    "                            if t == 'ìš´ë™':\n",
    "                                # ì–‘ ê°’ì´ ìˆìœ¼ë©´ ê·¸ ê°’ì„, ì—†ìœ¼ë©´ 1 ë¡œ ë””í´íŠ¸\n",
    "                                df.at[idx, 'exercise'] = amount if pd.notna(amount) else 1\n",
    "                            # ì¹´í˜ì¸\n",
    "                            if t == 'ì¹´í˜ì¸':\n",
    "                                df.at[idx, 'coffee'] = amount if pd.notna(amount) else 1\n",
    "                            # í¡ì—°\n",
    "                            if t == 'í¡ì—°':\n",
    "                                df.at[idx, 'smoking'] = amount if pd.notna(amount) else 1\n",
    "                            # ìŒì£¼(ì–‘ì´ ì•„ë‹Œ ë‹¨ìˆœ ì—¬ë¶€ë§Œ ì›í•˜ë©´ ê¸°ì¡´ì²˜ëŸ¼ 1ë¡œ)\n",
    "                            if t == 'ìŒì£¼':\n",
    "                                df.at[idx, 'alcohol'] = amount if pd.notna(amount) else 1\n",
    "                            # ìƒë¦¬\n",
    "                            if t == 'ìƒë¦¬' and st == 'ìƒë¦¬ì¤‘':\n",
    "                                df.at[idx, 'menstruation'] = 1\n",
    "\n",
    "output_path = os.path.join(output_folder, \"questionnaire_and_panic_dates_and_demo.csv\")\n",
    "df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ê²½ë¡œ ì„¤ì •\n",
    "zip_path = zip_path\n",
    "processed = df  \n",
    "\n",
    "# 3. PXPN ID ëª©ë¡ ì¶”ì¶œ\n",
    "pxpn_ids = processed[processed['ID'].astype(str).str.startswith('PXPN')]['ID'].unique()\n",
    "\n",
    "# 4. ê°ì • ê´€ë ¨ ì»¬ëŸ¼ ì´ˆê¸°í™”\n",
    "emotion_cols = ['positive_feeling', 'negative', 'positive_E', 'negative_E', 'anxiety', 'annoying']\n",
    "for col in emotion_cols:\n",
    "    if col not in processed.columns:\n",
    "        processed[col] = np.nan\n",
    "\n",
    "# 5. ë””ë²„ê·¸ìš© ì¹´ìš´í„° ë° ì •ë³´\n",
    "match_count = 0\n",
    "no_date_match = 0\n",
    "processed_ids = set()\n",
    "debug_info = []\n",
    "\n",
    "# 6. ì™¸ë¶€ zip ì—´ê¸°\n",
    "try:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as outer_zip:\n",
    "\n",
    "        # 7. ëª¨ë“  PXPN IDì— ëŒ€í•´ ë°˜ë³µ\n",
    "        for pid in pxpn_ids:\n",
    "            pid = str(pid).strip()\n",
    "            inner_zip_name = f\"ActiveData/{pid}_ActiveData.zip\"\n",
    "\n",
    "            if inner_zip_name not in outer_zip.namelist():\n",
    "                debug_info.append(f\"âŒ ID {pid}: ë‚´ë¶€ ZIP ì—†ìŒ â†’ {inner_zip_name}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                with outer_zip.open(inner_zip_name) as inner_zip_file:\n",
    "                    inner_zip_bytes = BytesIO(inner_zip_file.read())\n",
    "\n",
    "                    with zipfile.ZipFile(inner_zip_bytes) as inner_zip:\n",
    "                        checkup_filename = f\"{pid}_Checkup.csv\"\n",
    "\n",
    "                        if checkup_filename not in inner_zip.namelist():\n",
    "                            debug_info.append(f\"âš ï¸ ID {pid}: Checkup íŒŒì¼ ì—†ìŒ\")\n",
    "                            continue\n",
    "\n",
    "                        # Checkup CSV ì½ê¸°\n",
    "                        checkup = pd.read_csv(inner_zip.open(checkup_filename))\n",
    "\n",
    "                        # ë‚ ì§œ íƒ€ì… ë³€í™˜\n",
    "                        processed_pid = processed[processed['ID'] == pid].copy()\n",
    "                        processed_pid['date'] = pd.to_datetime(processed_pid['date'], errors='coerce')\n",
    "                        checkup['ì‘ì„±ì¼'] = pd.to_datetime(checkup['ì‘ì„±ì¼'], errors='coerce')\n",
    "\n",
    "                        # ê°ì • ì¹´í…Œê³ ë¦¬ë³„ ì²˜ë¦¬\n",
    "                        for category in ['ê¸°ë¶„', 'ì—ë„ˆì§€', 'ë¶ˆì•ˆ', 'ì§œì¦']:\n",
    "                            category_data = checkup[checkup['ì¢…ë¥˜'] == category]\n",
    "\n",
    "                            for _, row in category_data.iterrows():\n",
    "                                checkup_date = row['ì‘ì„±ì¼']\n",
    "                                score = row['ì²™ë„']\n",
    "\n",
    "                                for idx, proc_row in processed_pid.iterrows():\n",
    "                                    proc_date = proc_row['date']\n",
    "                                    if (\n",
    "                                        proc_date.year == checkup_date.year and\n",
    "                                        proc_date.month == checkup_date.month and\n",
    "                                        proc_date.day == checkup_date.day\n",
    "                                    ):\n",
    "                                        if category == 'ê¸°ë¶„':\n",
    "                                            if score > 0:\n",
    "                                                processed.at[idx, 'positive_feeling'] = score\n",
    "                                            elif score < 0:\n",
    "                                                processed.at[idx, 'negative'] = score\n",
    "                                        elif category == 'ì—ë„ˆì§€':\n",
    "                                            if score > 0:\n",
    "                                                processed.at[idx, 'positive_E'] = score\n",
    "                                            elif score < 0:\n",
    "                                                processed.at[idx, 'negative_E'] = score\n",
    "                                        elif category == 'ë¶ˆì•ˆ':\n",
    "                                            processed.at[idx, 'anxiety'] = score\n",
    "                                        elif category == 'ì§œì¦':\n",
    "                                            processed.at[idx, 'annoying'] = score\n",
    "\n",
    "                                        match_count += 1\n",
    "                                        processed_ids.add(pid)\n",
    "            except Exception as e:\n",
    "                debug_info.append(f\"â— ID {pid} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}\")\n",
    "except Exception as e:\n",
    "    debug_info.append(f\"ZIP íŒŒì¼ ì²˜ë¦¬ ì „ì²´ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "\n",
    "# 8. ê¸°ë¶„ ë° ì—ë„ˆì§€ ì¶©ëŒ ì¡°ì • (ì ˆëŒ€ê°’ ê¸°ì¤€)\n",
    "mask_mood = processed['positive_feeling'].notna() & processed['negative'].notna()\n",
    "for idx in processed[mask_mood].index:\n",
    "    pos = processed.at[idx, 'positive_feeling']\n",
    "    neg = processed.at[idx, 'negative']\n",
    "    if abs(pos) > abs(neg):\n",
    "        processed.at[idx, 'negative'] = 0\n",
    "    elif abs(pos) < abs(neg):\n",
    "        processed.at[idx, 'positive_feeling'] = 0\n",
    "    else:\n",
    "        processed.at[idx, 'positive_feeling'] = 0  # ë™ì¼í•˜ë©´ ê¸ì • ì œê±°, ë¶€ì • ìœ ì§€\n",
    "\n",
    "mask_energy = processed['positive_E'].notna() & processed['negative_E'].notna()\n",
    "for idx in processed[mask_energy].index:\n",
    "    posE = processed.at[idx, 'positive_E']\n",
    "    negE = processed.at[idx, 'negative_E']\n",
    "    if abs(posE) > abs(negE):\n",
    "        processed.at[idx, 'negative_E'] = 0\n",
    "    elif abs(posE) < abs(negE):\n",
    "        processed.at[idx, 'positive_E'] = 0\n",
    "    else:\n",
    "        processed.at[idx, 'positive_E'] = 0\n",
    "\n",
    "# 9. ê°’ì´ í•œìª½ë§Œ ìˆì„ ê²½ìš° ë‹¤ë¥¸ ìª½ì„ 0ìœ¼ë¡œ ì„¤ì •\n",
    "processed.loc[\n",
    "    processed['positive_feeling'].notna() & processed['negative'].isna(),\n",
    "    'negative'\n",
    "] = 0\n",
    "processed.loc[\n",
    "    processed['negative'].notna() & processed['positive_feeling'].isna(),\n",
    "    'positive_feeling'\n",
    "] = 0\n",
    "\n",
    "processed.loc[\n",
    "    processed['positive_E'].notna() & processed['negative_E'].isna(),\n",
    "    'negative_E'\n",
    "] = 0\n",
    "processed.loc[\n",
    "    processed['negative_E'].notna() & processed['positive_E'].isna(),\n",
    "    'positive_E'\n",
    "] = 0\n",
    "\n",
    "# 10. ë””ë²„ê·¸ ì¶œë ¥ (ìµœëŒ€ 20ê°œ)\n",
    "for info in debug_info[:20]:\n",
    "    print(info)\n",
    "\n",
    "\n",
    "output_path = os.path.join(output_folder, \"questionnaire_panic_demo_mood.csv\")\n",
    "processed.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype, is_string_dtype, is_datetime64_any_dtype\n",
    "\n",
    "# ì „ì²´ ì»¬ëŸ¼ ìˆœíšŒí•˜ë©° í˜•ì‹ í†µì¼\n",
    "for col in processed.columns:\n",
    "    if col == 'ID':\n",
    "        processed[col] = processed[col].astype(str).str.strip()\n",
    "    elif col == 'date':\n",
    "        processed[col] = pd.to_datetime(processed[col], errors='coerce')  # ë¬¸ìì—´ í¬í•¨ ì‹œ ìë™ ì²˜ë¦¬\n",
    "    elif is_datetime64_any_dtype(processed[col]):\n",
    "        processed[col] = pd.to_datetime(processed[col], errors='coerce')  # datetimeì´ë©´ ê·¸ëŒ€ë¡œ\n",
    "    elif is_string_dtype(processed[col]):\n",
    "        processed[col] = processed[col].astype(str).str.strip()  # ë¬¸ìì—´ì´ë©´ ì •ë¦¬\n",
    "    else:\n",
    "        # ì˜ˆì™¸ì ì¸ ê²½ìš°ë„ ë¬¸ìì—´ë¡œ í†µì¼\n",
    "        processed[col] = processed[col].astype(str).str.strip()\n",
    "\n",
    "\n",
    "output_path = os.path.join(output_folder, \"processed.csv\")\n",
    "processed.to_csv(output_path, index=False)\n",
    "print(\"ëª¨ë“  ì»¬ëŸ¼ í˜•ì‹ í†µì¼ ì™„ë£Œ ë° ì €ì¥ë¨.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processed.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dhlab-panic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
