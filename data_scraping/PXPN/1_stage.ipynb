{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required Packages:\n",
    "- pandas  : 1.5.3\n",
    "- openpyxl: 3.1.5\n",
    "- xlrd    : 2.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö | Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas  : 2.3.1\n",
      "openpyxl: 3.1.5\n",
      "xlrd    : 2.0.2\n"
     ]
    }
   ],
   "source": [
    "import config as cfg\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import xlrd\n",
    "import os\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "\n",
    "from library.path_utils import get_file_path, to_absolute_path\n",
    "\n",
    "print(\"pandas  :\", pd.__version__)\n",
    "print(\"openpyxl:\", openpyxl.__version__)\n",
    "print(\"xlrd    :\", xlrd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è | Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_PXPN_DIR = \"./raw_data/PXPN\"\n",
    "\n",
    "# ÏóëÏÖÄ ÌååÏùº Í≤ΩÎ°ú (Ïã§Ï†ú Í≤ΩÎ°úÎ°ú ÏàòÏ†ï)\n",
    "enroll_file_name = \"1. ÌîΩÏÖÄÌå®Îãâ enroll Ï†ïÎ≥¥_250516\"\n",
    "\n",
    "zip_file_name = \"pixelpanic_raw_data.zip\"\n",
    "output_folder_name = \"./_tmp/PXPN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "enroll_path = get_file_path(RAW_PXPN_DIR, f\"{enroll_file_name}.xlsx\")\n",
    "zip_path = get_file_path(RAW_PXPN_DIR, f\"{zip_file_name}\")\n",
    "csv_path = get_file_path(RAW_PXPN_DIR, f\"{enroll_file_name}.csv\")\n",
    "output_folder = to_absolute_path(output_folder_name)\n",
    "\n",
    "# ÏóëÏÖÄ ÏùΩÍ≥† csvÎ°ú Ï†ÄÏû•\n",
    "df = pd.read_excel(enroll_path)\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "enroll_path = get_file_path(RAW_PXPN_DIR, f\"{enroll_file_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\437070262.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result.loc[\n"
     ]
    }
   ],
   "source": [
    "# ÏÑ§Î¨∏ Î¶¨Ïä§Ìä∏\n",
    "top_5 = [\n",
    "    'ÌäπÏÑ± Î∂àÏïà ÏÑ§Î¨∏', 'ÌïúÍµ≠Ìòï ÌöåÎ≥µÌÉÑÎ†•ÏÑ± ÏßÄÏàò', 'ÌïúÍµ≠Ïñ¥Ìåê ÏïÑÏπ®Ìòï-Ï†ÄÎÖÅÌòï ÏÑ§Î¨∏ÏßÄ',\n",
    "    'ÌïúÍ∏ÄÌåê ÏÉùÎ¨ºÌïôÏ†Å Î¶¨Îì¨ ÌèâÍ∞Ä ÏÑ§Î¨∏ÏßÄ', 'Ïú†ÎÖÑÍ∏∞ Ïô∏ÏÉÅ Ï≤ôÎèÑ', 'ÌïúÍµ≠Ìòï Í∏∞Î∂ÑÏû•Ïï† ÏÑ§Î¨∏ÏßÄ',\n",
    "    'Í¥ëÏû•Í≥µÌè¨ Ïù∏ÏßÄ ÏÑ§Î¨∏ÏßÄ', 'ÏïåÎ∞îÎãà Í≥µÌô©-Í≥µÌè¨ ÏßàÎ¨∏ÏßÄ', 'Ïã†Ï≤¥Í∞êÍ∞Å ÏÑ§Î¨∏ÏßÄ',\n",
    "    'ÌïúÍ∏ÄÌåê Î≤îÎ∂àÏïà Ïû•Ïï†', 'ÌïúÍµ≠Ïñ¥Ìåê Ïö∞Ïö∏Ï¶ù ÏÑ†Î≥ÑÎèÑÍµ¨'\n",
    "]\n",
    "\n",
    "# Í≤∞Í≥º DataFrame Ï¥àÍ∏∞Ìôî: patient_code, date Ïª¨Îüº ÌôïÎ≥¥\n",
    "result = pd.DataFrame(columns=['patient_code', 'ÎÇ†Ïßú'])\n",
    "\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as outer_zip:\n",
    "    for i in range(6, 41):\n",
    "        formatted_index = f'{i:02d}'\n",
    "        patient_code = f'PXPN_100{formatted_index}'\n",
    "\n",
    "        # ÎÇ¥Î∂Ä zip ÌååÏùº Í≤ΩÎ°ú\n",
    "        inner_zip_name = f'ActiveData/{patient_code}_ActiveData.zip'\n",
    "        if inner_zip_name not in outer_zip.namelist():\n",
    "            continue\n",
    "\n",
    "        inner_zip_bytes = BytesIO(outer_zip.read(inner_zip_name))\n",
    "        with zipfile.ZipFile(inner_zip_bytes, 'r') as inner_zip:\n",
    "            inner_file_name = f'{patient_code}_SurveyResponse.csv'\n",
    "            if inner_file_name not in inner_zip.namelist():\n",
    "                continue\n",
    "\n",
    "            with inner_zip.open(inner_file_name) as f:\n",
    "                df = pd.read_csv(f)\n",
    "\n",
    "                # ÏûëÏÑ±Ïùº Ïª¨ÎüºÏóêÏÑú ÎÇ†ÏßúÎßå Ï∂îÏ∂ú\n",
    "                date_value = pd.to_datetime(df['ÏûëÏÑ±Ïùº'].iloc[0]).date()\n",
    "\n",
    "                # ÏÉàÎ°úÏö¥ ÌôòÏûê-ÏûëÏÑ±Ïùº Ìñâ Ï∂îÍ∞Ä\n",
    "                if not ((result['patient_code'] == patient_code) & (result['ÎÇ†Ïßú'] == date_value)).any():\n",
    "                    new_row = pd.DataFrame({\n",
    "                        'patient_code': [patient_code],\n",
    "                        'ÎÇ†Ïßú': [date_value]\n",
    "                    })\n",
    "                    result = pd.concat([result, new_row], ignore_index=True)\n",
    "\n",
    "                # Ï†êÏàò Ï≤òÎ¶¨\n",
    "                for j in top_5:\n",
    "                    sub_df = df[df['ÏÑ§Î¨∏Î™Ö'] == j].reset_index(drop=True)\n",
    "                    if sub_df.empty:\n",
    "                        continue\n",
    "\n",
    "                    # Ïó≠Ï±ÑÏ†ê Ï†êÏàòÍ∞Ä ÏûàÏúºÎ©¥ ÏÇ¨Ïö©\n",
    "                    scores = []\n",
    "                    for idx, row in sub_df.iterrows():\n",
    "                        if row['Ïó≠Ï±ÑÏ†êÏù∏ Í≤ΩÏö∞ Ïó≠Ï±ÑÏ†ê Ï†êÏàò'] != '-':\n",
    "                            scores.append(float(row['Ïó≠Ï±ÑÏ†êÏù∏ Í≤ΩÏö∞ Ïó≠Ï±ÑÏ†ê Ï†êÏàò']))\n",
    "                        else:\n",
    "                            val = row['Ï†êÏàò']\n",
    "                            scores.append('***' if pd.isna(val) else float(val))\n",
    "\n",
    "                    # Ïª¨ÎüºÎ™Ö ÏÉùÏÑ± Î∞è Í∞í ÏÇΩÏûÖ\n",
    "                    if j == 'ÌäπÏÑ± Î∂àÏïà ÏÑ§Î¨∏':\n",
    "                        prefix = 'STAI_X2'\n",
    "                    elif j == 'ÌïúÍµ≠Ìòï ÌöåÎ≥µÌÉÑÎ†•ÏÑ± ÏßÄÏàò':\n",
    "                        prefix = 'KRQ'\n",
    "                    elif j == 'ÌïúÍµ≠Ïñ¥Ìåê ÏïÑÏπ®Ìòï-Ï†ÄÎÖÅÌòï ÏÑ§Î¨∏ÏßÄ':\n",
    "                        prefix = 'CSM'\n",
    "                    elif j == 'ÌïúÍ∏ÄÌåê ÏÉùÎ¨ºÌïôÏ†Å Î¶¨Îì¨ ÌèâÍ∞Ä ÏÑ§Î¨∏ÏßÄ':\n",
    "                        prefix = 'BRIAN'\n",
    "                    elif j == 'ÌïúÍµ≠Ìòï Í∏∞Î∂ÑÏû•Ïï† ÏÑ§Î¨∏ÏßÄ':\n",
    "                        prefix = 'MDQ'\n",
    "                    elif j == 'Í¥ëÏû•Í≥µÌè¨ Ïù∏ÏßÄ ÏÑ§Î¨∏ÏßÄ':\n",
    "                        prefix = 'ACQ'\n",
    "                    elif j == 'Ïã†Ï≤¥Í∞êÍ∞Å ÏÑ§Î¨∏ÏßÄ':\n",
    "                        prefix = 'BSQ'\n",
    "                    elif j == 'ÌïúÍ∏ÄÌåê Î≤îÎ∂àÏïà Ïû•Ïï†':\n",
    "                        prefix = 'GAD'\n",
    "                    elif j == 'ÌïúÍµ≠Ïñ¥Ìåê Ïö∞Ïö∏Ï¶ù ÏÑ†Î≥ÑÎèÑÍµ¨':\n",
    "                        prefix = 'PHQ'\n",
    "\n",
    "                    # Ï£ºÏ†úÎ≥Ñ Î∂ÑÎ¶¨ Ï≤òÎ¶¨ ÌïÑÏöî ÏÑ§Î¨∏\n",
    "                    if j in ['Ïú†ÎÖÑÍ∏∞ Ïô∏ÏÉÅ Ï≤ôÎèÑ', 'ÏïåÎ∞îÎãà Í≥µÌô©-Í≥µÌè¨ ÏßàÎ¨∏ÏßÄ']:\n",
    "                        grouped = sub_df.copy()\n",
    "                        grouped['real_score'] = scores\n",
    "                        topic_order = {t: i+1 for i, t in enumerate(sorted(grouped['Ï£ºÏ†ú'].unique()))}\n",
    "                        for topic, order in topic_order.items():\n",
    "                            topic_df = grouped[grouped['Ï£ºÏ†ú'] == topic].reset_index(drop=True)\n",
    "                            for qnum, sc in enumerate(topic_df['real_score'], start=1):\n",
    "                                col_name = f\"{('CTQ' if j=='Ïú†ÎÖÑÍ∏∞ Ïô∏ÏÉÅ Ï≤ôÎèÑ' else 'APPQ')}-{order}-{qnum}\"\n",
    "                                result.loc[\n",
    "                                    (result['patient_code'] == patient_code) &\n",
    "                                    (result['ÎÇ†Ïßú'] == date_value),\n",
    "                                    col_name\n",
    "                                ] = sc\n",
    "                    else:\n",
    "                        for idx, sc in enumerate(scores, start=1):\n",
    "                            col_name = f\"{prefix}-{idx}\"\n",
    "                            result.loc[\n",
    "                                (result['patient_code'] == patient_code) &\n",
    "                                (result['ÎÇ†Ïßú'] == date_value),\n",
    "                                col_name\n",
    "                            ] = sc\n",
    "\n",
    "# Ïª¨Îüº ÏàúÏÑú Ïû¨Î∞∞Ïó¥: patient_code, date, ÎÇòÎ®∏ÏßÄ\n",
    "cols = ['patient_code', 'ÎÇ†Ïßú'] + [c for c in result.columns if c not in ['patient_code', 'ÎÇ†Ïßú']]\n",
    "result = result[cols]\n",
    "\n",
    "# Î∂àÌïÑÏöî Ïª¨Îüº ÏÇ≠Ï†ú\n",
    "result = result.drop(columns=['MDQ-14', 'MDQ-15', 'PHQ-10'], errors='ignore')\n",
    "\n",
    "# Ï†ÄÏû•\n",
    "\n",
    "output_path = os.path.join(output_folder, \"questionnaire.csv\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "result.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_code</th>\n",
       "      <th>ÎÇ†Ïßú</th>\n",
       "      <th>PHQ</th>\n",
       "      <th>STAI_X2</th>\n",
       "      <th>CSM</th>\n",
       "      <th>CTQ-1</th>\n",
       "      <th>CTQ-2</th>\n",
       "      <th>CTQ-3</th>\n",
       "      <th>CTQ-4</th>\n",
       "      <th>CTQ-5</th>\n",
       "      <th>KRQ</th>\n",
       "      <th>MDQ</th>\n",
       "      <th>ACQ</th>\n",
       "      <th>APPQ-1</th>\n",
       "      <th>APPQ-2</th>\n",
       "      <th>APPQ-3</th>\n",
       "      <th>BSQ</th>\n",
       "      <th>GAD</th>\n",
       "      <th>BRIAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PXPN_10006</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PXPN_10007</td>\n",
       "      <td>2024-11-13</td>\n",
       "      <td>14.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PXPN_10008</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PXPN_10009</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>18.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PXPN_10010</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>15.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PXPN_10011</td>\n",
       "      <td>2024-11-09</td>\n",
       "      <td>14.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PXPN_10012</td>\n",
       "      <td>2024-11-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PXPN_10013</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>21.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PXPN_10014</td>\n",
       "      <td>2024-11-18</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PXPN_10015</td>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>14.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PXPN_10018</td>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>6.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PXPN_10019</td>\n",
       "      <td>2024-11-22</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PXPN_10020</td>\n",
       "      <td>2024-12-11</td>\n",
       "      <td>21.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PXPN_10021</td>\n",
       "      <td>2024-12-24</td>\n",
       "      <td>22.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PXPN_10022</td>\n",
       "      <td>2024-12-11</td>\n",
       "      <td>10.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PXPN_10023</td>\n",
       "      <td>2025-01-03</td>\n",
       "      <td>11.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PXPN_10024</td>\n",
       "      <td>2025-01-23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PXPN_10025</td>\n",
       "      <td>2025-01-23</td>\n",
       "      <td>6.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PXPN_10028</td>\n",
       "      <td>2025-02-26</td>\n",
       "      <td>18.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PXPN_10029</td>\n",
       "      <td>2025-02-28</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PXPN_10030</td>\n",
       "      <td>2025-02-12</td>\n",
       "      <td>16.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PXPN_10032</td>\n",
       "      <td>2025-03-06</td>\n",
       "      <td>27.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PXPN_10034</td>\n",
       "      <td>2025-02-14</td>\n",
       "      <td>14.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PXPN_10036</td>\n",
       "      <td>2025-05-13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PXPN_10037</td>\n",
       "      <td>2025-03-31</td>\n",
       "      <td>15.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PXPN_10038</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>6.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PXPN_10039</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>13.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PXPN_10040</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>10.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_code          ÎÇ†Ïßú   PHQ  STAI_X2   CSM  CTQ-1  CTQ-2  CTQ-3  CTQ-4  \\\n",
       "0    PXPN_10006  2024-11-04   0.0     32.0  31.0   11.0   13.0   17.0   28.0   \n",
       "1    PXPN_10007  2024-11-13  14.0     71.0  20.0    5.0    9.0   24.0   40.0   \n",
       "2    PXPN_10008  2024-11-04   2.0     54.0  24.0    5.0    9.0    7.0   28.0   \n",
       "3    PXPN_10009  2024-11-04  18.0     70.0  26.0    9.0   17.0   17.0   38.0   \n",
       "4    PXPN_10010  2024-11-06  15.0     67.0  20.0    5.0    6.0    5.0   15.0   \n",
       "5    PXPN_10011  2024-11-09  14.0     49.0  20.0    5.0    5.0    7.0   11.0   \n",
       "6    PXPN_10012  2024-11-11   0.0     60.0  20.0    5.0    6.0    5.0   26.0   \n",
       "7    PXPN_10013  2024-11-08  21.0     67.0  28.0    7.0   12.0   20.0   40.0   \n",
       "8    PXPN_10014  2024-11-18  13.0     71.0  14.0   15.0    5.0   16.0   28.0   \n",
       "9    PXPN_10015  2024-11-25  14.0     56.0  26.0   15.0   10.0   19.0   26.0   \n",
       "10   PXPN_10018  2024-11-20   6.0     56.0  31.0    5.0    7.0   17.0   31.0   \n",
       "11   PXPN_10019  2024-11-22   8.0     51.0  26.0    5.0    7.0    7.0   10.0   \n",
       "12   PXPN_10020  2024-12-11  21.0     77.0  36.0    5.0    5.0    5.0    8.0   \n",
       "13   PXPN_10021  2024-12-24  22.0     73.0  14.0    5.0    6.0   11.0   34.0   \n",
       "14   PXPN_10022  2024-12-11  10.0     46.0  31.0    5.0    5.0   14.0    8.0   \n",
       "15   PXPN_10023  2025-01-03  11.0     57.0  19.0    5.0    8.0    7.0   17.0   \n",
       "16   PXPN_10024  2025-01-23   5.0     35.0  36.0    5.0    5.0    5.0    9.0   \n",
       "17   PXPN_10025  2025-01-23   6.0     51.0  29.0    5.0    9.0    7.0   10.0   \n",
       "18   PXPN_10028  2025-02-26  18.0     64.0  32.0    5.0    5.0    6.0   19.0   \n",
       "19   PXPN_10029  2025-02-28  15.0     60.0  33.0    5.0    7.0    9.0   22.0   \n",
       "20   PXPN_10030  2025-02-12  16.0     60.0  17.0    5.0    6.0   12.0   23.0   \n",
       "21   PXPN_10032  2025-03-06  27.0     74.0  13.0   13.0   16.0   24.0   31.0   \n",
       "22   PXPN_10034  2025-02-14  14.0     54.0  39.0    5.0   14.0   21.0   31.0   \n",
       "23   PXPN_10036  2025-05-13   6.0     44.0  29.0   14.0   16.0   10.0   27.0   \n",
       "24   PXPN_10037  2025-03-31  15.0     58.0  16.0    6.0    5.0    6.0   16.0   \n",
       "25   PXPN_10038  2025-03-19   6.0     47.0  44.0    5.0    5.0    7.0   14.0   \n",
       "26   PXPN_10039  2025-04-10  13.0     50.0  33.0    5.0    6.0   12.0   20.0   \n",
       "27   PXPN_10040  2025-05-05  10.0     45.0  29.0    5.0    5.0   14.0   14.0   \n",
       "\n",
       "    CTQ-5    KRQ   MDQ   ACQ  APPQ-1  APPQ-2  APPQ-3   BSQ   GAD  BRIAN  \n",
       "0    12.0  219.0   1.0  21.0     0.0    10.0     2.0  25.0   2.0   25.0  \n",
       "1    20.0  131.0   4.0  33.0    24.0    12.0    16.0  29.0  18.0   71.0  \n",
       "2     5.0  165.0   4.0  35.0    29.0    28.0    31.0  49.0   7.0   46.0  \n",
       "3    23.0  117.0  11.0  60.0    56.0    19.0    64.0  43.0  16.0   64.0  \n",
       "4     7.0  163.0   4.0  43.0    32.0    32.0    58.0  57.0  13.0   64.0  \n",
       "5     5.0  167.0  13.0  44.0    38.0    20.0    54.0  50.0  12.0   62.0  \n",
       "6    14.0  153.0   0.0  37.0    26.0     7.0    23.0  42.0   9.0    0.0  \n",
       "7    20.0  110.0  12.0  61.0    42.0    58.0    65.0  65.0  16.0   58.0  \n",
       "8     9.0  123.0   2.0  33.0    31.0    13.0    30.0  46.0  18.0   70.0  \n",
       "9    14.0  159.0   2.0  27.0    34.0    38.0    49.0  64.0   7.0   51.0  \n",
       "10   13.0  163.0  12.0  42.0     8.0    11.0    15.0  49.0  10.0   45.0  \n",
       "11    5.0  187.0   2.0  25.0     0.0     6.0    14.0  38.0   6.0   44.0  \n",
       "12    5.0  152.0   4.0  43.0     4.0    34.0    32.0  83.0  12.0   59.0  \n",
       "13   14.0  115.0   9.0  47.0    40.0    34.0    46.0  81.0  10.0   70.0  \n",
       "14   16.0  220.0   7.0  27.0    14.0    30.0    11.0  56.0   9.0   60.0  \n",
       "15    5.0  161.0   7.0  28.0     6.0    10.0    50.0  43.0   5.0   60.0  \n",
       "16    5.0  214.0   5.0  25.0     8.0    26.0    20.0  42.0   5.0   45.0  \n",
       "17    6.0  218.0   7.0  31.0    32.0    36.0    33.0  48.0  10.0   51.0  \n",
       "18    8.0  215.0   3.0  14.0    12.0    12.0     2.0  46.0  14.0   47.0  \n",
       "19    9.0  170.0  10.0  35.0    42.0    32.0    51.0  63.0  10.0   44.0  \n",
       "20   11.0  161.0  12.0  50.0    14.0    26.0    51.0  70.0  11.0   57.0  \n",
       "21   23.0   99.0  13.0  63.0    71.0    39.0    71.0  74.0  21.0   78.0  \n",
       "22   20.0  173.0  10.0  19.0     8.0     5.0    21.0  50.0  13.0   43.0  \n",
       "23   18.0  170.0   8.0  25.0     6.0    13.0     8.0  36.0   1.0   36.0  \n",
       "24    5.0  171.0   5.0  26.0    25.0     8.0    13.0  63.0   4.0   69.0  \n",
       "25   11.0  212.0   4.0  50.0    43.0    16.0    25.0  58.0   5.0   38.0  \n",
       "26    9.0  163.0   0.0  31.0     6.0     4.0     5.0  49.0   8.0   38.0  \n",
       "27    6.0  224.0  10.0  45.0    52.0    60.0    12.0  79.0  17.0   33.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ÏÇ¨Ïö©Ìï† Ï†ëÎëêÏñ¥ Î™©Î°ù\n",
    "prefixes = [\"PHQ\", \"STAI_X2\", \"CSM\", \"CTQ-1\", \"CTQ-2\", \"CTQ-3\", \"CTQ-4\", \"CTQ-5\", \"KRQ\", \"MDQ\", \"ACQ\", \"APPQ-1\", \"APPQ-2\", \"APPQ-3\", \"BSQ\", \"GAD\", \"BRIAN\"]\n",
    "# Í≤∞Í≥ºÎ•º Ï†ÄÏû•Ìï† Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ\n",
    "aggregated_df = result[['patient_code', 'ÎÇ†Ïßú']].copy()\n",
    "\n",
    "for prefix in prefixes:\n",
    "    # Ìï¥Îãπ Ï†ëÎëêÏñ¥Î°ú ÏãúÏûëÌïòÎäî Ïª¨Îüº Ï∞æÍ∏∞\n",
    "    matched_cols = [col for col in result.columns if col.startswith(prefix)]\n",
    "    \n",
    "    # Í∞í Ìï©ÏÇ∞Ìï¥ÏÑú ÏÉàÎ°úÏö¥ Ïª¨ÎüºÏúºÎ°ú Ï∂îÍ∞Ä\n",
    "    aggregated_df[f'{prefix.rstrip(\"-\")}'] = result[matched_cols].apply(pd.to_numeric, errors='coerce').sum(axis=1)\n",
    "\n",
    "display(aggregated_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    patient_code         ÎÇ†Ïßú gender\n",
      "0     PXPN_10008 2024-11-04      0\n",
      "1     PXPN_10008 2024-11-05      0\n",
      "2     PXPN_10008 2024-11-06      0\n",
      "3     PXPN_10008 2024-11-07      0\n",
      "4     PXPN_10008 2024-11-08      0\n",
      "..           ...        ...    ...\n",
      "975   PXPN_10046 2025-07-02      0\n",
      "976   PXPN_10046 2025-07-03      0\n",
      "977   PXPN_10046 2025-07-04      0\n",
      "978   PXPN_10046 2025-07-05      0\n",
      "979   PXPN_10046 2025-07-06      0\n",
      "\n",
      "[980 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# ÏóëÏÖÄ ÌååÏùº Í≤ΩÎ°ú\n",
    "file_path = enroll_path\n",
    "\n",
    "# ÏóëÏÖÄ ÏãúÌä∏ ÏùΩÍ∏∞\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ïª¨Îüº Ïù¥Î¶Ñ Î≥ÄÍ≤Ω\n",
    "df = df.rename(columns={'ÌöåÏõêÏΩîÎìú': 'patient_code', '2. ÏÑ±Î≥Ñ': 'gender'})\n",
    "\n",
    "# ÌïÑÏöîÌïú Ïª¨ÎüºÎßå ÏÑ†ÌÉù\n",
    "df = df[['patient_code', 'Ïó∞Íµ¨ÏãúÏûëÏùº', 'Ïó∞Íµ¨Ï¢ÖÎ£åÏùº', 'gender']]\n",
    "\n",
    "# ÎÇ†Ïßú ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò\n",
    "df['Ïó∞Íµ¨ÏãúÏûëÏùº'] = pd.to_datetime(df['Ïó∞Íµ¨ÏãúÏûëÏùº'], errors='coerce')\n",
    "df['Ïó∞Íµ¨Ï¢ÖÎ£åÏùº'] = pd.to_datetime(df['Ïó∞Íµ¨Ï¢ÖÎ£åÏùº'], errors='coerce')\n",
    "\n",
    "# Í∞Å ÌôòÏûêÏóê ÎåÄÌï¥ ÎÇ†Ïßú ÏÉùÏÑ±\n",
    "expanded_rows = []\n",
    "for _, row in df.iterrows():\n",
    "    if pd.notnull(row['Ïó∞Íµ¨ÏãúÏûëÏùº']) and pd.notnull(row['Ïó∞Íµ¨Ï¢ÖÎ£åÏùº']):\n",
    "        date_range = pd.date_range(start=row['Ïó∞Íµ¨ÏãúÏûëÏùº'], end=row['Ïó∞Íµ¨Ï¢ÖÎ£åÏùº'])\n",
    "        for date in date_range:\n",
    "            expanded_rows.append({'patient_code': row['patient_code'], 'ÎÇ†Ïßú': date, 'gender': row['gender']})\n",
    "\n",
    "# Í≤∞Í≥º Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ ÏÉùÏÑ±\n",
    "expanded_df = pd.DataFrame(expanded_rows)\n",
    "expanded_df = expanded_df.replace({'ÎÇ®': '0', 'Ïó¨': '1'})\n",
    "print(expanded_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    patient_code         ÎÇ†Ïßú gender\n",
      "0     PXPN_10008 2024-11-04      0\n",
      "1     PXPN_10008 2024-11-05      0\n",
      "2     PXPN_10008 2024-11-06      0\n",
      "3     PXPN_10008 2024-11-07      0\n",
      "4     PXPN_10008 2024-11-08      0\n",
      "..           ...        ...    ...\n",
      "975   PXPN_10046 2025-07-02      0\n",
      "976   PXPN_10046 2025-07-03      0\n",
      "977   PXPN_10046 2025-07-04      0\n",
      "978   PXPN_10046 2025-07-05      0\n",
      "979   PXPN_10046 2025-07-06      0\n",
      "\n",
      "[980 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# ÏóëÏÖÄ ÌååÏùº Í≤ΩÎ°ú\n",
    "file_path = enroll_path\n",
    "\n",
    "# CSV ÏùΩÍ∏∞\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ïª¨Îüº Ïù¥Î¶Ñ Î≥ÄÍ≤Ω (ÏÉùÎÖÑÏõîÏùº Ïª¨ÎüºÎèÑ Ï∂îÍ∞Ä)\n",
    "df = df.rename(columns={\n",
    "    'ÌöåÏõêÏΩîÎìú': 'patient_code',\n",
    "    '2. ÏÑ±Î≥Ñ': 'gender'  # ÏÉùÎÖÑÏõîÏùº Ïª¨Îüº Ïù¥Î¶ÑÏù¥ Ïã§Ï†ú Îã§Î•¥Î©¥ Ïù¥ Î∂ÄÎ∂Ñ ÏàòÏ†ï ÌïÑÏöî\n",
    "})\n",
    "\n",
    "# ÌïÑÏöîÌïú Ïª¨ÎüºÎßå ÏÑ†ÌÉù\n",
    "df = df[['patient_code', 'Ïó∞Íµ¨ÏãúÏûëÏùº', 'Ïó∞Íµ¨Ï¢ÖÎ£åÏùº', 'gender', '3. ÏÉùÎÖÑÏõîÏùº']]\n",
    "\n",
    "# ÎÇ†Ïßú ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò\n",
    "df['Ïó∞Íµ¨ÏãúÏûëÏùº'] = pd.to_datetime(df['Ïó∞Íµ¨ÏãúÏûëÏùº'], errors='coerce')\n",
    "df['Ïó∞Íµ¨Ï¢ÖÎ£åÏùº'] = pd.to_datetime(df['Ïó∞Íµ¨Ï¢ÖÎ£åÏùº'], errors='coerce')\n",
    "df['3. ÏÉùÎÖÑÏõîÏùº'] = pd.to_datetime(df['3. ÏÉùÎÖÑÏõîÏùº'], errors='coerce')\n",
    "\n",
    "\n",
    "# Í∞Å ÌôòÏûêÏóê ÎåÄÌï¥ ÎÇ†Ïßú ÏÉùÏÑ±\n",
    "expanded_rows = []\n",
    "for _, row in df.iterrows():\n",
    "    if pd.notnull(row['Ïó∞Íµ¨ÏãúÏûëÏùº']) and pd.notnull(row['Ïó∞Íµ¨Ï¢ÖÎ£åÏùº']):\n",
    "        date_range = pd.date_range(start=row['Ïó∞Íµ¨ÏãúÏûëÏùº'], end=row['Ïó∞Íµ¨Ï¢ÖÎ£åÏùº'])\n",
    "        for date in date_range:\n",
    "            expanded_rows.append({\n",
    "                'patient_code': row['patient_code'],\n",
    "                'ÎÇ†Ïßú': date,\n",
    "                'gender': '0' if row['gender'] == 'ÎÇ®' else '1'\n",
    "            })\n",
    "\n",
    "# Í≤∞Í≥º Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ ÏÉùÏÑ±\n",
    "expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Ï∂úÎ†•\n",
    "print(expanded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df['ÎÇ†Ïßú']    = pd.to_datetime(expanded_df['ÎÇ†Ïßú'])\n",
    "aggregated_df['ÎÇ†Ïßú'] = pd.to_datetime(aggregated_df['ÎÇ†Ïßú'])\n",
    "expanded_answer = pd.merge(expanded_df, aggregated_df, on=['patient_code', 'ÎÇ†Ïßú'], how='outer')\n",
    "expanded_answer = expanded_answer.rename(columns={'patient_code': 'ID', 'ÎÇ†Ïßú': 'date', 'GAD': 'GAD_7', 'CTQ-1': 'CTQ_1', 'CTQ-2': 'CTQ_2', 'CTQ-3': 'CTQ_3', 'CTQ-4': 'CTQ_4', 'CTQ-5': 'CTQ_5', 'APPQ-1': 'APPQ_1', 'APPQ-2': 'APPQ_2', 'APPQ-3': 'APPQ_3', 'PHQ': 'PHQ_9'})\n",
    "output_path = os.path.join(output_folder, \"questionnaire_test.csv\")\n",
    "expanded_answer.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Panic.csv ÏóÜÏùå: ActiveData/PXPN_10010_ActiveData.zip\n",
      "‚ö†Ô∏è Panic.csv ÏóÜÏùå: ActiveData/PXPN_10012_ActiveData.zip\n",
      "‚ö†Ô∏è Panic.csv ÏóÜÏùå: ActiveData/PXPN_10023_ActiveData.zip\n",
      "‚ö†Ô∏è Panic.csv ÏóÜÏùå: ActiveData/PXPN_10034_ActiveData.zip\n",
      "‚ö†Ô∏è Panic.csv ÏóÜÏùå: ActiveData/PXPN_10039_ActiveData.zip\n",
      "‚ö†Ô∏è Panic.csv ÏóÜÏùå: ActiveData/PXPN_10040_ActiveData.zip\n"
     ]
    }
   ],
   "source": [
    "# 0. ÎÇ†Ïßú ÌòïÏãù ÌÜµÏùº\n",
    "expanded_answer['date'] = pd.to_datetime(expanded_answer['date'])\n",
    "\n",
    "# 1. PXPNÎ≥Ñ Panic ÎÇ†Ïßú ÏàòÏßë\n",
    "PXPN_panic_dates = pd.DataFrame(columns=['ID', 'date'])\n",
    "main_zip_path = zip_path  # Ïòà: '/Users/.../ActiveData.zip'\n",
    "\n",
    "with zipfile.ZipFile(main_zip_path, 'r') as outer_zip:\n",
    "    for inner_name in outer_zip.namelist():\n",
    "        if inner_name.startswith(\"ActiveData/\") and inner_name.endswith('_ActiveData.zip'):\n",
    "            pid = os.path.basename(inner_name).replace('_ActiveData.zip', '')\n",
    "\n",
    "            with outer_zip.open(inner_name) as inner_file:\n",
    "                data = inner_file.read()\n",
    "                inner_bytes = BytesIO(data)\n",
    "\n",
    "                if not zipfile.is_zipfile(inner_bytes):\n",
    "                    print(f\"‚ùå ÎÇ¥Î∂Ä zip ÏïÑÎãò (Î¨¥ÏãúÎê®): {inner_name}\")\n",
    "                    continue\n",
    "\n",
    "                with zipfile.ZipFile(inner_bytes, 'r') as active_zip:\n",
    "                    panic_csvs = [f for f in active_zip.namelist() if f.endswith('Panic.csv')]\n",
    "                    if not panic_csvs:\n",
    "                        print(f\"‚ö†Ô∏è Panic.csv ÏóÜÏùå: {inner_name}\")\n",
    "                        continue\n",
    "\n",
    "                    with active_zip.open(panic_csvs[0]) as f:\n",
    "                        df_panic = pd.read_csv(f)\n",
    "                        if 'ÏûëÏÑ±Ïùº' not in df_panic.columns:\n",
    "                            print(f\"‚ö†Ô∏è 'ÏûëÏÑ±Ïùº' ÏóÜÏùå: {inner_name}\")\n",
    "                            continue\n",
    "\n",
    "                        for ÏûëÏÑ±Ïùº in df_panic['ÏûëÏÑ±Ïùº']:\n",
    "                            PXPN_panic_dates = pd.concat([\n",
    "                                PXPN_panic_dates,\n",
    "                                pd.DataFrame({'ID': [pid], 'date': [ÏûëÏÑ±Ïùº]})\n",
    "                            ], ignore_index=True)\n",
    "\n",
    "# 2. ÎÇ†Ïßú Î∞è panic Ï†ïÎ¶¨\n",
    "PXPN_panic_dates['panic'] = 2\n",
    "PXPN_panic_dates['date'] = pd.to_datetime(PXPN_panic_dates['date']).dt.strftime('%Y-%m-%d')\n",
    "expanded_answer['date'] = pd.to_datetime(expanded_answer['date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# 3. outer merge\n",
    "merged = pd.merge(\n",
    "    PXPN_panic_dates,\n",
    "    expanded_answer,\n",
    "    on=['ID', 'date'],\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# 4. Ïö∞ÏÑ†ÏàúÏúÑ panic Í∞í Ïú†ÏßÄ\n",
    "merged = (\n",
    "    merged\n",
    "    .sort_values(['ID', 'date', 'panic'], ascending=[True, True, False])\n",
    "    .drop_duplicates(subset=['ID', 'date'], keep='first')\n",
    ")\n",
    "\n",
    "# 5. Ï†ÑÎÇ† panic=1 Ï†ÅÏö©\n",
    "df = merged.copy()\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "for _, row in df[df['panic'] == 2].iterrows():\n",
    "    pid = row['ID']\n",
    "    curr_date = row['date']\n",
    "    prev_date = curr_date - pd.Timedelta(days=1)\n",
    "\n",
    "    # Ïó∞ÏÜçÎêú 2 Ï†úÍ±∞\n",
    "    while ((df['ID'] == pid) & (df['date'] == prev_date) & (df['panic'] == 2)).any():\n",
    "        prev_date -= pd.Timedelta(days=1)\n",
    "\n",
    "    mask = (df['ID'] == pid) & (df['date'] == prev_date)\n",
    "    if mask.any():\n",
    "        df.loc[mask & (df['panic'].fillna(0) < 1), 'panic'] = 1\n",
    "\n",
    "df = df.sort_values(['ID', 'date']).reset_index(drop=True)\n",
    "df['date'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "df['panic'] = df['panic'].fillna(0)\n",
    "\n",
    "# 6. Enroll Î≥ëÌï© (age)\n",
    "enroll_df = pd.read_csv(enroll_path, encoding='utf-8')\n",
    "enroll_df = enroll_df.rename(columns={\n",
    "    'ÌöåÏõêÏΩîÎìú': 'patient_code',\n",
    "    '3. ÏÉùÎÖÑÏõîÏùº': 'birthdate',\n",
    "    'Ïó∞Íµ¨Ï¢ÖÎ£åÏùº': 'end_date'\n",
    "})\n",
    "enroll_df['birthdate'] = pd.to_datetime(enroll_df['birthdate'], errors='coerce')\n",
    "enroll_df['end_date'] = pd.to_datetime(enroll_df['end_date'], errors='coerce')\n",
    "enroll_df['age'] = enroll_df['end_date'].dt.year - enroll_df['birthdate'].dt.year\n",
    "\n",
    "age_df = enroll_df[['patient_code', 'age']].drop_duplicates().rename(columns={'patient_code': 'ID'})\n",
    "final_df = df.merge(age_df, on='ID', how='left')\n",
    "\n",
    "# 7. Ï†ÄÏû•\n",
    "output_path = os.path.join(output_folder, \"questionnaire_and_panic_date.csv\")\n",
    "final_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\3806454974.py:61: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '50' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, 'exercise'] = amount if pd.notna(amount) else 1\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\3806454974.py:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '8' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, 'alcohol'] = amount if pd.notna(amount) else 1\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\3806454974.py:64: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, 'coffee'] = amount if pd.notna(amount) else 1\n",
      "C:\\Users\\cyshi\\AppData\\Local\\Temp\\ipykernel_41456\\3806454974.py:67: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '8' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, 'smoking'] = amount if pd.notna(amount) else 1\n"
     ]
    }
   ],
   "source": [
    "# ÌååÏùº Í≤ΩÎ°ú\n",
    "csv_path = output_path\n",
    "zip_path = zip_path\n",
    "# Îç∞Ïù¥ÌÑ∞ Î∂àÎü¨Ïò§Í∏∞\n",
    "df = pd.read_csv(csv_path)\n",
    "df = df[df[\"ID\"].str.startswith(\"PXPN\")].copy()\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# Ïª¨Îüº Ï¥àÍ∏∞Ìôî\n",
    "for col in ['marriage', 'job', 'alcohol', 'coffee', 'smoking', 'menstruation', 'exercise',\n",
    "            'smkHx', 'drinkHx', 'suicideHx',\n",
    "            'suicide_need']: \n",
    "    df[col] = np.nan\n",
    "\n",
    "# ZIP Ïó¥Í∏∞\n",
    "with zipfile.ZipFile(zip_path, 'r') as outer_zip:\n",
    "    for pid in df['ID'].unique():\n",
    "        inner_zip_name = f\"ActiveData/{pid}_ActiveData.zip\"\n",
    "        if inner_zip_name not in outer_zip.namelist():\n",
    "            continue\n",
    "\n",
    "        # ÎÇ¥Î∂Ä ZIP Ïó¥Í∏∞\n",
    "        with outer_zip.open(inner_zip_name) as inner_zip_file:\n",
    "            inner_zip_bytes = BytesIO(inner_zip_file.read())\n",
    "            with zipfile.ZipFile(inner_zip_bytes) as inner_zip:\n",
    "\n",
    "                # 1. Sociodemographic Ï≤òÎ¶¨\n",
    "                soc_path = f\"{pid}_Sociodemographic.csv\"\n",
    "                if soc_path in inner_zip.namelist():\n",
    "                    soc = pd.read_csv(inner_zip.open(soc_path), header=None, index_col=0).T\n",
    "                    if 'Í≤∞Ìòº' in soc.columns:\n",
    "                        df.loc[df['ID'] == pid, 'marriage'] = 1 if soc['Í≤∞Ìòº'].values[0] == 'Í∏∞Ìòº' else 0\n",
    "                    if 'ÌòÑÏû¨ ÏßÅÏóÖ Ïú†Î¨¥' in soc.columns:\n",
    "                        df.loc[df['ID'] == pid, 'job'] = 1 if soc['ÌòÑÏû¨ ÏßÅÏóÖ Ïú†Î¨¥'].values[0] == 'Y' else 0\n",
    "                    if 'Í≥ºÍ±∞ Ìù°Ïó∞ Ïó¨Î∂Ä' in soc.columns:\n",
    "                        df.loc[df['ID'] == pid, 'smkHx'] = 1 if soc['Í≥ºÍ±∞ Ìù°Ïó∞ Ïó¨Î∂Ä'].values[0] == 'Y' else 0\n",
    "                    if 'ÏßÄÍ∏àÍπåÏßÄ ÏùåÏ£º Ïó¨Î∂Ä' in soc.columns:\n",
    "                        df.loc[df['ID'] == pid, 'drinkHx'] = 1 if soc['ÏßÄÍ∏àÍπåÏßÄ ÏùåÏ£º Ïó¨Î∂Ä'].values[0] == 'Y' else 0\n",
    "                    if 'Í≥ºÍ±∞ ÏûêÏÇ¥ ÏãúÎèÑ Ïó¨Î∂Ä' in soc.columns:\n",
    "                        df.loc[df['ID'] == pid, 'suicideHx'] = 1 if soc['Í≥ºÍ±∞ ÏûêÏÇ¥ ÏãúÎèÑ Ïó¨Î∂Ä'].values[0] == 'Y' else 0\n",
    "                    if 'ÏßÄÎÇú 1Îã¨Í∞Ñ ÏûêÏÇ¥ÏãúÎèÑ Ïó¨Î∂Ä' in soc.columns:\n",
    "                        df.loc[df['ID'] == pid, 'suicide_need'] = 1 if soc['ÏßÄÎÇú 1Îã¨Í∞Ñ ÏûêÏÇ¥ÏãúÎèÑ Ïó¨Î∂Ä'].values[0] == 'Y' else 0\n",
    "\n",
    "\n",
    "                # 2. Pattern Ï≤òÎ¶¨\n",
    "                pat_path = f\"{pid}_Pattern.csv\"\n",
    "                if pat_path in inner_zip.namelist():\n",
    "                    pat = pd.read_csv(inner_zip.open(pat_path))\n",
    "                    pat['ÏûëÏÑ±Ïùº'] = pd.to_datetime(pat['ÏûëÏÑ±Ïùº'], errors='coerce')\n",
    "\n",
    "                    for idx, row in df[df[\"ID\"] == pid].iterrows():\n",
    "                        d = row[\"date\"]\n",
    "                        today_rows = pat[pat[\"ÏûëÏÑ±Ïùº\"] == d]\n",
    "                        for _, r in today_rows.iterrows():\n",
    "                            t = r.get('Ï¢ÖÎ•ò', '')\n",
    "                            st = r.get('ÏÑ∏Î∂ÄÏ¢ÖÎ•ò', '')\n",
    "                            amount = r.get('Ïñë', None)  # 'Ïñë' Ïª¨Îüº Í∞í\n",
    "                            # Ïö¥Îèô\n",
    "                            if t == 'Ïö¥Îèô':\n",
    "                                # Ïñë Í∞íÏù¥ ÏûàÏúºÎ©¥ Í∑∏ Í∞íÏùÑ, ÏóÜÏúºÎ©¥ 1 Î°ú ÎîîÌè¥Ìä∏\n",
    "                                df.at[idx, 'exercise'] = amount if pd.notna(amount) else 1\n",
    "                            # Ïπ¥ÌéòÏù∏\n",
    "                            if t == 'Ïπ¥ÌéòÏù∏':\n",
    "                                df.at[idx, 'coffee'] = amount if pd.notna(amount) else 1\n",
    "                            # Ìù°Ïó∞\n",
    "                            if t == 'Ìù°Ïó∞':\n",
    "                                df.at[idx, 'smoking'] = amount if pd.notna(amount) else 1\n",
    "                            # ÏùåÏ£º(ÏñëÏù¥ ÏïÑÎãå Îã®Ïàú Ïó¨Î∂ÄÎßå ÏõêÌïòÎ©¥ Í∏∞Ï°¥Ï≤òÎüº 1Î°ú)\n",
    "                            if t == 'ÏùåÏ£º':\n",
    "                                df.at[idx, 'alcohol'] = amount if pd.notna(amount) else 1\n",
    "                            # ÏÉùÎ¶¨\n",
    "                            if t == 'ÏÉùÎ¶¨' and st == 'ÏÉùÎ¶¨Ï§ë':\n",
    "                                df.at[idx, 'menstruation'] = 1\n",
    "\n",
    "output_path = os.path.join(output_folder, \"questionnaire_and_panic_dates_and_demo.csv\")\n",
    "df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
    "zip_path = zip_path\n",
    "processed = df  \n",
    "\n",
    "# 3. PXPN ID Î™©Î°ù Ï∂îÏ∂ú\n",
    "pxpn_ids = processed[processed['ID'].astype(str).str.startswith('PXPN')]['ID'].unique()\n",
    "\n",
    "# 4. Í∞êÏ†ï Í¥ÄÎ†® Ïª¨Îüº Ï¥àÍ∏∞Ìôî\n",
    "emotion_cols = ['positive_feeling', 'negative', 'positive_E', 'negative_E', 'anxiety', 'annoying']\n",
    "for col in emotion_cols:\n",
    "    if col not in processed.columns:\n",
    "        processed[col] = np.nan\n",
    "\n",
    "# 5. ÎîîÎ≤ÑÍ∑∏Ïö© Ïπ¥Ïö¥ÌÑ∞ Î∞è Ï†ïÎ≥¥\n",
    "match_count = 0\n",
    "no_date_match = 0\n",
    "processed_ids = set()\n",
    "debug_info = []\n",
    "\n",
    "# 6. Ïô∏Î∂Ä zip Ïó¥Í∏∞\n",
    "try:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as outer_zip:\n",
    "\n",
    "        # 7. Î™®Îì† PXPN IDÏóê ÎåÄÌï¥ Î∞òÎ≥µ\n",
    "        for pid in pxpn_ids:\n",
    "            pid = str(pid).strip()\n",
    "            inner_zip_name = f\"ActiveData/{pid}_ActiveData.zip\"\n",
    "\n",
    "            if inner_zip_name not in outer_zip.namelist():\n",
    "                debug_info.append(f\"‚ùå ID {pid}: ÎÇ¥Î∂Ä ZIP ÏóÜÏùå ‚Üí {inner_zip_name}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                with outer_zip.open(inner_zip_name) as inner_zip_file:\n",
    "                    inner_zip_bytes = BytesIO(inner_zip_file.read())\n",
    "\n",
    "                    with zipfile.ZipFile(inner_zip_bytes) as inner_zip:\n",
    "                        checkup_filename = f\"{pid}_Checkup.csv\"\n",
    "\n",
    "                        if checkup_filename not in inner_zip.namelist():\n",
    "                            debug_info.append(f\"‚ö†Ô∏è ID {pid}: Checkup ÌååÏùº ÏóÜÏùå\")\n",
    "                            continue\n",
    "\n",
    "                        # Checkup CSV ÏùΩÍ∏∞\n",
    "                        checkup = pd.read_csv(inner_zip.open(checkup_filename))\n",
    "\n",
    "                        # ÎÇ†Ïßú ÌÉÄÏûÖ Î≥ÄÌôò\n",
    "                        processed_pid = processed[processed['ID'] == pid].copy()\n",
    "                        processed_pid['date'] = pd.to_datetime(processed_pid['date'], errors='coerce')\n",
    "                        checkup['ÏûëÏÑ±Ïùº'] = pd.to_datetime(checkup['ÏûëÏÑ±Ïùº'], errors='coerce')\n",
    "\n",
    "                        # Í∞êÏ†ï Ïπ¥ÌÖåÍ≥†Î¶¨Î≥Ñ Ï≤òÎ¶¨\n",
    "                        for category in ['Í∏∞Î∂Ñ', 'ÏóêÎÑàÏßÄ', 'Î∂àÏïà', 'ÏßúÏ¶ù']:\n",
    "                            category_data = checkup[checkup['Ï¢ÖÎ•ò'] == category]\n",
    "\n",
    "                            for _, row in category_data.iterrows():\n",
    "                                checkup_date = row['ÏûëÏÑ±Ïùº']\n",
    "                                score = row['Ï≤ôÎèÑ']\n",
    "\n",
    "                                for idx, proc_row in processed_pid.iterrows():\n",
    "                                    proc_date = proc_row['date']\n",
    "                                    if (\n",
    "                                        proc_date.year == checkup_date.year and\n",
    "                                        proc_date.month == checkup_date.month and\n",
    "                                        proc_date.day == checkup_date.day\n",
    "                                    ):\n",
    "                                        if category == 'Í∏∞Î∂Ñ':\n",
    "                                            if score > 0:\n",
    "                                                processed.at[idx, 'positive_feeling'] = score\n",
    "                                            elif score < 0:\n",
    "                                                processed.at[idx, 'negative'] = score\n",
    "                                        elif category == 'ÏóêÎÑàÏßÄ':\n",
    "                                            if score > 0:\n",
    "                                                processed.at[idx, 'positive_E'] = score\n",
    "                                            elif score < 0:\n",
    "                                                processed.at[idx, 'negative_E'] = score\n",
    "                                        elif category == 'Î∂àÏïà':\n",
    "                                            processed.at[idx, 'anxiety'] = score\n",
    "                                        elif category == 'ÏßúÏ¶ù':\n",
    "                                            processed.at[idx, 'annoying'] = score\n",
    "\n",
    "                                        match_count += 1\n",
    "                                        processed_ids.add(pid)\n",
    "            except Exception as e:\n",
    "                debug_info.append(f\"‚ùó ID {pid} Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò: {str(e)}\")\n",
    "except Exception as e:\n",
    "    debug_info.append(f\"ZIP ÌååÏùº Ï≤òÎ¶¨ Ï†ÑÏ≤¥ Ïã§Ìå®: {str(e)}\")\n",
    "\n",
    "\n",
    "# 8. Í∏∞Î∂Ñ Î∞è ÏóêÎÑàÏßÄ Ï∂©Îèå Ï°∞Ï†ï (Ï†àÎåÄÍ∞í Í∏∞Ï§Ä)\n",
    "mask_mood = processed['positive_feeling'].notna() & processed['negative'].notna()\n",
    "for idx in processed[mask_mood].index:\n",
    "    pos = processed.at[idx, 'positive_feeling']\n",
    "    neg = processed.at[idx, 'negative']\n",
    "    if abs(pos) > abs(neg):\n",
    "        processed.at[idx, 'negative'] = 0\n",
    "    elif abs(pos) < abs(neg):\n",
    "        processed.at[idx, 'positive_feeling'] = 0\n",
    "    else:\n",
    "        processed.at[idx, 'positive_feeling'] = 0  # ÎèôÏùºÌïòÎ©¥ Í∏çÏ†ï Ï†úÍ±∞, Î∂ÄÏ†ï Ïú†ÏßÄ\n",
    "\n",
    "mask_energy = processed['positive_E'].notna() & processed['negative_E'].notna()\n",
    "for idx in processed[mask_energy].index:\n",
    "    posE = processed.at[idx, 'positive_E']\n",
    "    negE = processed.at[idx, 'negative_E']\n",
    "    if abs(posE) > abs(negE):\n",
    "        processed.at[idx, 'negative_E'] = 0\n",
    "    elif abs(posE) < abs(negE):\n",
    "        processed.at[idx, 'positive_E'] = 0\n",
    "    else:\n",
    "        processed.at[idx, 'positive_E'] = 0\n",
    "\n",
    "# 9. Í∞íÏù¥ ÌïúÏ™ΩÎßå ÏûàÏùÑ Í≤ΩÏö∞ Îã§Î•∏ Ï™ΩÏùÑ 0ÏúºÎ°ú ÏÑ§Ï†ï\n",
    "processed.loc[\n",
    "    processed['positive_feeling'].notna() & processed['negative'].isna(),\n",
    "    'negative'\n",
    "] = 0\n",
    "processed.loc[\n",
    "    processed['negative'].notna() & processed['positive_feeling'].isna(),\n",
    "    'positive_feeling'\n",
    "] = 0\n",
    "\n",
    "processed.loc[\n",
    "    processed['positive_E'].notna() & processed['negative_E'].isna(),\n",
    "    'negative_E'\n",
    "] = 0\n",
    "processed.loc[\n",
    "    processed['negative_E'].notna() & processed['positive_E'].isna(),\n",
    "    'positive_E'\n",
    "] = 0\n",
    "\n",
    "# 10. ÎîîÎ≤ÑÍ∑∏ Ï∂úÎ†• (ÏµúÎåÄ 20Í∞ú)\n",
    "for info in debug_info[:20]:\n",
    "    print(info)\n",
    "\n",
    "\n",
    "output_path = os.path.join(output_folder, \"questionnaire_panic_demo_mood.csv\")\n",
    "processed.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î™®Îì† Ïª¨Îüº ÌòïÏãù ÌÜµÏùº ÏôÑÎ£å Î∞è Ï†ÄÏû•Îê®.\n"
     ]
    }
   ],
   "source": [
    "from pandas.api.types import is_numeric_dtype, is_string_dtype, is_datetime64_any_dtype\n",
    "\n",
    "# Ï†ÑÏ≤¥ Ïª¨Îüº ÏàúÌöåÌïòÎ©∞ ÌòïÏãù ÌÜµÏùº\n",
    "for col in processed.columns:\n",
    "    if col == 'ID':\n",
    "        processed[col] = processed[col].astype(str).str.strip()\n",
    "    elif col == 'date':\n",
    "        processed[col] = pd.to_datetime(processed[col], errors='coerce')  # Î¨∏ÏûêÏó¥ Ìè¨Ìï® Ïãú ÏûêÎèô Ï≤òÎ¶¨\n",
    "    elif is_datetime64_any_dtype(processed[col]):\n",
    "        processed[col] = pd.to_datetime(processed[col], errors='coerce')  # datetimeÏù¥Î©¥ Í∑∏ÎåÄÎ°ú\n",
    "    elif is_string_dtype(processed[col]):\n",
    "        processed[col] = processed[col].astype(str).str.strip()  # Î¨∏ÏûêÏó¥Ïù¥Î©¥ Ï†ïÎ¶¨\n",
    "    else:\n",
    "        # ÏòàÏô∏Ï†ÅÏù∏ Í≤ΩÏö∞ÎèÑ Î¨∏ÏûêÏó¥Î°ú ÌÜµÏùº\n",
    "        processed[col] = processed[col].astype(str).str.strip()\n",
    "\n",
    "\n",
    "output_path = os.path.join(output_folder, \"processed.csv\")\n",
    "processed.to_csv(output_path, index=False)\n",
    "print(\"Î™®Îì† Ïª¨Îüº ÌòïÏãù ÌÜµÏùº ÏôÑÎ£å Î∞è Ï†ÄÏû•Îê®.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'date', 'panic', 'gender', 'PHQ_9', 'STAI_X2', 'CSM', 'CTQ_1',\n",
      "       'CTQ_2', 'CTQ_3', 'CTQ_4', 'CTQ_5', 'KRQ', 'MDQ', 'ACQ', 'APPQ_1',\n",
      "       'APPQ_2', 'APPQ_3', 'BSQ', 'GAD_7', 'BRIAN', 'age', 'marriage', 'job',\n",
      "       'alcohol', 'coffee', 'smoking', 'menstruation', 'exercise', 'smkHx',\n",
      "       'drinkHx', 'suicideHx', 'suicide_need', 'positive_feeling', 'negative',\n",
      "       'positive_E', 'negative_E', 'anxiety', 'annoying'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(processed.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
