{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70eaa164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fdfc514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from path_utils import get_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6868cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_SYM_DIR = \"./raw_data/SYM\"\n",
    "# 엑셀 파일 경로 (실제 경로로 수정)\n",
    "output_folder_name = \"./tmp/SYM\"\n",
    "SYM1_file_name = \"backup_SYM1.xlsx\"\n",
    "SYM2_file_name = \"backup_SYM2.xlsx\"\n",
    "\n",
    "SYM_raw_paths = [\n",
    "    get_file_path(RAW_SYM_DIR, f\"{SYM1_file_name}\"),\n",
    "    get_file_path(RAW_SYM_DIR, f\"{SYM2_file_name}\"),\n",
    "]\n",
    "output_folder = get_file_path(output_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa5ad3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils_for_preprocessing import load_raw_file, filter_by_valid_ids\n",
    "from functools import reduce\n",
    "import datetime\n",
    "import os \n",
    "\n",
    "start_date = load_raw_file(SYM_raw_paths, sheet_name=\"연구 참여자 기본 정보\")\n",
    "\n",
    "start_date = start_date.rename(columns={'비식별키': 'ID', '연구_동의일': 'start_date'})\n",
    "start_date = start_date[['ID', 'start_date']]\n",
    "start_date['start_date'] = pd.to_datetime(start_date['start_date'], errors='coerce').dt.date\n",
    "output_path = os.path.join(output_folder, \"start_date.csv\")\n",
    "start_date.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499bf289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils_for_preprocessing import load_raw_file, filter_by_valid_ids\n",
    "import datetime\n",
    "import numpy as np\n",
    "# 1. 엑셀 파일 경로 리스트\n",
    "\n",
    "# 2. “공황일지” 시트를 모두 불러와 합치기\n",
    "sdm = load_raw_file(SYM_raw_paths, sheet_name='생활패턴-흡연,식사,생리')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ——— 2. 이진 변수 변환 ———\n",
    "# 생리 여부 Y → 1, else 0\n",
    "sdm['생리'] = np.where(sdm['생리'] == 'Y', 1, np.nan)\n",
    "# 야식 여부 Y → 1, else 0\n",
    "sdm['야식'] = np.where(sdm['야식'] == 'Y', 1, 0)\n",
    "\n",
    "# ——— 3. 불필요 컬럼 제거 ———\n",
    "sdm.drop(\n",
    "    columns=['아침식사','점심식사','저녁식사','오전간식','오후간식'],\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# ——— 4. 컬럼명 정리 ———\n",
    "sdm = sdm.rename(columns={\n",
    "    '비식별키': 'ID',\n",
    "    '날짜': 'date',\n",
    "    '흡연량': 'smoking',\n",
    "    '야식': 'late_night_snack',\n",
    "    '생리': 'menstruation'\n",
    "})[['ID','date','smoking','late_night_snack','menstruation']].copy()\n",
    "sdm = filter_by_valid_ids(sdm, id_column='ID')\n",
    "# ——— 5. 인덱스 리셋 & 결과 저장 ———\n",
    "sdm.reset_index(drop=True, inplace=True)\n",
    "output_path = os.path.join(output_folder, \"smoking_diet_mens.csv\")\n",
    "sdm.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aae62a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용할 측정값 컬럼: 측정값(_1_:_값_없음,_0_:_알수_없는_수면,_1_:_깨어남,_2_:_램_수면,_3_:_얕은_수면,_4_:_깊은_수면)\n",
      "           ID       date  SLT1      SLT2  SLT3      SLT4      SLT5      SLT6  \\\n",
      "0  SYM1-1-100 2021-03-19   0.0  8.000000   0.0  0.000000  0.000000  0.000000   \n",
      "1  SYM1-1-100 2021-08-12   0.9  0.000000   0.0  3.683333  1.225000  1.516667   \n",
      "2  SYM1-1-103 2021-02-17   0.0  0.000000   0.0  5.333333  1.833333  0.000000   \n",
      "3  SYM1-1-103 2021-02-18   0.0  4.250000   0.0  2.450000  0.566667  0.000000   \n",
      "4  SYM1-1-103 2021-02-19   0.0  0.000000   0.0  6.166667  1.566667  0.000000   \n",
      "5  SYM1-1-103 2021-02-23   0.0  0.033333   0.0  0.000000  0.000000  0.000000   \n",
      "6  SYM1-1-103 2021-03-04   0.0  7.000000   0.0  0.000000  0.000000  0.000000   \n",
      "7  SYM1-1-103 2021-03-06   0.0  0.000000   0.0  0.033333  0.000000  0.000000   \n",
      "8  SYM1-1-103 2021-03-08   0.0  4.766667   0.0  1.816667  0.000000  0.000000   \n",
      "9  SYM1-1-103 2021-04-20   0.0  0.000000   0.0  3.050000  0.000000  0.000000   \n",
      "\n",
      "   total_sleep  \n",
      "0     8.000000  \n",
      "1     7.325000  \n",
      "2     7.166667  \n",
      "3     7.266667  \n",
      "4     7.733333  \n",
      "5     0.033333  \n",
      "6     7.000000  \n",
      "7     0.033333  \n",
      "8     6.916667  \n",
      "9     5.750000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils_for_preprocessing import load_raw_file, filter_by_valid_ids\n",
    "\n",
    "# 2. “생활패턴-음주” 시트를 모두 불러와 합치기\n",
    "sleep_raw = load_raw_file(SYM_raw_paths, sheet_name=\"라이프로그-수면\")\n",
    "\n",
    "sleep_raw = filter_by_valid_ids(sleep_raw, id_column=\"비식별키\")\n",
    "\n",
    "\n",
    "# 4) 날짜 컬럼 datetime으로 변환하고 normalize\n",
    "sleep_raw['날짜'] = pd.to_datetime(sleep_raw['날짜'], errors='coerce').dt.normalize()\n",
    "\n",
    "# 5) 측정값 컬럼명 자동 탐색\n",
    "measure_cols = [col for col in sleep_raw.columns if '측정값' in col]\n",
    "if not measure_cols:\n",
    "    raise KeyError(\"측정값 컬럼을 찾을 수 없습니다. 컬럼명을 확인하세요.\")\n",
    "# 여러 개 있으면 첫 번째를 사용\n",
    "measure_col = measure_cols[0]\n",
    "\n",
    "print(\"사용할 측정값 컬럼:\", measure_col)\n",
    "\n",
    "# 5.5) 동일한 ID, 날짜에 대해 측정값 이어붙이기\n",
    "sleep_raw = sleep_raw.groupby(['비식별키', '날짜'], as_index=False).agg({\n",
    "    measure_col: lambda x: ','.join(x.dropna().astype(str)),\n",
    "    '취침시간': 'first',\n",
    "    '기상시간': 'first'\n",
    "})\n",
    "\n",
    "# 6) SLT별 누적 시간을 계산하는 함수\n",
    "def calc_slt_times(row):\n",
    "    raw = row[measure_col]\n",
    "    # 쉼표로 구분된 문자열 → 정수 리스트\n",
    "    vals = [int(x) for x in str(raw).split(',') if x != '']\n",
    "    # 개수 세기\n",
    "    count_0 = vals.count(0)  # SLT2\n",
    "    count_1 = vals.count(1)  # SLT1\n",
    "    count_2 = vals.count(2)  # SLT6\n",
    "    count_3 = vals.count(3)  # SLT4\n",
    "    count_4 = vals.count(4)  # SLT5\n",
    "    # SLT3은 해당값 없음\n",
    "    count_5 = 0\n",
    "\n",
    "    # 30초 단위 → 시간(시간 단위)\n",
    "    slt1_h = count_1 * 30 / 3600\n",
    "    slt2_h = count_0 * 30 / 3600\n",
    "    slt3_h = 0\n",
    "    slt4_h = count_3 * 30 / 3600\n",
    "    slt5_h = count_4 * 30 / 3600\n",
    "    slt6_h = count_2 * 30 / 3600\n",
    "\n",
    "    return pd.Series({\n",
    "        'SLT1': slt1_h,\n",
    "        'SLT2': slt2_h,\n",
    "        'SLT3': slt3_h,\n",
    "        'SLT4': slt4_h,\n",
    "        'SLT5': slt5_h,\n",
    "        'SLT6': slt6_h\n",
    "    })\n",
    "\n",
    "# 7) calc_slt_times를 df_filtered에 적용\n",
    "slt_times = sleep_raw.apply(calc_slt_times, axis=1)\n",
    "\n",
    "# 8) 필요한 컬럼(ID, 날짜, 취침시간, 기상시간)과 SLT 결과 합치기\n",
    "df_final = pd.concat([\n",
    "    sleep_raw[['비식별키', '날짜', '취침시간', '기상시간']]\n",
    "        .rename(columns={'비식별키': 'ID', '날짜': 'date'})\n",
    "        .reset_index(drop=True),\n",
    "    slt_times.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "# 9) 'ID'·'date' 순으로 정렬\n",
    "df_final = df_final.sort_values(['ID', 'date']).reset_index(drop=True)\n",
    "\n",
    "# Convert 취침시간 and 기상시간 to datetime and compute total_sleep\n",
    "df_final['취침시간'] = pd.to_datetime(df_final['취침시간'], errors='coerce')\n",
    "df_final['기상시간'] = pd.to_datetime(df_final['기상시간'], errors='coerce')\n",
    "df_final['total_sleep'] = (df_final['기상시간'] - df_final['취침시간']).dt.total_seconds() / 3600\n",
    "# Drop 취침시간 and 기상시간 columns\n",
    "df_final.drop(columns=['취침시간', '기상시간'], inplace=True)\n",
    "\n",
    "# 10) 결과 확인 (상위 10행 출력)\n",
    "print(df_final.head(10))\n",
    "\n",
    "output_path = os.path.join(output_folder, \"sleep_summary.csv\")\n",
    "df_final.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e099522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils_for_preprocessing import load_raw_file, filter_by_valid_ids\n",
    "from functools import reduce\n",
    "\n",
    "def extract_questionnaire_from_raw(path, questionnaire_sheet, df_name, questionnaire_column):\n",
    "    df = load_raw_file(path, sheet_name=questionnaire_sheet)\n",
    "    # Load 비식별키, 설문시작일, 설문완료일, and questionnaire_column\n",
    "    df = df[['비식별키', '설문시작일', '설문완료일', questionnaire_column]]\n",
    "    # Filter to keep only rows where 설문완료일 is not null\n",
    "    df = df[pd.notnull(df['설문완료일'])].copy()\n",
    "    # Use 설문시작일 as date\n",
    "    df = df[['비식별키', '설문시작일', questionnaire_column, '설문완료일']]\n",
    "    # Drop the 설문완료일 column\n",
    "    df.drop(['설문완료일'], axis=1, inplace=True)\n",
    "    # Rename columns to [\"ID\", \"date\", df_name]\n",
    "    df.columns = [\"ID\", \"date\", df_name]\n",
    "    df.drop_duplicates(['ID','date'], keep='last', inplace=True, ignore_index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ——— 1. 각 설문지별 시트 이름과 문항 컬럼 매핑 ———\n",
    "questionnaire_specs = {\n",
    "    'BRIAN':  ('22생물학적 리듬',    '1.생물학적_리듬_평가_척도_1번_히든_그룹_합산'),\n",
    "    'CSM':    ('20아침형-저녁형', '1.조합_척도_1~13번_문항_점수_합산'),\n",
    "    'CTQ_1':  ('27유년기 외상',       '1.유년기_외상_척도_요인1._정서방임_점수_합산'),\n",
    "    'CTQ_2':  ('27유년기 외상',       '2.유년기_외상_척도_요인2._신체학대_점수_합산'),\n",
    "    'CTQ_3':  ('27유년기 외상',       '3.유년기_외상_척도_요인3._성학대_점수_합산'),\n",
    "    'CTQ_4':  ('27유년기 외상',       '4.유년기_외상_척도_요인4._정서학대_점수_합산'),\n",
    "    'CTQ_5':  ('27유년기 외상',       '5.유년기_외상_척도_요인5._신체방임_점수_합산'),\n",
    "    'KRQ':    ('13회복탄력성',              '1.회복탄력성_척도_1번_그룹_점수_합산'),\n",
    "    'MDQ':    ('2기분 장애',          '1.기분_장애_척도_1번_그룹_점수_합산'),\n",
    "    'SPAQ_1': ('21계절성 양상',             '1.계절성_양상_척도_2번_그룹_점수_합산'),\n",
    "    'SPAQ_2': ('21계절성 양상',             '2.계절성_양상_척도_3번_문항_점수'),\n",
    "    'STAI_X2':('5특성 불안',           '1.특성_불안_척도_1번_그룹_점수_합산'),\n",
    "    'ACQ':    ('9광장공포인지', '1.광장공포_인지_척도_1번_그룹_점수_합산'),\n",
    "    'APPQ_1': ('11공황-공포',         '1.알바니_공포_공황_척도_요인1._광장공포_점수_합계'),\n",
    "    'APPQ_2': ('11공황-공포',         '2.알바니_공포_공황_척도_요인2._사회공포_점수_합계'),\n",
    "    'APPQ_3': ('11공황-공포',         '3.알바니_공포_공황_척도_요인3._내부감각두려움_점수_합계'),\n",
    "    'BSQ':    ('10신체감각','1.신체감각_척도_1번_그룹_점수_합산'),\n",
    "    'BFNE':   ('6부정적평가에 대한 두려움','1.두려움_척도_1번_그룹_점수_합산'),\n",
    "    'CES_D':  ('32우울증',         '1.우울_척도_개정판_1번_그룹_점수_합산'),\n",
    "    'GAD_7':  ('8범불안 장애','1.범불안_장애_척도_1번_그룹_점수_합산'),\n",
    "    'KOSSSF': ('12직무스트레스',         '1.직무스트레스_단축형_척도_1번_그룹_점수_합산'),\n",
    "    'PHQ_9':  ('1우울증 선별','1.우울증_척도_1번_그룹_점수_합산'),\n",
    "    'SADS':   ('7사회적회피 및 불편감','1.사회적_회피_및_불편감_척도_1번_그룹_점수_합산'),\n",
    "    'STAI_X1':('4상태 불안',       '1.불안_척도_1번_그룹_점수_합산'),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# ——— 2. SYM1·SYM2 파일에서 같은 설문지만 모아오는 함수 ———\n",
    "def extract_multi(path, sheet_name, df_name, questionnaire_col):\n",
    "    dfs = []\n",
    "    for p in path:\n",
    "        df = extract_questionnaire_from_raw(\n",
    "            path=p,\n",
    "            questionnaire_sheet=sheet_name,\n",
    "            df_name=df_name,\n",
    "            questionnaire_column=questionnaire_col\n",
    "        )\n",
    "        dfs.append(df)\n",
    "    # 동일 ID·date 중복 시 마지막 값을 남기고 제거\n",
    "    return pd.concat(dfs, ignore_index=True) \\\n",
    "             .drop_duplicates(subset=['ID','date'], keep='last')\n",
    "\n",
    "# ——— 3. 각 설문지 데이터 로드 ———\n",
    "loaded = {}\n",
    "for name, (sheet, col) in questionnaire_specs.items():\n",
    "    loaded[name] = extract_multi(SYM_raw_paths, sheet, name, col)\n",
    "\n",
    "# ——— 4. 날짜 컬럼 datetime 변환 ———\n",
    "for df in loaded.values():\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "# ——— 5. 여러 설문지 병합 (outer join) ———\n",
    "questionnaire_bydate = reduce(\n",
    "    lambda left, right: pd.merge(left, right, on=['ID','date'], how='outer'),\n",
    "    loaded.values()\n",
    ")\n",
    "\n",
    "# ——— 6. 수치형 변환 ———\n",
    "for col in loaded.keys():\n",
    "    questionnaire_bydate[col] = pd.to_numeric(questionnaire_bydate[col], errors='coerce')\n",
    "\n",
    "# ——— 7. 결과 저장 (CSV) ———\n",
    "questionnaire_bydate = filter_by_valid_ids(questionnaire_bydate, id_column=\"ID\")\n",
    "output_path = os.path.join(output_folder, \"questionnaire.csv\")\n",
    "questionnaire_bydate.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "302b0164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils_for_preprocessing import load_raw_file, filter_by_valid_ids\n",
    "\n",
    "# 2. “공황일지” 시트를 모두 불러와 합치기\n",
    "panic_raw = load_raw_file(SYM_raw_paths, sheet_name=\"공황일지\")\n",
    "\n",
    "# 3. 필요한 컬럼을 동적으로 찾기\n",
    "cols = panic_raw.columns.tolist()\n",
    "\n",
    "# - ID: “비식별키” 포함\n",
    "id_col = next((c for c in cols if \"비식별키\" in c), None)\n",
    "# - date: “날짜” 포함\n",
    "date_col = next((c for c in cols if \"날짜\" in c or \"Date\" in c), None)\n",
    "# - severity(강도): “강도” 또는 “Severity” 포함\n",
    "severity_col = next((c for c in cols if \"강도\" in c or \"Severity\" in c), None)\n",
    "\n",
    "# 4. 컬럼 존재 여부 확인\n",
    "missing = [name for name, col in [(\"ID\", id_col), (\"date\", date_col), (\"severity\", severity_col)]\n",
    "           if col is None]\n",
    "if missing:\n",
    "    raise KeyError(f\"다음 필수 컬럼을 찾을 수 없습니다: {missing}\\n실제 컬럼명: {cols}\")\n",
    "\n",
    "# 5. ID, date, severity 컬럼만 추출\n",
    "\n",
    "panic = panic_raw[[id_col, date_col, severity_col]].copy()\n",
    "\n",
    "# 6. 날짜를 YYYY-MM-DD 문자열로 변환\n",
    "panic['date'] = pd.to_datetime(panic[date_col], errors='coerce').dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 7. panic = 2로 일괄 설정 (데이터가 존재하면 공황 기록이 있다는 의미)\n",
    "panic['panic'] = 2\n",
    "\n",
    "# 8. 컬럼 이름 통일\n",
    "panic.rename(columns={\n",
    "    id_col: 'ID',\n",
    "    severity_col: 'severity'\n",
    "}, inplace=True)\n",
    "\n",
    "# 9. 이제 필요한 최종 컬럼 순서만 남기기\n",
    "panic = panic[['ID', 'date', 'panic', 'severity']]\n",
    "# 10. 유효한 ID만 남기기\n",
    "panic = filter_by_valid_ids(panic, id_column=\"ID\")\n",
    "# 11. 같은 ID, date에 중복된 행이 있을 경우 severity와 panic의 최대값만 남기기\n",
    "panic = panic.groupby(['ID', 'date'], as_index=False).agg({\n",
    "    'panic': 'max',\n",
    "    'severity': 'max'\n",
    "})\n",
    "\n",
    "output_path = os.path.join(output_folder, \"panic_by_date.csv\")\n",
    "panic.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bbb5f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils_for_preprocessing import load_raw_file, filter_by_valid_ids\n",
    "\n",
    "# 2. “생활패턴-음주” 시트를 모두 불러와 합치기\n",
    "alcohol_raw = load_raw_file(SYM_raw_paths, sheet_name=\"생활패턴-운동\")\n",
    "\n",
    "# 3. ID와 날짜 컬럼을 동적으로 찾기\n",
    "id_col = next((c for c in alcohol_raw.columns if \"비식별키\" in c), None)\n",
    "date_col = next((c for c in alcohol_raw.columns if \"날짜\" in c), None)\n",
    "\n",
    "if id_col is None:\n",
    "    raise KeyError(f\"ID 컬럼('비식별키' 포함)을 찾지 못했습니다. 가능한 컬럼: {alcohol_raw.columns.tolist()}\")\n",
    "if date_col is None:\n",
    "    raise KeyError(f\"날짜 컬럼('날짜' 포함)을 찾지 못했습니다. 가능한 컬럼: {alcohol_raw.columns.tolist()}\")\n",
    "\n",
    "# 운동시간(분) 컬럼 찾기\n",
    "amount_col = next((c for c in alcohol_raw.columns if '운동시간' in c), None)\n",
    "if amount_col is None:\n",
    "    raise KeyError(f\"운동시간(분) 컬럼을 찾지 못했습니다. 가능한 컬럼: {alcohol_raw.columns.tolist()}\")\n",
    "\n",
    "# 4. ID, 날짜, 운동시간 컬럼만 추출\n",
    "df = alcohol_raw[[id_col, date_col, amount_col]].copy()\n",
    "\n",
    "# 5. 날짜를 YYYY-MM-DD 문자열로 변환\n",
    "df['date'] = pd.to_datetime(df[date_col], errors='coerce').dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 6. 컬럼명을 통일하여 ['ID', 'date', 'exercise']로 이름 변경\n",
    "df = df.rename(columns={id_col: 'ID', amount_col: 'exercise'})\n",
    "\n",
    "# 7. 한 사람(비식별키)이 특정 날짜에 음주 기록이 있으면 alcohol=1, 없으면 해당 행이 존재하지 않음\n",
    "#    → 즉, 중복 제거만 하면 한 ID/날짜당 한 행이 남고, alcohol 컬럼을 1로 설정\n",
    "df = df.drop_duplicates(subset=['ID', 'date'], ignore_index=True)\n",
    "\n",
    "# 8. 최종 컬럼 순서: ['ID', 'date', 'exercise']\n",
    "df = df[['ID', 'date', 'exercise']]\n",
    "df = filter_by_valid_ids(df, id_column='ID')\n",
    "\n",
    "output_path = os.path.join(output_folder, \"exercise_per_date.csv\")\n",
    "df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e5a6200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'gender', 'ht', 'wt', 'marriage', 'job', 'smkHx', 'drinkHx',\n",
      "       'suicideHx', 'suicide_need_in_month', 'medication_in_month', 'age'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from utils_for_preprocessing import load_raw_file, filter_by_valid_ids\n",
    "\n",
    "\n",
    "# 2. “연구 참여자 기본 정보” 시트를 모두 불러와 합치기\n",
    "raw = load_raw_file(SYM_raw_paths, sheet_name=\"연구 참여자 기본 정보\")\n",
    "\n",
    "# 3. 필요한 컬럼을 동적으로 찾기\n",
    "cols = raw.columns.tolist()\n",
    "\n",
    "# - ID: “비식별키” 포함\n",
    "id_col = next((c for c in cols if \"비식별\" in c), None)\n",
    "\n",
    "# - Date_of_birth: “Date_of_birth” 또는 “Birth” 등 날짜 포함\n",
    "dob_col = next((c for c in cols if \"Date_of_birth\" in c or \"생년월일\" in c), None)\n",
    "\n",
    "# - Gender: “Gender” 또는 “성별”\n",
    "gender_col = next((c for c in cols if \"Gender\" in c or \"성별\" in c), None)\n",
    "\n",
    "ht_col = next(\n",
    "    (c for c in cols\n",
    "     if ((\"height\" in c or \"키\" in c) and \"비식별\" not in c)),\n",
    "    None\n",
    ")\n",
    "\n",
    "# - Weight: “Weight” 또는 “체중”\n",
    "wt_col = next((c for c in cols if \"Weight\" in c or \"몸무게\" in c), None)\n",
    "\n",
    "# - Marriage: “Marital” 또는 “혼인” 등\n",
    "marriage_col = next((c for c in cols if \"Marital\" in c or \"결혼\" in c), None)\n",
    "\n",
    "# - Job: “Occupation” 또는 “직업”\n",
    "job_col = next((c for c in cols if \"Occupation\" in c or \"직업\" in c), None)\n",
    "\n",
    "# - Smoker history: “Smoker” 또는 “Smoking” 등\n",
    "smkHx_col = next((c for c in cols if \"Smoker\" in c or \"과거_흡연_여부\" in c), None)\n",
    "\n",
    "# - Drinker history: “Drinker” 또는 “Drinking” 등\n",
    "drinkHx_col = next((c for c in cols if \"Drinker\" in c or \"음주_여부\" in c), None)\n",
    "\n",
    "# - Suicide history: “Suicide_history” 또는 “자살” 등\n",
    "suicideHx_col = next(\n",
    "    (c for c in cols\n",
    "     if ((\"Suicide_history\" in c or \"자살_시도_여부\" in c) and \"1달\" not in c)),\n",
    "    None\n",
    ")\n",
    "\n",
    "# - Suicide ideation in past month: “Suicide_ideation” 또는 “Self_harm” 등\n",
    "suicide_need_col = next((c for c in cols if \"Suicide_ideation\" in c or \"자살_시도_욕구\" in c), None)\n",
    "\n",
    "# - Medication in past month: “Medication_history” 또는 “Medication” 등\n",
    "medication_col = next((c for c in cols if \"Medication_history\" in c or \"처방약_여부\" in c), None)\n",
    "\n",
    "# - Consent date: “연구 동의일” 또는 유사 컬럼명\n",
    "consent_col = next((c for c in cols if \"동의\" in c and (\"연구\" in c or \"동의일\" in c)), None)\n",
    "\n",
    "# 4. 칼럼 존재 여부 확인\n",
    "\n",
    "required = {\n",
    "    \"ID\": id_col,\n",
    "    \"Date_of_birth\": dob_col,\n",
    "    \"Gender\": gender_col,\n",
    "    \"Height\": ht_col,\n",
    "    \"Weight\": wt_col,\n",
    "    \"Marriage\": marriage_col,\n",
    "    \"Job\": job_col,\n",
    "    \"Smoker_history\": smkHx_col,\n",
    "    \"Drinker_history\": drinkHx_col,\n",
    "    \"Suicide_history\": suicideHx_col,\n",
    "    \"Suicide_ideation\": suicide_need_col,\n",
    "    \"Medication_history\": medication_col,\n",
    "    \"Consent_date\": consent_col,\n",
    "}\n",
    "\n",
    "missing = [name for name, col in required.items() if col is None]\n",
    "if missing:\n",
    "    raise KeyError(f\"다음 필수 컬럼을 찾을 수 없습니다: {missing}\\n실제 컬럼명: {cols}\")\n",
    "\n",
    "# 5. 필요한 컬럼만 골라서 복사\n",
    "demographic_data = raw[\n",
    "    [\n",
    "        id_col,\n",
    "        dob_col,\n",
    "        gender_col,\n",
    "        ht_col,\n",
    "        wt_col,\n",
    "        marriage_col,\n",
    "        job_col,\n",
    "        smkHx_col,\n",
    "        drinkHx_col,\n",
    "        suicideHx_col,\n",
    "        suicide_need_col,\n",
    "        medication_col,\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "# 6. '생년월일' 컬럼명을 'Date_of_birth'로 변경\n",
    "demographic_data.rename(columns={dob_col: \"Date_of_birth\"}, inplace=True)\n",
    "\n",
    "# 7. Date_of_birth → datetime64로 변환 (형식: YYYYMMDD)\n",
    "demographic_data[\"Date_of_birth\"] = pd.to_datetime(\n",
    "    demographic_data[\"Date_of_birth\"],\n",
    "    format=\"%Y%m%d\",\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "# 변환 실패한 항목은 NaT가 되며, 이후 계산 시 주의\n",
    "\n",
    "# Convert consent date column to datetime\n",
    "if consent_col is None:\n",
    "    raise KeyError(\"필수 컬럼 '연구 동의일'을 찾을 수 없습니다. 실제 컬럼명: {}\".format(cols))\n",
    "demographic_data[\"Consent_date\"] = pd.to_datetime(\n",
    "    raw[consent_col], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# 8. 오늘 날짜 기준으로 나이(age) 계산\n",
    "# Compute age at consent date\n",
    "consent_dates = demographic_data[\"Consent_date\"].dt.date\n",
    "birth_dates = demographic_data[\"Date_of_birth\"].dt.date\n",
    "years_diff = consent_dates.apply(lambda d: d.year) - demographic_data[\"Date_of_birth\"].dt.year\n",
    "adjust = ((demographic_data[\"Consent_date\"].dt.month < demographic_data[\"Date_of_birth\"].dt.month)\n",
    "          | ((demographic_data[\"Consent_date\"].dt.month == demographic_data[\"Date_of_birth\"].dt.month)\n",
    "             & (demographic_data[\"Consent_date\"].dt.day < demographic_data[\"Date_of_birth\"].dt.day))\n",
    "         ).astype(int)\n",
    "ages = (years_diff - adjust).fillna(0).astype(int)\n",
    "\n",
    "# 9. 'age' 컬럼으로 삽입\n",
    "demographic_data[\"age\"] = ages\n",
    "\n",
    "# 10. 이후 더 이상 'Date_of_birth'와 'Consent_date' 컬럼은 필요 없으니 삭제\n",
    "demographic_data.drop(columns=[\"Date_of_birth\", \"Consent_date\"], inplace=True)\n",
    "\n",
    "# 11. 컬럼명 개별 매핑\n",
    "demographic_data.rename(columns={\n",
    "    id_col: \"ID\",\n",
    "    gender_col: \"gender\",\n",
    "    ht_col: \"ht\",\n",
    "    wt_col: \"wt\",\n",
    "    marriage_col: \"marriage\",\n",
    "    job_col: \"job\",\n",
    "    smkHx_col: \"smkHx\",\n",
    "    drinkHx_col: \"drinkHx\",\n",
    "    suicideHx_col: \"suicideHx\",\n",
    "    suicide_need_col: \"suicide_need_in_month\",\n",
    "    medication_col: \"medication_in_month\"\n",
    "}, inplace=True)\n",
    "# 'age' 컬럼은 이미 올바른 이름이므로 그대로 둡니다.\n",
    "\n",
    "# 12. 범주형 변수를 1/0으로 변환\n",
    "demographic_data[\"marriage\"] = demographic_data[\"marriage\"].astype(str).str.upper().eq(\"Y\").astype(int)\n",
    "demographic_data[\"job\"] = demographic_data[\"job\"].astype(str).str.upper().eq(\"Y\").astype(int)\n",
    "demographic_data[\"smkHx\"] = demographic_data[\"smkHx\"].astype(str).str.upper().eq(\"Y\").astype(int)\n",
    "demographic_data[\"drinkHx\"] = demographic_data[\"drinkHx\"].astype(str).str.upper().eq(\"Y\").astype(int)\n",
    "demographic_data[\"suicideHx\"] = demographic_data[\"suicideHx\"].astype(str).str.upper().eq(\"Y\").astype(int)\n",
    "demographic_data[\"suicide_need_in_month\"] = (\n",
    "    demographic_data[\"suicide_need_in_month\"].astype(str).str.upper().eq(\"Y\").astype(int)\n",
    ")\n",
    "demographic_data[\"medication_in_month\"] = (\n",
    "    demographic_data[\"medication_in_month\"].astype(str).str.upper().eq(\"Y\").astype(int)\n",
    ")\n",
    "demographic_data[\"gender\"] = demographic_data[\"gender\"].astype(str).str.upper().map({\"M\": 1, \"F\": 0}).fillna(0).astype(int)\n",
    "\n",
    "# 13. 유효한 ID만 필터링\n",
    "print(demographic_data.columns)\n",
    "demographic_data = filter_by_valid_ids(demographic_data, id_column=\"ID\")\n",
    "\n",
    "# 14. 인덱스 리셋 및 저장\n",
    "demographic_data.reset_index(drop=True, inplace=True)\n",
    "output_path = os.path.join(output_folder, \"demographic_data.csv\")\n",
    "demographic_data.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47aae307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils_for_preprocessing import load_raw_file, filter_by_valid_ids\n",
    "\n",
    "# 2. “생활패턴-음주” 시트를 모두 불러와 합치기\n",
    "alcohol_raw = load_raw_file(SYM_raw_paths, sheet_name=\"생활패턴-카페인\")\n",
    "\n",
    "# 3. ID와 날짜 컬럼을 동적으로 찾기\n",
    "id_col = next((c for c in alcohol_raw.columns if \"비식별키\" in c), None)\n",
    "date_col = next((c for c in alcohol_raw.columns if \"날짜\" in c), None)\n",
    "\n",
    "if id_col is None:\n",
    "    raise KeyError(f\"ID 컬럼('비식별키' 포함)을 찾지 못했습니다. 가능한 컬럼: {alcohol_raw.columns.tolist()}\")\n",
    "if date_col is None:\n",
    "    raise KeyError(f\"날짜 컬럼('날짜' 포함)을 찾지 못했습니다. 가능한 컬럼: {alcohol_raw.columns.tolist()}\")\n",
    "\n",
    "# 섭취량 컬럼 찾기\n",
    "amount_col = next((c for c in alcohol_raw.columns if '섭취량' in c), None)\n",
    "if amount_col is None:\n",
    "    raise KeyError(f\"섭취량 컬럼('섭취량' 포함)을 찾지 못했습니다. 가능한 컬럼: {alcohol_raw.columns.tolist()}\")\n",
    "\n",
    "# 4. ID와 날짜만 추출\n",
    "df = alcohol_raw[[id_col, date_col, amount_col]].copy()\n",
    "\n",
    "# 5. 날짜를 YYYY-MM-DD 문자열로 변환\n",
    "df['date'] = pd.to_datetime(df[date_col], errors='coerce').dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 6. 컬럼명을 통일하여 ['ID', 'date']로 이름 변경\n",
    "df = df.rename(columns={id_col: 'ID', amount_col: 'coffee'})\n",
    "\n",
    "# 7. 한 사람(비식별키)이 특정 날짜에 음주 기록이 있으면 alcohol=1, 없으면 해당 행이 존재하지 않음\n",
    "#    → 즉, 중복 제거만 하면 한 ID/날짜당 한 행이 남고, alcohol 컬럼을 1로 설정\n",
    "df = df.drop_duplicates(subset=['ID', 'date'], ignore_index=True)\n",
    "\n",
    "# 8. 최종 컬럼 순서: ['ID', 'date', 'alcohol']\n",
    "df = df[['ID', 'date', 'coffee']]\n",
    "df = filter_by_valid_ids(df, id_column='ID')\n",
    "\n",
    "output_path = os.path.join(output_folder, \"coffee_per_date.csv\")\n",
    "df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38906c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils_for_preprocessing import load_raw_file, filter_by_valid_ids\n",
    "\n",
    "\n",
    "# 2. “생활패턴-음주” 시트를 모두 불러와 합치기\n",
    "alcohol_raw = load_raw_file(SYM_raw_paths, sheet_name=\"생활패턴-음주\")\n",
    "\n",
    "# 3. ID와 날짜 컬럼을 동적으로 찾기\n",
    "id_col = next((c for c in alcohol_raw.columns if \"비식별키\" in c), None)\n",
    "date_col = next((c for c in alcohol_raw.columns if \"날짜\" in c), None)\n",
    "\n",
    "if id_col is None:\n",
    "    raise KeyError(f\"ID 컬럼('비식별키' 포함)을 찾지 못했습니다. 가능한 컬럼: {alcohol_raw.columns.tolist()}\")\n",
    "if date_col is None:\n",
    "    raise KeyError(f\"날짜 컬럼('날짜' 포함)을 찾지 못했습니다. 가능한 컬럼: {alcohol_raw.columns.tolist()}\")\n",
    "\n",
    "# 음주량 컬럼 찾기\n",
    "amount_col = next((c for c in alcohol_raw.columns if '음주량' in c), None)\n",
    "if amount_col is None:\n",
    "    raise KeyError(f\"음주량 컬럼('음주량' 포함)을 찾지 못했습니다. 가능한 컬럼: {alcohol_raw.columns.tolist()}\")\n",
    "\n",
    "# 4. ID와 날짜, 음주량 컬럼만 추출\n",
    "df = alcohol_raw[[id_col, date_col, amount_col]].copy()\n",
    "\n",
    "# 5. 날짜를 YYYY-MM-DD 문자열로 변환\n",
    "df['date'] = pd.to_datetime(df[date_col], errors='coerce').dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 6. 컬럼명을 통일하여 ['ID', 'date', 'alcohol']로 이름 변경\n",
    "df = df.rename(columns={id_col: 'ID', amount_col: 'alcohol'})\n",
    "\n",
    "# 7. 한 사람(비식별키)이 특정 날짜에 음주 기록이 있으면 alcohol=1, 없으면 해당 행이 존재하지 않음\n",
    "df = df.drop_duplicates(subset=['ID', 'date'], ignore_index=True)\n",
    "\n",
    "# 8. 최종 컬럼 순서: ['ID', 'date', 'alcohol']\n",
    "df = df[['ID', 'date', 'alcohol']]\n",
    "df = filter_by_valid_ids(df, id_column='ID')\n",
    "\n",
    "output_path = os.path.join(output_folder, \"alcohol_per_date.csv\")\n",
    "df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed32c62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date         ID      time     HR\n",
      "0  2022-05-17  SYM1-1-65  00:00:00   79.0\n",
      "1  2022-05-16  SYM1-1-65  00:00:00    0.0\n",
      "2  2022-05-15  SYM1-1-65  00:00:00   70.0\n",
      "3  2022-05-14  SYM1-1-65  00:00:00   72.0\n",
      "4  2022-05-13  SYM1-1-65  00:00:00  155.0\n",
      "5  2022-05-12  SYM1-1-65  00:00:00    0.0\n",
      "6  2022-05-11  SYM1-1-65  00:00:00   77.0\n",
      "7  2022-05-10  SYM1-1-65  00:00:00   73.0\n",
      "8  2022-05-09  SYM1-1-65  00:00:00    0.0\n",
      "9  2022-05-07  SYM1-1-65  00:00:00    0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils_for_preprocessing import (\n",
    "    load_raw_file,\n",
    "    serialize_lifelog_heartrate,\n",
    "    filter_by_valid_ids\n",
    ")\n",
    "\n",
    "\n",
    "sheet_name = \"라이프로그-심박수\"\n",
    "\n",
    "# For each path, produce the long-format heart-rate DataFrame\n",
    "hr_dfs = [serialize_lifelog_heartrate(p) for p in SYM_raw_paths]\n",
    "HR_melted = pd.concat(hr_dfs, ignore_index=True)\n",
    "HR_melted.rename(columns={\"heart_rate\": \"HR\"}, inplace=True)\n",
    "HR_melted[\"HR\"] = HR_melted[\"HR\"].fillna(0)\n",
    "HR_melted[\"date\"] = HR_melted[\"date\"].astype(str).str[:10]\n",
    "HR_melted = filter_by_valid_ids(HR_melted, id_column='ID')\n",
    "output_path = os.path.join(output_folder, \"HR.csv\")\n",
    "HR_melted.to_csv(output_path, index=False)\n",
    "\n",
    "print(HR_melted.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93cc9ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils_for_preprocessing import load_raw_file, filter_by_valid_ids\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "steps = load_raw_file(SYM_raw_paths, sheet_name=\"라이프로그-걸음수\")\n",
    "\n",
    "# ——— 1. SYM1 & SYM2 엑셀병합 & 유효 ID 필터링 ———\n",
    "# raw_dfs: 각 엑셀파일에서 같은 시트 읽어서 DataFrame 리스트로\n",
    "# valid_ids 필터링\n",
    "\n",
    "# ——— 2. 중복 ID·날짜 제거 ———\n",
    "foot = steps.drop_duplicates(subset=['비식별키', '날짜'], keep='last')\n",
    "\n",
    "\n",
    "# ——— 4. Mi Band 사용자 데이터 제외 ———\n",
    "#    '측정_유형' 컬럼이 'Mi Band'인 행을 제거\n",
    "foot = foot[foot['측정_유형'] != 'MI-BAND']\n",
    "\n",
    "# ——— 5. 측정값(NaN) 있는 행 제거 ———\n",
    "foot.dropna(subset=['측정값(_1_:_값_없음)'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# ——— 8. 불필요 컬럼 제거 ———\n",
    "foot.drop(['총_걸음수', '측정_유형'], axis=1, inplace=True)\n",
    "\n",
    "# ——— 9. 인덱스 리셋 ———\n",
    "foot.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# ——— 10. 시계열 형태로 변환 (serialize_lifelog_data) ———\n",
    "#  하루 1440분에 대응하는 시간 인덱스 생성\n",
    "time_idx = pd.date_range('00:00:00', periods=1440, freq='1min').time\n",
    "col_minutes = [t.strftime('%H:%M:%S') for t in time_idx]\n",
    "\n",
    "#  '측정값(-1_:_값_없음)' 컬럼을 쉼표로 분리\n",
    "split_vals = foot['측정값(_1_:_값_없음)'].str.split(',').tolist()\n",
    "df_splitted = pd.DataFrame(split_vals, columns=col_minutes)\n",
    "\n",
    "#  원본과 합치고, 원래 측정 단위·값 컬럼 제거\n",
    "df_merged = pd.concat([foot[['날짜', '비식별키']].reset_index(drop=True),\n",
    "                       df_splitted.reset_index(drop=True)], axis=1)\n",
    "\n",
    "#  melt로 long 포맷 변환\n",
    "foot_melted = df_merged.melt(id_vars=['날짜', '비식별키'],\n",
    "                             var_name='time',\n",
    "                             value_name='foot')\n",
    "\n",
    "# ——— 11. 컬럼명 정리 & 값 정제 ———\n",
    "foot_melted.rename(columns={\n",
    "    '날짜': 'date',\n",
    "    '비식별키': 'ID'\n",
    "}, inplace=True)\n",
    "\n",
    "#  '-1' 값을 np.nan으로 변경\n",
    "foot_melted.loc[foot_melted['foot'] == '-1', 'foot'] = np.nan\n",
    "\n",
    "\n",
    "#  date 컬럼을 'YYYY-MM-DD' 포맷 문자열로\n",
    "foot_melted['date'] = foot_melted['date'].astype(str).str[:10]\n",
    "\n",
    "foot_melted = filter_by_valid_ids(foot_melted, id_column=\"ID\")\n",
    "\n",
    "\n",
    "output_path = os.path.join(output_folder, \"foot.csv\")\n",
    "foot_melted.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f5eabb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils_for_preprocessing import extract_emotion_diary_from_raw, filter_by_valid_ids\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "# For each metric, extract from both files and concatenate\n",
    "positive_dfs = [\n",
    "    extract_emotion_diary_from_raw(\n",
    "        p,\n",
    "        questionnaire_sheet='정서일지',\n",
    "        df_name='positive_feeling',\n",
    "        questionnaire_column='긍정적기분'\n",
    "    ) for p in SYM_raw_paths\n",
    "]\n",
    "positive = pd.concat(positive_dfs, ignore_index=True)\n",
    "\n",
    "negative_dfs = [\n",
    "    extract_emotion_diary_from_raw(\n",
    "        p,\n",
    "        questionnaire_sheet='정서일지',\n",
    "        df_name='negative_feeling',\n",
    "        questionnaire_column='부정적기분'\n",
    "    ) for p in SYM_raw_paths\n",
    "]\n",
    "negative = pd.concat(negative_dfs, ignore_index=True)\n",
    "\n",
    "positive_E_dfs = [\n",
    "    extract_emotion_diary_from_raw(\n",
    "        p,\n",
    "        questionnaire_sheet='정서일지',\n",
    "        df_name='positive_E',\n",
    "        questionnaire_column='긍정적에너지'\n",
    "    ) for p in SYM_raw_paths\n",
    "]\n",
    "positive_E = pd.concat(positive_E_dfs, ignore_index=True)\n",
    "\n",
    "negative_E_dfs = [\n",
    "    extract_emotion_diary_from_raw(\n",
    "        p,\n",
    "        questionnaire_sheet='정서일지',\n",
    "        df_name='negative_E',\n",
    "        questionnaire_column='부정적에너지'\n",
    "    ) for p in SYM_raw_paths\n",
    "]\n",
    "negative_E = pd.concat(negative_E_dfs, ignore_index=True)\n",
    "\n",
    "anxiety_dfs = [\n",
    "    extract_emotion_diary_from_raw(\n",
    "        p,\n",
    "        questionnaire_sheet='정서일지',\n",
    "        df_name='anxiety',\n",
    "        questionnaire_column='불안'\n",
    "    ) for p in SYM_raw_paths\n",
    "]\n",
    "anxiety = pd.concat(anxiety_dfs, ignore_index=True)\n",
    "\n",
    "annoying_dfs = [\n",
    "    extract_emotion_diary_from_raw(\n",
    "        p,\n",
    "        questionnaire_sheet='정서일지',\n",
    "        df_name='annoying',\n",
    "        questionnaire_column='짜증'\n",
    "    ) for p in SYM_raw_paths\n",
    "]\n",
    "annoying = pd.concat(annoying_dfs, ignore_index=True)\n",
    "\n",
    "#data preprocessing\n",
    "data_list = [positive, negative, positive_E, negative_E, anxiety, annoying]\n",
    "emotion_diary = reduce(lambda x, y : pd.merge(x, y, on=['ID', 'date'], how='outer'), data_list)\n",
    "emotion_diary = filter_by_valid_ids(emotion_diary, id_column='ID')\n",
    "\n",
    "output_path = os.path.join(output_folder, \"emotion_diary.csv\")\n",
    "emotion_diary.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49db8161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils_for_preprocessing import load_raw_file, filter_by_valid_ids\n",
    "from functools import reduce\n",
    "\n",
    "diary = load_raw_file(SYM_raw_paths, sheet_name=\"일기\")\n",
    "diary = diary.rename(columns={'비식별키': 'ID', '날짜' : 'date', '기분' : 'mood', '내용' : 'contents'})\n",
    "diary = filter_by_valid_ids(diary ,id_column=\"ID\")\n",
    "\n",
    "diary = diary.drop_duplicates(subset=['ID', 'date'], keep='last')\n",
    "diary.dropna(subset=['contents'], inplace=True)\n",
    "diary = diary.drop(columns=['시간'])\n",
    "output_path = os.path.join(output_folder, \"diary.csv\")\n",
    "diary.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376b3ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e85a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366fd571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f9bc47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
