{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28551a76",
   "metadata": {},
   "source": [
    "# Panic Project (DHLAB) - Multiclass Classification PyCaret Model for Panic Severity Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdc63ef",
   "metadata": {},
   "source": [
    "author:  `@cyshin971`  \n",
    "\n",
    "date:    `2025-07-xx`  \n",
    "\n",
    "Instructions:\n",
    "- Scrape data (see `README` - `Instructions` - `Data Scraping`)  \n",
    "- Run `data_preprocessing.ipynb`\n",
    "- Run `data_imputation.ipynb`\n",
    "- Run `data_analysis.ipynb`\n",
    "- Under ‚öôÔ∏è|Settings, specify name of the `scraped_data_filename` you want to use\n",
    "  - Specify how many days prior to panic (`dbp`) you want to use (`1`, `2`, `3`)\n",
    "  - (Optional) specify type of imputation you want to use `use_growing_average`, `null_default_zero`\n",
    "\n",
    "version: `3-1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a49b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"3-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fec94e",
   "metadata": {},
   "source": [
    "# üìö | Import Libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95047cb",
   "metadata": {},
   "source": [
    "Required Packages:\n",
    "- `python` (`3.10`)\n",
    "- `pandas`  \n",
    "- `numpy`\n",
    "- `json`\n",
    "- `matplotlib`\n",
    "- `pyacaret`\n",
    "- `shap`\n",
    "- `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca28a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config as cfg\n",
    "import logging\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "\n",
    "from library.pandas_utils import move_column, remove_columns, create_empty_df, read_csv, aggregate_by_column\n",
    "from library.text_utils import save_as_csv\n",
    "from library.json_utils import load_dict_from_file\n",
    "from library.path_utils import get_file_path\n",
    "from library.matplotlib_utils import plot_histogram_of_counts\n",
    "\n",
    "from pycaret.classification import *\n",
    "import shap\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83462d69",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è | Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6e7b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_data_filename = \"final_result_20250626_360_no_ffill\" # Name of the scraped data file without extension (.csv)\n",
    "# leave as None if you want to retrieve from the latest imputed data file\n",
    "use_growing_avg = None # Set to True/False to retrieve growing average '_grw' OR average '_avg' data\n",
    "null_default_zero = None # Set to True/False to retrieve zero filled '_zero' OR global average filled '_global' data\n",
    "\n",
    "dbp_param = 2 # from 1 to 3, depending on the DBP model you want to use.\n",
    "\n",
    "only_top_10_features = False # If True, only the top 10 features will be used for the model training and evaluation.\n",
    "top_10_features = None\n",
    "# Top 10 features for 1 DBP 360 model\n",
    "# top_10_features = ['STAI_X2', 'age', 'PHQ_9', 'smoking', 'CTQ_4', 'annoying', 'gender', 'drinkHx', 'SLT4', 'step_delta2']\n",
    "# Top 10 features for 2 DBP 360 model\n",
    "# top_10_features = ['smoking(1)', 'step_mean_delta(2)', 'step_hvar_mean_delta(2)', 'step_delta2(1)', 'suicideHx', 'steps_variance(1)', 'marriage', 'age', 'gender', 'step_delta2(2)']\n",
    "# Top 10 features for 3 DBP 360 model\n",
    "# top_10_features = ['HR_mean(3)', 'HR_acrophase(2)', 'steps_mean(3)', 'age', 'steps_maximum(2)', 'smoking(1)', 'HR_var(3)', 'gender', 'suicideHx', 'steps_maximum(3)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7bf1ba",
   "metadata": {},
   "source": [
    "# üìÅ | Path Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25f5f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data\"\n",
    "TMP_PATH = \"./_tmp\"\n",
    "OUT_PATH = TMP_PATH\n",
    "OUTPUT_PATH = \"./panic_severity_model/_results\"\n",
    "\n",
    "try:\n",
    "\tcurrent_config = load_dict_from_file(OUT_PATH, 'current_config')\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"File not found: {get_file_path(OUT_PATH, 'current_config.csv')}.\\nPlease run data_preprocessing.ipynb first.\")\n",
    "\n",
    "print(f\"Loaded current config with {len(current_config)} keys:\")\n",
    "scraped_data_filename = None\n",
    "for k, v in current_config.items():\n",
    "    if k == 'scraped_data_filename':\n",
    "        scraped_data_filename = v\n",
    "    elif k == 'preproc_version':\n",
    "        preproc_version = v\n",
    "    elif k == 'imputation_version':\n",
    "        imputation_version = v\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "if scraped_data_filename is None:\n",
    "\traise ValueError(\"scraped_data_filename not found in current_config. Please ensure that data_preprocessing.ipynb has been run successfully before running this notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b4473c",
   "metadata": {},
   "source": [
    "# üåê | Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e8af24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUTPUT:\n",
    "    num_classes = 3\n",
    "    class_names = ['Mild', 'Moderate', 'Severe']\n",
    "    \n",
    "    label2name = dict(enumerate(class_names))\n",
    "    name2label = {v: k for k, v in label2name.items()}\n",
    "    \n",
    "    plot_label2name = {\n",
    "\t\t'class_0': 'Mild',\n",
    "\t\t'class_1': 'Moderate',\n",
    "\t\t'class_2': 'Severe'\n",
    "\t}\n",
    "    plot_name2label = {v: k for k, v in plot_label2name.items()}\n",
    "\n",
    "    color_name2color = {\n",
    "\t\t'Mild': 'skyblue',\n",
    "\t\t'Moderate': 'orange',\n",
    "\t\t'Severe': 'lightcoral'\n",
    "\t}\n",
    "    \n",
    "    output_dict = {\n",
    "\t\t1: 'Mild',\n",
    "\t\t2: 'Mild',\n",
    "\t\t3: 'Moderate',\n",
    "\t\t4: 'Severe',\n",
    "\t\t5: 'Severe'\n",
    "\t}\n",
    "    output_dict_inv = {v: k for k, v in output_dict.items()}\n",
    "\n",
    "    @staticmethod\n",
    "    def get_label_name(label):\n",
    "        return OUTPUT.label2name[label]\n",
    "    @staticmethod\n",
    "    def get_label_from_name(name):\n",
    "        return OUTPUT.name2label[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0172b789",
   "metadata": {},
   "source": [
    "# ‚öíÔ∏è | Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307bd1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\tfeatures_dict = load_dict_from_file(DATA_PATH, 'panic_features_dict')\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"File not found: {get_file_path(OUT_PATH, 'panic_features_dict.csv')}.\\nPlease run data_preprocessing.ipynb first.\")\n",
    "\n",
    "print(f\"Loaded features dict with {len(features_dict)} keys:\")\n",
    "for k, v in features_dict.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "if use_growing_avg is None:\n",
    "\tuse_growing_avg = features_dict.get('use_growing_avg', False)\n",
    "if null_default_zero is None:\n",
    "\tnull_default_zero = features_dict.get('null_default_zero', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4319fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The following lines can be used in development mode to select data files generated through development mode\n",
    "# spec = f\"_{('grw' if use_growing_avg else 'avg')}_{('zero' if null_default_zero else 'global')}\"\n",
    "# data_filename = f'panic_pre_data_filled_{imputation_version}({scraped_data_filename}){spec}'\n",
    "\n",
    "# NOTE: Make sure to change the file names below to match the actual files you have\n",
    "pre_data = read_csv(get_file_path(DATA_PATH, f'panic_pre_data_filled.csv'))\n",
    "display(pre_data.head(3))\n",
    "metadata = read_csv(get_file_path(DATA_PATH, f'panic_metadata.csv'))\n",
    "display(metadata.head(3))\n",
    "demography_data = read_csv(get_file_path(DATA_PATH, f'panic_demography_data.csv'))\n",
    "display(demography_data.head(3))\n",
    "patient_data = read_csv(get_file_path(DATA_PATH+'/analysis', f'panic_patient_analysis.csv'))\n",
    "display(patient_data.head(3))\n",
    "\n",
    "print(f\"Number of Demographic Features: {len(features_dict['demography'])}\")\n",
    "print(f\"Number of Daily Features: {len(features_dict['dailylog'])}\")\n",
    "print(f\"Number of Life Log Features: {len(features_dict['lifelog'])}\")\n",
    "print(f\"Number of Questionnaire Features: {len(features_dict['questionnaire'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d373b39",
   "metadata": {},
   "source": [
    "# üîÑÔ∏è | Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50191164",
   "metadata": {},
   "source": [
    "## Filter Relevant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852adcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_metadata = create_empty_df()\n",
    "filtered_pre_data = create_empty_df()\n",
    "proc_data_init = create_empty_df()\n",
    "\n",
    "# Filter metadata for entries with at least dbp_param days of prior data\n",
    "print(f\"Found {len(metadata[metadata['panic_label'] == 1])} entries with panic label.\")\n",
    "proc_data_init = metadata[(metadata[f'panic_label'] == 1) &\n",
    "                          (metadata[f'valid_entry_{dbp_param}'] == 1)].copy()\n",
    "filtered_panic_metadata_entry_ids = proc_data_init['entry_id'].unique()\n",
    "filtered_metadata = metadata[(metadata['ref_event_id'].isin(filtered_panic_metadata_entry_ids)) &\n",
    "                             (metadata[f'dbp'] <= dbp_param)].copy()\n",
    "print(f\"Found {len(filtered_panic_metadata_entry_ids)} entries with panic label and at least {dbp_param} days of prior data.\")\n",
    "\n",
    "# Perform checks\n",
    "unique_dbp = filtered_metadata['dbp'].unique()\n",
    "if len(unique_dbp) != dbp_param:\n",
    "\traise ValueError(f\"Expected {dbp_param} unique DBP values, found {len(unique_dbp)}: {unique_dbp}\")\n",
    "del unique_dbp\n",
    "\n",
    "filtered_entry_ids = filtered_metadata['entry_id'].unique()\n",
    "filtered_panic_entry_ids = filtered_metadata['ref_event_id'].unique()\n",
    "# Filter pre_data for entries that reference panic events with at least dbp_param days of prior data\n",
    "filtered_pre_data = pre_data[pre_data['entry_id'].isin(filtered_entry_ids)].copy()\n",
    "\n",
    "# Perform checks\n",
    "if len(filtered_pre_data) != len(filtered_metadata):\n",
    "\traise ValueError(f\"Filtered pre_data length {len(filtered_pre_data)} does not match filtered_metadata length {len(filtered_metadata)}\")\n",
    "print(f\"Filtered data contains {len(filtered_panic_entry_ids)} unique panic events and {len(filtered_entry_ids)} unique entry IDs.\")\n",
    "print(f\"Filtered pre_data contains {len(filtered_pre_data['ID'].unique())} unique IDs.\")\n",
    "del filtered_entry_ids\n",
    "\n",
    "# Initialize processed data with correct entries\n",
    "proc_data_init = proc_data_init[features_dict['id']+features_dict['label']].copy()\n",
    "print(f\"Initial processed data contains {len(proc_data_init)} entries with {len(proc_data_init.columns)} columns.\")\n",
    "display(proc_data_init.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84254be",
   "metadata": {},
   "source": [
    "## üß± | Construct Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e0927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_data_int = create_empty_df()\n",
    "proc_data_int = proc_data_init.copy()\n",
    "\n",
    "# remove 'severity' from features_dict['dailylog]\n",
    "features_dict['dailylog'] = [f for f in features_dict['dailylog'] if f != 'severity']\n",
    "\n",
    "if only_top_10_features:\n",
    "    top_10_demo = [f for f in top_10_features if f in features_dict['demography']]\n",
    "    demography_data = demography_data[['ID'] + top_10_demo].copy()\n",
    "# use demography data to add demographic features to proc_data using ID (multiple entries per ID)\n",
    "proc_data_int = pd.merge(proc_data_int, demography_data, on='ID', how='left')\n",
    "\t\n",
    "\n",
    "for i in range(1, dbp_param + 1):\n",
    "    # make a dictionary of 'entry_id' : 'ref_event_id' for the current dbp\n",
    "\tdbp_dict = filtered_metadata[filtered_metadata['dbp'] == i].set_index('entry_id')['ref_event_id'].to_dict()\n",
    "\tprint(f\"Processing data for {i} days before panic.\")\n",
    "\n",
    "\tentry_ids = dbp_dict.keys()\n",
    "\tfiltered_pre_data_i = filtered_pre_data[filtered_pre_data['entry_id'].isin(entry_ids)].copy()\n",
    "\tif len(filtered_pre_data_i) != len(dbp_dict.keys()):\n",
    "\t\traise ValueError(f\"Filtered pre_data length {len(filtered_pre_data_i)} does not match filtered_metadata length {len(dbp_dict.keys())} for {i} days before panic\")\n",
    "  \t# Update 'entry_id' in filtered_pre_data_i to the corresponding 'ref_event_id' from dbp_dict\n",
    "\tfiltered_pre_data_i['entry_id'] = filtered_pre_data_i['entry_id'].map(dbp_dict)\n",
    "\t\n",
    "\tfeatures_list = ['entry_id']+features_dict['dailylog']+features_dict['lifelog']\n",
    "\tif i == dbp_param:\n",
    "\t\tfeatures_list += features_dict['questionnaire']\n",
    "   \n",
    "\tfiltered_pre_data_i = filtered_pre_data_i[features_list].copy()\n",
    "\t# rename ALL non-ID columns to include the suffix\n",
    "\tif dbp_param > 1:\n",
    "\t\tcols_to_rename = [c for c in filtered_pre_data_i.columns if c != 'entry_id']\n",
    "\t\trename_map = {c: f\"{c}({i})\" for c in cols_to_rename}\n",
    "\t\tfiltered_pre_data_i.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "\tproc_data_int = pd.merge(proc_data_int, filtered_pre_data_i, on='entry_id', how='left', suffixes=('', f'_{i}'))\n",
    "\n",
    "# Use OUTPUT.output_dict to map severity labels\n",
    "proc_data_int['severity'] = proc_data_int['severity'].map(OUTPUT.output_dict)\n",
    "\n",
    "if only_top_10_features:\n",
    "\t# Filter proc_data_int to only include the top 10 features\n",
    "\ttop_10_features = [f for f in top_10_features if f in proc_data_int.columns]\n",
    "\tif len(top_10_features) != 10:\n",
    "\t\traise ValueError(f\"No top 10 features found in proc_data_int ({len(top_10_features)} found). Expected 10.\\n{top_10_features}\")\n",
    "\tproc_data_int = proc_data_int[features_dict['id'] + ['panic', 'severity', 'panic_label'] + top_10_features].copy()\n",
    "\n",
    "display(proc_data_int.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7bf588",
   "metadata": {},
   "source": [
    "## üíæ | Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49c7abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_data = create_empty_df()\n",
    "proc_data = proc_data_int.copy()\n",
    "\n",
    "r_cols = ['panic',\n",
    "          'panic_label']\n",
    "remove_columns(proc_data, r_cols)\n",
    "move_column(proc_data, 'severity', -1)\n",
    "display(proc_data.head(3))\n",
    "save_as_csv(proc_data, DATA_PATH, f'panic_severity_multi_proc_data_{dbp_param}days_{version}({scraped_data_filename})', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad165785",
   "metadata": {},
   "source": [
    "## üîç | Processed Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba07f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(patient_data.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46625d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_matrix = [\n",
    "\t('n_valid_panic', 'entry_id', 'count'),\n",
    "\t('n_mild', 'severity', lambda x: (x == 'Mild').sum()),\n",
    "\t('n_moderate', 'severity', lambda x: (x == 'Moderate').sum()),\n",
    "\t('n_severe', 'severity', lambda x: (x == 'Severe').sum()),\n",
    "]\n",
    "\n",
    "proc_data_agg = aggregate_by_column(proc_data, 'ID', agg_matrix)\n",
    "\n",
    "# merge the relevant IDs from patient_data into proc_data_agg to get the patient data\n",
    "proc_data_agg = pd.merge(proc_data_agg, patient_data, on='ID', how='left')\n",
    "display(proc_data_agg.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca57ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_of_counts(proc_data_agg['n_entries'],\n",
    "\t\t\t\t\t\t title='Number of Entries per Patient', figsize=(8, 3),\n",
    "\t\t\t\t\t\t xlabel='Number of Entries',\n",
    "\t\t\t\t\t\t ylabel='Number of Patients', ymax=20,\n",
    "       \t\t\t\t\t bins_step=50)\n",
    "print(f\"Number of patients > 100 entries: {len(proc_data_agg[proc_data_agg['n_entries'] > 100])}\")\n",
    "print(f\"Number of patients with <= 100 entries: {len(proc_data_agg[proc_data_agg['n_entries'] <= 100])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49957b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a histogram of the severity distribution\n",
    "plt.figure(figsize=(5, 3))\n",
    "severity_counts = proc_data['severity'].value_counts().sort_index()\n",
    "total_count = severity_counts.sum()\n",
    "colors = [OUTPUT.color_name2color['Mild'], OUTPUT.color_name2color['Moderate'], OUTPUT.color_name2color['Severe']]\n",
    "ax = severity_counts.plot(kind='bar', color=colors)\n",
    "plt.title('Severity Distribution')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Add labels with counts and percentages at the center of each bar\n",
    "for p in ax.patches:\n",
    "\tcount = p.get_height()\n",
    "\tpercentage = f\"{(count / total_count * 100):.1f}%\"\n",
    "\tax.annotate(f'{count}\\n{percentage}',\n",
    "\t\t\t\t(p.get_x() + p.get_width() / 2., p.get_height() / 2.),\n",
    "\t\t\t\tha='center', va='center', fontsize=10, color='black', xytext=(0, 0),\n",
    "\t\t\t\ttextcoords='offset points')\n",
    "\n",
    "# Remove the 'severity' label from the bottom\n",
    "ax.set_xlabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b01af17",
   "metadata": {},
   "source": [
    "# ü§ñ | Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4744a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = proc_data.copy()\n",
    "remove_columns(data, features_dict['id'])\n",
    "print(f\"Processed data contains {len(data)} entries with {len(data.columns)} columns after removing ID columns.\")\n",
    "display(data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249402fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyCaret setup\n",
    "clf = setup(\n",
    "    data=data,\n",
    "    target='severity',               # replace with your target column name\n",
    "    session_id=123,                  # for reproducibility\n",
    "    normalize=True,                  # scale numeric features\n",
    "    transformation=False,            # turn off power transformation\n",
    "    train_size=0.8,                  # 80/20 split\n",
    "    fold=5,                          # 5-fold cross-validation\n",
    "    fold_strategy='stratifiedkfold',\n",
    "    numeric_imputation='mean',\n",
    "    remove_multicollinearity=True,   # for small datasets, this is often helpful\n",
    "\tmulticollinearity_threshold=0.9, # threshold for removing multicollinear features\n",
    "\t# html=False,                    # do not generate HTML report (use plain-text output)\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603bb323",
   "metadata": {},
   "source": [
    "# üöÇ | Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4eea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare baseline models and select the best by Accuracy\n",
    "best_model = compare_models(sort='Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4757a3b6",
   "metadata": {},
   "source": [
    "# üß™ | Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6e4fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pull()  # Get the latest output table as a DataFrame\n",
    "# Cross-Validation results\n",
    "# print(\"Cross-Validation Results:\")\n",
    "# display(results)  # Jupyter display (can further style if you want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48196744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on hold-out set (20% test split)\n",
    "holdout_results = predict_model(best_model)\n",
    "print(f\"Hold-out Set Results (20% test split) for {OUTPUT.num_classes} classes (test_size={len(holdout_results)}):\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa63f947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best model\n",
    "os.makedirs('./_results', exist_ok=True)  # Ensures the folder exists\n",
    "save_model(best_model, f'./_results/panic_severity_multi_best_model_{dbp_param}days_{version}({scraped_data_filename})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a651c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_model_name = None\n",
    "if spec_model_name:\n",
    "    # Create a specific model (e.g., Random Forest)\n",
    "\tspec_model = create_model(spec_model_name, fold=5, cross_validation=True)\n",
    "\tprint(f\"Created specific model: {spec_model_name}\")\n",
    "\n",
    "\t# Evaluate the specific model\n",
    "\tspec_results = predict_model(spec_model)\n",
    "\tprint(f\"Specific Model Results ({spec_model_name}):\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9246934",
   "metadata": {},
   "source": [
    "# üîç | Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0084dcd0",
   "metadata": {},
   "source": [
    "## SHAP Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b9624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the best model is TreeExplainer-compatible\n",
    "tree_model_ids = ['et', 'rf', 'gbc', 'lightgbm', 'dt']\n",
    "tree_model_names = [\n",
    "    'Extra Trees Classifier', 'Random Forest Classifier',\n",
    "    'Gradient Boosting Classifier', 'Light Gradient Boosting Machine',\n",
    "    'Decision Tree Classifier'\n",
    "]\n",
    "\n",
    "# Function to check compatibility by class name\n",
    "def is_tree_model(model):\n",
    "    model_name = model.__class__.__name__.lower()\n",
    "    # Try common tree model keywords\n",
    "    return any(keyword in model_name for keyword in ['forest', 'tree', 'boost', 'lightgbm'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbc5b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP analysis only if TreeExplainer compatible\n",
    "if spec_model_name:\n",
    "    logging.info(f\"Using specific model: {spec_model_name}\")\n",
    "    shap_model = spec_model\n",
    "else:\n",
    "    logging.info(\"Using best model from PyCaret compare_models.\")\n",
    "    shap_model = best_model\n",
    "\n",
    "is_compatible = is_tree_model(shap_model)\n",
    "\n",
    "if is_compatible:\n",
    "    print(f\"Best model ({shap_model.__class__.__name__}) is compatible with SHAP TreeExplainer.\")\n",
    "\n",
    "    # Extract features (remove prediction/score columns)\n",
    "    feature_cols = [col for col in holdout_results.columns if col in data.columns and col != 'severity']\n",
    "    X_holdout = holdout_results[feature_cols]\n",
    "\n",
    "    # --- Robust estimator unwrapping for ensembles ---\n",
    "    model_to_explain = shap_model\n",
    "    base_estimator_key = None  # Track which base estimator is used\n",
    "    # Unwrap only if Voting or Stacking ensemble\n",
    "    if isinstance(model_to_explain, (VotingClassifier, StackingClassifier)):\n",
    "        named_estimators = dict(model_to_explain.named_estimators_)\n",
    "        # Try to select a tree-based model in order of preference\n",
    "        for key in ['rf', 'et', 'gbc', 'lightgbm', 'dt']:\n",
    "            if key in named_estimators and is_tree_model(named_estimators[key]):\n",
    "                model_to_explain = named_estimators[key]\n",
    "                base_estimator_key = key\n",
    "                print(f\"Selected base estimator '{key}' from Voting/Stacking ensemble.\")\n",
    "                break\n",
    "        if base_estimator_key is None:\n",
    "            print(\"Warning: No compatible tree model found in the ensemble; SHAP will use the full ensemble.\")\n",
    "\n",
    "    print(\"Model to explain:\", type(model_to_explain))\n",
    "\n",
    "    # Build the SHAP TreeExplainer\n",
    "    explainer = shap.TreeExplainer(model_to_explain)\n",
    "    shap_values = explainer.shap_values(X_holdout)\n",
    "\n",
    "    # Get SHAP values as DataFrame (one per class)\n",
    "    shap_dfs = {}\n",
    "    \n",
    "    if isinstance(shap_values, list):\n",
    "        # Standard SHAP output for multiclass: list of [n_samples, n_features] arrays (one per class)\n",
    "        for i, class_shap in enumerate(shap_values):\n",
    "            shap_dfs[f\"class_{i}\"] = pd.DataFrame(class_shap, columns=X_holdout.columns, index=X_holdout.index)\n",
    "    elif isinstance(shap_values, np.ndarray) and shap_values.ndim == 3:\n",
    "        # SHAP returned shape: (n_samples, n_features, n_classes)\n",
    "        n_classes = shap_values.shape[2]\n",
    "        for i in range(n_classes):\n",
    "            shap_dfs[f\"class_{i}\"] = pd.DataFrame(shap_values[:,:,i], columns=X_holdout.columns, index=X_holdout.index)\n",
    "    else:\n",
    "        # Binary or regression: single 2D array\n",
    "        shap_dfs[\"shap_values\"] = pd.DataFrame(shap_values, columns=X_holdout.columns, index=X_holdout.index)\n",
    "else:\n",
    "    logging.warning(f\"Model ({best_model.__class__.__name__}) is NOT compatible with SHAP TreeExplainer.\")\n",
    "    print(\"Please select one of the following tree models for SHAP analysis: 'et', 'rf', 'gbc', 'lightgbm', 'dt'\")\n",
    "    print(\"Example:\")\n",
    "    print(\"rf_model = create_model('rf')\\nrf_model = finalize_model(rf_model)\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c1e9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 10  # Number of features to show\n",
    "\n",
    "if is_compatible:\n",
    "\t# Compute the global maximum value across all classes\n",
    "\tglobal_max = max(df.abs().mean(axis=0).max() for df in shap_dfs.values()) * 1.25\n",
    "\n",
    "\ttop_overall_features = {}\n",
    "\n",
    "\tfor class_label in OUTPUT.plot_label2name.keys():\n",
    "\t\tdf = shap_dfs[class_label]\n",
    "\t\t# Compute mean absolute SHAP value for each feature\n",
    "\t\tfeature_importance = df.abs().mean(axis=0).sort_values(ascending=False)\n",
    "\t\t# Get top features\n",
    "\t\ttop_features = feature_importance.head(top_n)\n",
    "\t\tfor i, feature in enumerate(top_features.index):\n",
    "\t\t\tif feature not in top_overall_features:\n",
    "\t\t\t\ttop_overall_features[feature] = [0, []]  # Initialize with zero and None\n",
    "\t\t\ttop_overall_features[feature][0] += top_features[feature]\n",
    "\t\t\ttop_overall_features[feature][1].append(OUTPUT.plot_label2name[class_label])\n",
    "\t\t\n",
    "\t\t# Bar plot\n",
    "\t\tplt.figure(figsize=(6, 4))\n",
    "\t\tcolors = [OUTPUT.color_name2color[OUTPUT.plot_label2name[class_label]]] * len(top_features)\n",
    "\t\tax = top_features[::-1].plot(kind='barh', color=colors)\n",
    "\t\tplt.title(f\"Top {top_n} Features by Mean(|SHAP|) for {OUTPUT.plot_label2name[class_label]}\")\n",
    "\t\tplt.xlabel(\"Mean(|SHAP Value|)\")\n",
    "\t\tplt.xlim(0, global_max)  # Set the x-axis limit to the global maximum\n",
    "\t\t# plt.xlim(0, .0325)  # Set the x-axis limit to the global maximum\n",
    "\t\t\n",
    "\t\t# Add labels with values to the right of each bar\n",
    "\t\tfor p in ax.patches:\n",
    "\t\t\tvalue = f\"{p.get_width():.4f}\"\n",
    "\t\t\tax.annotate(value,\n",
    "\t\t\t\t\t\t(p.get_width() + 0.001, p.get_y() + p.get_height() / 2),\n",
    "\t\t\t\t\t\tha='left', va='center', fontsize=10, color='black', xytext=(0, 0),\n",
    "\t\t\t\t\t\ttextcoords='offset points')\n",
    "\t\t\n",
    "\t\tplt.tight_layout()\n",
    "\t\tplt.show()\n",
    "\n",
    "\t# Create a DataFrame for the overall top features\n",
    "\ttop_overall_df = pd.DataFrame.from_dict(\n",
    "\t\t{feature: {\"Mean(|SHAP|)\": values[0], \"Class\": values[1]} for feature, values in top_overall_features.items()},\n",
    "\t\torient='index'\n",
    "\t)\n",
    "\ttop_overall_df['Mean(|SHAP|)'] = top_overall_df.apply(\n",
    "\t\tlambda row: row['Mean(|SHAP|)'] / len(row['Class']), axis=1\n",
    "\t)\n",
    "\ttop_overall_df = top_overall_df.sort_values(by='Mean(|SHAP|)', ascending=False)\n",
    "\t# Display the overall top features\n",
    "\tprint(f\"Overall Top {top_n} Features by Mean(|SHAP|):\")\n",
    "\tdisplay(top_overall_df.head(top_n))\n",
    "\t# save_as_csv(top_overall_df, TMP_PATH, f'panic_severity_multi_top_features_{dbp_param}days_{version}({scraped_data_filename})', index=True)\n",
    "\n",
    "\t# === GLOBAL MEAN ACROSS ALL CLASSES AND SAMPLES ===\n",
    "\t# Stack all SHAP values (for all classes) vertically and compute mean across all samples and classes\n",
    "\tall_abs_shap = np.vstack([df.abs().values for df in shap_dfs.values()])\n",
    "\tglobal_feature_importance = pd.DataFrame({\n",
    "\t\t'Feature': X_holdout.columns,\n",
    "\t\t'Global Mean(|SHAP|)': all_abs_shap.mean(axis=0)\n",
    "\t}).set_index('Feature')\n",
    "\tglobal_top_features = global_feature_importance.sort_values(by='Global Mean(|SHAP|)', ascending=False).head(top_n)\n",
    "\tprint(f\"\\nTop {top_n} Features by GLOBAL Mean(|SHAP|) Across All Classes and Samples:\")\n",
    "\tdisplay(global_top_features)\n",
    "\t# save_as_csv(global_top_features, TMP_PATH, f'panic_severity_multi_global_top_features_{dbp_param}days_{version}({scraped_data_filename})', index=True)\n",
    "else:\n",
    "    logging.warning(f\"Model ({best_model.__class__.__name__}) is NOT compatible with SHAP TreeExplainer.\")\n",
    "    print(f\"Best model ({best_model.__class__.__name__}) is NOT compatible with SHAP TreeExplainer.\")\n",
    "    print(\"Please select one of the following tree models for SHAP analysis: 'et', 'rf', 'gbc', 'lightgbm', 'dt'\")\n",
    "    print(\"Example:\")\n",
    "    print(\"rf_model = create_model('rf')\\nrf_model = finalize_model(rf_model)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcbb171",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 10\n",
    "\n",
    "if is_compatible:\n",
    "\tfor class_label, df in shap_dfs.items():\n",
    "\t\t# 1. Compute top N features by mean(|SHAP value|) for this class\n",
    "\t\tfeature_importance = df.abs().mean(axis=0).sort_values(ascending=False)\n",
    "\t\ttop_features = feature_importance.head(top_n).index.tolist()\n",
    "\n",
    "\t\t# 2. Subset SHAP values and features\n",
    "\t\tshap_values_top = df[top_features]\n",
    "\t\tX_top = X_holdout[top_features]\n",
    "\n",
    "\t\t# 3. Beeswarm plot (summary plot) for this class and top features only\n",
    "\t\tplt.figure(figsize=(8, 5))\n",
    "\t\tshap.summary_plot(\n",
    "\t\t\tshap_values_top.values,    # SHAP values: shape (n_samples, n_top_features)\n",
    "\t\t\tX_top,                    # Input features for those columns\n",
    "\t\t\tfeature_names=top_features,\n",
    "\t\t\tshow=False,               # So we can modify the plot\n",
    "\t\t\tplot_size=(8, 5)\n",
    "\t\t)\n",
    "\t\tplt.title(f\"SHAP Beeswarm: Top {top_n} Features ({OUTPUT.plot_label2name[class_label]})\")\n",
    "\t\tplt.tight_layout()\n",
    "\t\tplt.show()\n",
    "else:\n",
    "\tlogging.warning(f\"Model ({best_model.__class__.__name__}) is NOT compatible with SHAP TreeExplainer.\")\n",
    "\tprint(f\"Best model ({best_model.__class__.__name__}) is NOT compatible with SHAP TreeExplainer.\")\n",
    "\tprint(\"Please select one of the following tree models for SHAP analysis: 'et', 'rf', 'gbc', 'lightgbm', 'dt'\")\n",
    "\tprint(\"Example:\")\n",
    "\tprint(\"rf_model = create_model('rf')\\nrf_model = finalize_model(rf_model)\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dhlab-panic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
